\documentclass[]{article}
\input{../mathdoc}
\input{../mathsym}
\input{../theorem}
%\input{../preview}

\author{Presenter: Richard Fabiano, Notes by Michael Reed, Book: Erwin Kreyszig}
\title{Functional Analysis}
%date{}

\begin{document}
\maketitle

%\begin{abstract}
%\end{abstract}

Chapter 1 - Metric spaces:
skip but will refer back to some examples.

\ul{Chapter 2}

\begin{definition}
	A vector space over a field $K$ is nonempty set $X$ of elements (called vectors) together with algebraic operations of vector addition and scalar multiplication which satisfy axioms (p. 50-51).
\end{definition}
\begin{note}
	In this course, $K$ is always either $\mb R$ or $\mb C$.
\end{note}
\begin{example}
	[$\mb R^2$ and $\mb R^3$] These we can \say{visualize} vectors as directed line segments and we have some \say{intuition.}
\end{example}
\begin{example}
	[$X = \mb R^n$] $x = (\xi_1,\dots,\xi_n)$, $\xi_i\in\mb R$.
\end{example}
\begin{example}
	[$X=\mb C^n$] $x = (\xi_1,\dots,\xi_n)$, $\xi_i\in\mb C$.
\end{example}
\begin{example}
	[$X=\ell^\infty$] vectors are sequences $x=(\xi_1,\xi_2,\dots)$ satisfying $\sup\setc{|\xi_i|}{i=1,2,\dots}<\infty$.
\end{example}
\begin{example}
	[$X = C{[}a,b{]}$] vectors $x=x(t)$ are continuous functions on interval $[a,b]$.
\end{example}

\begin{definition}
	A \ul{subspace} of a vector space $X$ is a nonempty subset $Y$ such that $\forall x,y\in Y$ and $\forall \alpha,\beta\in K$, then $\alpha x+\beta y\in Y$.
\end{definition}
\begin{note}
	A subspace $Y$ is itself a vector space.
\end{note}
\begin{definition}
	A \ul{linear combination} of vectors $x_1,\dots,x_n$ in $X$ is a vector of the form $\alpha_1x_1+\dots+\alpha_nx_n$, with $\alpha_n\in K$.
\end{definition}
\begin{definition}
	If $M\subset X$ is a subset of $X$, the set of all linear combinations of vectors of vectors in $M$ is called span of $M$, denoted $\spn M$.
\end{definition}
\begin{note}
	$\spn M$ is a subspace.
\end{note}
\begin{definition}
	Consider a finite set $M = \set{x_1,\dots,x_n}$ and the equation $\alpha_1x_1 + \dots + \alpha_nx_n = 0$ $(*)$.
	If $(*)$ holds only for $\alpha_1=\alpha_2=\dots=\alpha_n = 0$, then $M$ is linearly independent. otherwise dependent.
\end{definition}

An infinite set $M$ is linearly independent if every finite subset is linearly independent.

\begin{definition}
	If $X$ is a vector space and $\mc B$ is a linear independent subset such that $\spn \mc B = X$, then $\mc B$ is a basis for $X$ (Hamel basis).
\end{definition}

\begin{definition}
	A vector space $X$ is \ul{finite dimensional} if there is a natural number $n$ such that $X$ contains a set of $n$ linearly independent vectors, whereas any set of $n+1$ vectors is linearly dependent.
	In this case, $n$ is the \ul{dimension} of $X$.
	If $X$ is not finite dimensional, it is \ul{infinite dimensional}.
\end{definition}
\begin{note}
	$X = \set0$ has dimension 0.
\end{note}
\begin{corollary}
	Every finite dimensional vector space has a basis.
\end{corollary}

\begin{theorem}
	Every vector space has a basis (requires axiom of choice).
\end{theorem}

\ul{HW} 2.1: 3,4,6,7,10.

Last time: vector spaces and their (algebraic) properties.

To motivate definition of a norm on a vector space, consider $\mb R^2$.

\begin{definition}
	A normed vector space is a vector space $X$ with a norm $||\cdot||$ defined on it.
	A \ul{norm} $||\cdot||$ on a vector space $X$ is a real-valued function on $X$, with values denoted by $||x||$, which satisfies:
	\begin{itemize}
		\item[N1)] $||x||\geq 0$
		\item[N2)] $||x||=0$ if and only if $x=0$
		\item[N3)] $||\alpha x|| = |\alpha|\,||x||$ for all $x\in X$, for all $\alpha\in K$
		\item[N4)] $||x+y||\leq ||x||+||y||$ for all $x,y\in X$ (Triangle inequality).
	\end{itemize}
\end{definition}
\begin{note}
	The norm defines a metric on $X$ by $d(x,y) = ||x-y||$.
\end{note}
\begin{example}
	[$\mb R^3$ with Euclidean norm] For $x=(\xi_1,\xi_2,\xi_3)$, $||x||=\sqrt{\xi_1^2+\xi_2^2+\xi_3^2}$.
\end{example}
\begin{example}
	[$\mb R^n$] For $x=(\xi_1,\dots,\xi_n)$, define $||x||_2 = \sqrt{\sum_{i=1}^n \xi_i^2}$.
\end{example}
\begin{example}
	[$X = C{[}a,b{]}$] For $x=x(t)$, define $\displaystyle||x|| = \max_{a\leq t\leq b}|x(t)|$.
	Notation: this is also denoted $||\cdot||_\infty$.
\end{example}
\begin{example}
	[$X = \ell^\infty$] For $x = (\xi_i)_{i=1}^\infty$, define norm $||x|| = \sup\setc{|\xi_i|}{i=1,\dots}$.
\end{example}

\begin{definition}
	A sequence of vectors $(x_n)_{n=1}^\infty$ in a normed vector space $X$ is \ul{convergent} if there exists $x\in\mb X$ such that $\lim_{n\ra\infty}||x_n-x||=0$.
	Notation: we write $x_n\ra x$.
\end{definition}

\begin{recall}
	$\displaystyle\lim_{n\ra\infty} ||x_n-x||=0$ means: for every $\epsilon>0$, there exists $N>0$ such that if $n\geq N$, then $||x_n-x||<\epsilon$.
\end{recall}

\begin{definition}
	A sequence of vectors $(x_n)_{n=1}^\infty$ is \ul{Cauchy} if for every $\epsilon>0$, there exists $N>0$ such that if $m,n>N$, then $||x_m-x_n||<\epsilon$.
\end{definition}
\begin{definition}
	A normed vector space is \ul{complete} if every Cauchy sequence in $X$ is convergent in $X$.
\end{definition}
\begin{definition}
	A complete normed vector space is called a \ul{Banach space}.
\end{definition}

\begin{example}
	[$X = \mb R^n$, with Euclidean norm $||\cdot ||_2$] For $x=(\xi_1,\dots,\xi_n)$, $||x||_2 = \sqrt{\sum_{i=1}^n \xi_i^2}$ is a norm. N1-N3 easy.
	For $x,y=(\eta_1,\dots,\eta_n)$.
	To show $||x+y|| \leq ||x||+||y||$, show
	\begin{align*}
		||x+y||^2 &\leq (||x||+||y||)^2 = ||x||^2 + ||y||^2 + 2 ||x||\,||y||. \\
		||x+y||^2 &= \sum_{i=1}^n (\xi_i+\eta_i)^2 
				  = \sum_{i=1}^n (\xi_i^2 + \eta_i^2 + 2\xi_i\eta_i) \\
				  &= \sum_{i=1}^n \xi_i + \sum_{i=1}^n \eta_i + 2\sum_{i=1}^n \xi_i\eta_i
				  = ||x||^2 + ||y||^2 + 2\sum_{i=1}^n \xi_i\eta_i \\
				  &\leq ||x||^2 + ||y||^2 + 2\sum_{i=1}^n |\xi_i\eta_i| \qquad \text{Cauchy-Schwarz ineqaulity}\\
				  &\leq ||x||^2 + ||y||2 + 2\sqrt{\sum_{i=1}^n|\xi_i|^2} \sqrt{\sum_{i=1}^n|\eta_i|^2} \\
				  &= ||x||^2 + ||y||^2 + 2||x||\cdot||y|| = (||x||+||y||)^2
	\end{align*}
	To show $\mb R^n$ is complete with this norm:
	Let $(x_m)_{m=1}^\infty$ be a Cauchy sequence in $\mb R^n$.
	Notation: $x_m = (\xi_1^m,\dots,\xi_n^m)$.
	Let $\epsilon>0$. There $\exists N>0$ such that if $m,r>N$, then $||x_m-r_r||<\epsilon$.
	So $||x_m-x_r||^2 < \epsilon^2$.
	So $\sum_{i=1}^n (\xi_i^m-\xi_i^r)^2 < \epsilon^2$ $(*)$.
	For each $i$, $(\xi_i^m-\xi_i^r)^2<\epsilon^2$, so $|\xi_i^m-\xi_i^r|<\epsilon$.
	So $(\xi_i^m)_{m=1}^\infty$ is a Cauchy sequence of real numbers, here convergent since $\mb R$ is complete.
	Thus $\lim_{m\ra\infty} \xi_i^m = \xi_i$ for each $i$.
	Define $x = (\xi_1,\dots,\xi_n)$.
	Let $r\ra\infty$ in $(*)$ to get $\sum_{i=1}^n(\xi_i^m-\xi_i)^2\leq\epsilon^2$ and $||x^m-x||^2 \leq \epsilon^2$ and $||x^m-x||\leq \epsilon$.
	Thus $x_m\ra x$.
\end{example}

\ul{HW} 2.2: 6,10

Last time: normed vector spaces, $\mb R^n$ is complete.

Define vector space $s = $ set of all sequences (bounded or unbounded).
$x\in s$, $x=(\xi_1,\xi_2,\dots)$ or $x=(\xi_i)_{i=1}^\infty$.
Can define a metric by $$d(x,y) = \sum_{i=1}^\infty \frac1{2^i} \frac{|\xi_i-\eta_i|}{1+|\xi_i-\eta_i|},$$ where $x = (\xi_i)_{i=1}^\infty,y=(\eta_i)_{i=1}^\infty$.
Is there a norm $||\cdot||$ on $S$ such that $d(x,y) = ||x-y||$ for all $x,y\in S$.

\begin{theorem}
	[Translation Invariance] On vector space $X$, a metric $d$ induced by a norm is translation invariant: $d(x+a,y+a)=d(x,y)$ and $d(\alpha x,\alpha y) = |\alpha|d(x,y)$ for all $x,y,a\in X$, and all scalar.
\end{theorem}
\begin{proof}
	Let $x,y,a\in X$ and $\alpha$ scalar.
	$d(x+a,y+a) = ||(x+a)-(y+a)|| = ||x-y|| = d(x,y)$ and
	$d(\alpha x -\alpha y) = ||\alpha x-\alpha y|| = ||\alpha(x-y)|| = |\alpha|\ ||x-y|| = |\alpha| d(x,y)$.
\end{proof}

HW: Show metric $d$ on $s$ is not induced by any norm.

\begin{recall}
	[$\displaystyle X = \ell^\infty = \setc{x=(\xi_i)_{i=1}^\infty}{\sup_{1\leq i\leq\infty}|\xi_i|<\infty}$]
	Can define norm by $\displaystyle||x||_\infty = \sup_i|\xi_i|$.
	$\ell^\infty$ with this norm is complete, hence a Banach space.
\end{recall}
\begin{example}
	[$X = C{[}a,b{]}$]
	Define a norm on $X$ by $\displaystyle||x(t)||_\infty = \max_{a\leq t\leq b}|x(t)|$.
	Can check this is a norm. $C[a,b]$ with $||\ ||_\infty$ is complete (HW grad).
\end{example}
\begin{example}
	[$X = C{[}a,b{]}$] Define a norm on $X$ by $||x||_1 = \int_a^b|x(t)|\,dt$.
	Can check this is a norm.
	Claim: $C[a,b]$ with $||\ ||_1$ is not complete.
	To show this, we must demonstrate a sequence of functions $(x_n)_{n=1}^\infty$ in $C[a,b]$ which is Cauchy in $||\cdot ||_1$, but $(x_n)_{n=1}^\infty$ does not converge to any $x\in X$.
Take $X = C[0,1]$. Define $x_n(t) \begin{cases} 0 & 0\leq t\leq 1/2 \\ nt-\frac n2 & \frac12 \leq t \leq \frac12+\frac1n \\ 1 & \frac12+\frac1n\leq t\leq 1 \end{cases}$.
		Consider $\displaystyle||x_n-x_m||_1 = \int_0^1|x_n(t)-x_m(t)|\,dt \leq \frac12\cdot\frac1N$ for $n,m\geq N$.
		Given $\epsilon>0$, set $N>\frac1{2\epsilon}$.
		If $n,m\geq N$, then $||x_n-x_m||\leq\frac1{2N}<\epsilon$.
		Clearly $(x_n)_{n=1}^\infty$ is Cauchy in $||\,||_1$.
		Can we have $x_n\ra x$ for some $x(t)\in C[a,b]$?
		If so, then $||x_n-x||_1\ra 0$ but $$||x_n(t)-x(t)||_1 = \int_0^\frac12 |x(t)|\, dt + \int_\frac12^{a_n} |x_n(t)-x(t)|\,dt + \int_{a_n}^1 |1-x(t)|\,dt$$ must have $\lra 0$ as $n\ra\infty$.
		This implies $\int_0^\frac12|x(t)|\,dt=0$, so $x(t)=0$ for $0\leq t<\frac12$ and $\int_\frac12^1 |1-x(t)|\, dt = 0$, so $x(t) = 1$ for $\frac12<t\leq 1$.
		Can't have $x(t)\in C[0,1]$.
\end{example}
\begin{example}
	Similar for $X=C[a,b]$ with $||\cdot||_2,||\cdot||_p,p\geq 1$.
	$\displaystyle ||x||_p = \plr{\int_a^b|x(t)|^p\,dt}^\frac1p$.
\end{example}

\begin{definition}
	A subspace $Y$ of a normed vector space $X$ is \ul{closed} whenever $(x_n)_{n=1}^\infty$ is a sequence in $Y$ with $x_n\ra x$, then $x\in Y$.
\end{definition}
\begin{theorem}
	Let $X$ be a Banach space.
	A subspace $Y$ of $X$ is complete if and only if $Y$ is closed.
\end{theorem}
\begin{proof}
	\ul{$\implies$}$|$ Suppose $Y$ is complete subspace of $X$. Let $(x_n)_{n=1}^\infty$ be a sequence in $Y$, and suppose $x_n\ra x\in X$. Since $x_n\ra x$ in $X$, then $(x_n)_{n=1}^\infty$ is Cauchy in $X$. Thus $(x_n)_{n=1}^\infty$ is Cauchy in $Y$.
	Because $Y$ is complete, $(x_n)$ converges in $Y$. Thus $x\leq y$, so $Y$ is closed.

	\ul{$\Lla$}$|$ Suppose $Y$ is closed. Let $(x_n)_{n=1}^\infty$ be a Cauchy sequence in $Y$. Then $(x_n)_{n=1}^\infty$ is Cauchy in $X$, hence converges in $X$, say $x_n\ra x\in X$. Since $Y$ is closed, we ahve $x\in Y$.
	Thus $Y$ is complete.
\end{proof}

\begin{recall}
	For $x = (x_1,x_2)\in\mb R^2$, $||x||_2 = \sqrt{x_1^2+x_2^2}$ and $||x||_\infty = \max\set{|x_1|,|x_2|}$.
	So $$S_2 = \setc{x\in\mb R^2}{||x||_2 = 1} = \setc{(x_1,x_2)}{x_1^2+x_2^2=1}$$ 
	and $$S_\infty = \setc{x\in\mb R^2}{||x||_\infty=1} = \setc{(x_1,x_2)}{|x_1|=1\text{ or }|x_2|=1}.$$
\end{recall}

\begin{definition}
	Let $X$ and $Y$ be normed spaces.
	A mapping $T:X\ra Y$ is an \ul{isometry} if it preserves length: that is, if $||Tx||_Y = ||x||_X$ for all $x\in X$.
	If $T$ is also an isomorphism, then we say $X$ and $Y$ are \ul{isomorphically isometric} i.e., they are the \say{same.}
\end{definition}

\begin{theorem}
	Let $X$ be a normed space.
	Then there exists a completion of $X$.
\end{theorem}

\begin{lemma}
	Let $\set{x_1,x_2,\dots,x_n}$ be linearly independent in a normed vector space $X$.
	Then there exists $c>0$ such that for every set of scalars $\set{\alpha_1,\dots,\alpha_n}$ we have $(*)$ $||\alpha_1x_1+\alpha_2x_2+\dots+\alpha_nx_n|| \geq c(|\alpha_1|+\dots+|\alpha_n|)$.
\end{lemma}
\begin{proof}
	Set $s = |\alpha_1|+\dots+|\alpha_n|$. If $s=0$, then $(*)$ always holds for any $c>0$.
	So let $s>0$. Instead of $(*)$ consider $(**)$ $||\beta_1x_1+\beta_2x_2+\dots+\beta_nx_n||\geq c$ for all $\sum_{j=1}^n|\beta_j| = 1$, where $\beta_j = \frac{\alpha_j}s$.

	BWOC, suppose $(**)$ not true for all scalars such that $\sum_{j=1}^n|\beta_j| = 1$.
	Thus there is exists a sequence $(y_n)_{m=1}^\infty$, $y_m = \beta_1^m x_1 + \beta_2^m x_2 + \dots + \beta_n^m x_n$, with $\sum_{j=1}^n|\beta_j^m| = 1$, and $||y_m||\ra0$ as $m\ra 0$.
	We have
	\begin{align*}
		y_1 &: \beta_1^1, \beta_2^1,\dots,\beta_n^1 \\
		y_2 &: \beta_1^2, \beta_2^2,\dots,\beta_n^2 \\
			&\vdots \\
		y_m &: \beta_1^m,\beta_2^m,\dots,\beta_n^m \\
			&\vdots
	\end{align*}
	Notice $|\beta_j^m|\leq 1$ for all $m,j$. The sequence $(\beta_1^m)_{m=1}^\infty$ is bounded, hence has a convergent subsequence, $(\beta_1^{m,1})$, and $\beta_1^{m,1}\ra\beta_1$.
	There is a subsequence $(y_{1,m})$.
	Next consider $(\beta_2^{m,1})$.
	Similarly it has convergent subsequence $\beta_2^{m,2}$ and $\beta_2^{m,2}\ra\beta_2$.
	Also $\beta_1^{m,2}\ra\beta_1$. (Bolzano-Weierstrass theorem) Repeat for each index, getting subsequence of the previous subsequence.
	Get a subsequence $(y_{n,m})_{m=1}^\infty$ of $(y_m)$ such that $y_{n,m} = \gamma_1^mx_1 + \gamma_2^mx_2 + \dots + \gamma_n^mx_n$ and $\sum_{j=1}^n|\gamma_j^m|=1$ and $\lim_{m\ra\infty}\gamma_j^m = \beta_j$.
	Define $y = \beta_1x_1+\beta_2x_2+\dots+\beta_nx_n$.
	Thus $y_{n,m}\ra y$, where $\sum_{j=1}^n |\beta_j| = 1$.
	But $||y_{n,m}||\ra0$, and $||y||\neq0$ contradiction.
\end{proof}

\begin{theorem}
	Every finite dimensional subspace $Y$ of normed space $X$ is complete and closed.
\end{theorem}
\begin{corollary}
	Every finite dimensional normed space is a Banach space.
\end{corollary}

There are things that happen in infinite dimensional spaces that don't happen in finite dimensional spaces. For example, every finite dimensional vector space is complete; but not all infinite dimensional ones.

\ul{HW 2.3}: 1,3,10, G2;
\ul{HW 2.4}: 1,2,8, G6.

Last time: Every finite dimensional normed space is complete.
Use Lemma:
If $\set{x_1,\dots,x_n}$ is linearly independent in $X$, then $\exists c>0$ such that $||\alpha_1x_1+\dots+\alpha_nx_n|| \geq c(|\alpha_1|+\dots+|\alpha_n|)$.

\begin{definition}
	Let $X$ be a vector space, and let $||\cdot||$ and $||\cdot||_0$ be two norms on $X$.
	The norms are said to be \ul{equivalent} if there are positive numbers $a,b$ such that $\forall x\in X$ we have $a||x||_0 \leq ||x|| \leq b||x||_0$.
\end{definition}
\begin{remark}
	Note that $a||x||_0 \leq ||x||\leq b||x||_0 \implies \frac1b||x||\leq ||x||_0 \leq \frac1a||x||$ and $||x_n-x||\ra0$ implies $||x_n-x||_0\ra 0$ + vice versa.
\end{remark}
\begin{theorem}
	Let $X$ be a finite dimensional vector space.
	If $||\cdot||,||\cdot||_0$ are norms on $X$, they are equivalent.
\end{theorem}
\begin{proof}
	Let $X$ be finite dimensional and let $||\cdot||,||\cdot||_0$ be norms on $X$.
	Sufficient to show $\exists$ constants $c_1,c_2>0$ such that \ul{$||x||_0\leq c_1||x||$} and $||x||\leq c_2||x||_0$ for all $x\in X$.
	Let $\set{x_1,\dots,x_n}$ be a basis for $X$.
	Set $k = \max\setc{||x_j||_0}{j=1,\dots,n}>0$ and let $c>0$ be given by the Lemma in $||\cdot||$.
	Let $x\in X$. Then $x = \alpha_1x_1+\dots+\alpha_nx_n$.
	Then 
	\begin{align*}
		||x||_0 &= ||\alpha_1x_1+\dots+\alpha_nx_n||_0 \leq |\alpha_1|\,||x_1||_0 + \dots + |\alpha_n|\,||x_n||_0 \leq k(|\alpha_1|+\dots+|\alpha_n|) \\
				&\leq \frac kc||\alpha_1x_1+\dots+\alpha_nx_n|| \leq \frac kc||x|| = c_1||x||
	\end{align*}
	Similar argument shows that $||x||\leq c_2||x||_0$.
\end{proof}
\begin{example}
	An example of normed space with two norms that are not equivalent.
	We know it must be infinite dimensional by last result.
	$X = C[a,b]$ with norms $||\cdot||_\infty$ and $||\cdot||_1$.
	Not equivalent, $X$ with $||\cdot||_\infty$ is complete (Banach space) but $X$ with $||\cdot||_1$ is not complete.
\end{example}

\newpage

\begin{definition}
	A subset $M$ of a normed space (or metric space) $X$ is \ul{compact} if every sequence in $M$ has a subsequence that converges in $M$.
\end{definition}
\begin{lemma}
	A compact set $M$ is closed and bounded.
	Converse is not true in general, but it is true for compact subsets of $\mb R$ by Bolzano-Weierstrass theorem.
\end{lemma}
\begin{theorem}
	Let $X$ be a finite dimensional normed space.
	A subset $M$ is compact if and only if $M$ is closed and bounded.
\end{theorem}
\begin{example}
	A subset $M$ of a normed space which is closed and bounded, but not compact.
	Let $X = \ell^2$ with $||\cdot||_2$.
	Set 
	\begin{align*}
		e_1 &= (1,0,0,\dots) = (\delta_{1j})_{j=1}^\infty \\
		e_2 &= (0,1,0,\dots) = (\delta_{2j})_{j=1}^\infty \\
		e_n &= (\delta_{nj})_{j=1}^\infty
	\end{align*}
	$M = \set{e_1,e_2,\dots}$ is bounded because $||e_n||=1$ for $n=1,\dots$.
	Also $||e_m-e_n|| = \sqrt2$ for all $m\neq n$.
	So $M$ is closed, but $M$ is not compact.
	That is, $(e_n)_{n=1}^\infty$ is a sequence in $M$ with no convergent subsequence.
\end{example}

Last time: compact sets,,
\begin{itemize}
	\item a compact set is closed + bounded
	\item converse is true in finite dimensional noremd space
\end{itemize}

\begin{theorem}
	[Riesz Lemma]
	Let $Y,Z$ be subspaces of normed space $X$, and suppose $Y$ is a closed proper subspace of $Z$.
	Then for every $\theta\in(0,1)$ there exists $z\in Z$ such that $||z||=1$ and $||z-y||\geq\theta$ for all $y\in Y$.
\end{theorem}
\begin{proof}
	Let $\theta\in(0,1)$. Let $v\in Z\bs Y$. Let $\ds a = \inf_{y\in Y}||v-y||$.
	We know $a>0$ because if $a=0$, there exists a sequence $(y_n)_{n=1}^\infty$ in $Y$ such that $||v-y||\ra0$. 
	Thus $y_n\ra v$, which implies $v\in Y$ because $Y$ is closed. But $v\notin Y$, so $a\neq 0$.
	There exists $y_0\in Y$ such that $\ds a<||v-y_0||\leq \frac a\theta$.
	Such a vector exists, otherwise the $\ds \inf_{y\in Y}||v-y||\geq \frac a\theta$.
	Set $z = c(v-y_0)$, where $\ds c=\frac1{||v-y_0||}$.
	Then $z\in Z$ and $||z||=1$.
	For any $y\in Y$ we have 
	\begin{align*}
		||z-y|| &= ||c(v-y_0)-y||
				= c||v-y_0-\frac1cy||
				= c||v-y_1||,
	\end{align*}
	where $\ds y_1 = y_0+\frac1cy\in Y$, so $y_1\in Y$.
	So
		$$||z-y|| = c||v-y_1|| 
				\geq c\cdot a 
				= \frac a{||v-y_0||} 
				\geq a\cdot\frac\theta a = \theta$$
	implies $||z-y||\geq\theta$.
\end{proof}
\ul{HW} 2.5: 7

\begin{theorem}
	Let $X$ be a normed space. Then $X$ is finite dimensional if and only if the closed unit ball $M = \setc{x\in X}{||x||\leq 1}$ is compact.
\end{theorem}
\begin{proof}
	\ul{$\implies$}$\mid$ Suppose that $X$ is finite dimensional.
	Then $M$ is closed and bounded, hence compact by previous result.

	\ul{$\La$}$\mid$ Suppose $M$ is compact. BWOC, suppose $X$ is infinite dimensional.
	Pick $x_1\in $ such that $||x_1||=1$, and set $X_1=\spn\set{x_1}$.
	By Riesz's lemma, there exists $x_2\in X$ such that $||x_2||=1$ and $||x_2-x||\geq\frac12$ for all $x\in X_1$.
	In particular, $||x_2-x_1||\geq\frac12$.
	Set $X_2 = \spn\set{x_1,x_2}$.
	By Riesz lemma again, there exists $x_3\in X\bs X_2$ such that $||x_3||=1$ and $||x_3-x_2||\geq\frac12$ for all $x\in X_2$.
	In particular, $||x_3-x_2||\geq\frac12$ and $||x_3-x_1||\geq\frac12$.
	Continue process by induction to get sequence $(x_n)_{n=1}^\infty$ in $M$.
	This cannot have a convergent subsequence because $||x_m-x_n||\geq\frac12$ for all $m,n$.
	Contradiction to $M$ being compact.
\end{proof}

\subsection*{Linear Operators}

\begin{definition}
	A \ul{linear operator} $T$ is a mapping such that
	\begin{enumerate}
		\item[i)] the domain $\ms D(T)$ is a vector space and the range $\ms R(T)$ lies in a vector space with same field of scalars.
		\item[ii)] for all $x,y\in \ms D(T)$, and scalars $\alpha$, $T(x+y) = Tx+Ty$ and $T(\alpha x) = \alpha Tx$.
	\end{enumerate}
\end{definition}
\begin{definition}
	The \ul{null space} of $T$, denoted $\ms N(T)$, is $N(T) = \setc{x\in \ms D(T)}{Tx=0}$.
\end{definition}
\begin{theorem}
	Let $T:\ms D(T)\subset X\ra Y$ be a linear operator from $X$ into $Y$. Then
	\begin{enumerate}
		\item[a.] $\ms R(T)$ is a subspace of $Y$.
		\item[b.] If $\dim\ms D(T)=n<\infty$, then $\dim\ms R(T)\leq n$.
		\item[c.] $\ms N(T)$ is a subspace of $X$.
	\end{enumerate}
\end{theorem}
\begin{example}
	For any vector space $X$, the identity operator $I$ and zero operator $T=0$ (that is, $Tx=0$ for all $x\in X$) are linear operators.
\end{example}
\begin{example}
	[$X=\Cb{}ab$] The integral operator $T:X\ra X$,
	$$(Tx)(t) = \int_a^tx(s)\,ds.$$
	The differential operator $T:\ms D(T)\subset X\ra X$,
	$$ (Tx)(t) = x'(t).$$
	But $\ms D(T) = \setc{x(t)\in \Cb{}ab}{x'(t)\in \Cb{}ab}$.
\end{example}

\begin{recall}
Last time: compactness + dimension.
Introduction to linear operators.
If $T:\ms D(T)\subset X\ra Y$, then
\begin{enumerate}
	\item[a.] $\ms R(t)$ is a vector space,
	\item[b.] If $\dim\ms D(T)=n<\infty$, then $\dim\ms R(T)\leq n$,
	\item[c.] $\ms N(T)$ is a vector space.
\end{enumerate}
\end{recall}
\begin{proof}
	[Proof of b.]
	Assume $\dim\ms D(T)=n<\infty$.
	From part a., $\ms R(T)$ is a vector space.
	To show $\dim\ms R(T)\leq n$,
	it is sufficient to show that every set of $n+1$ vectors in $\ms R(T)$ is linearly dependent.
	Let $\set{y_1,\dots,y_{n+1}}$ be any vectors in $\ms R(T)$.
	Then $\exists x_1,\dots,x_{n+1}\in\ms D(T)$ such that $Tx_j = y_j$ for $j=1,\dots,n+1$.
	Since $\dim\ms D(T) = n$, the set $\set{x_1,\dots,x_{n+1}}$ is linearly dependent.
	Thus there exist scalars $\alpha_1,\dots,\alpha_{n+1}$, not all zero, such that $\alpha_1x_1+\dots+\alpha_{n+1}x_{n+1} = 0$.
	So 
	\begin{align*}
		T(\alpha_1x_1+\dots+\alpha_{n+1}x_{n+1}) &= T0 = 0 \\
		\alpha_1Tx_1 +\dots+ \alpha_{n+1}Tx_{n+1} &= 0 \\
		\alpha_1y_1 + \dots + \alpha_{n+1}y_{n+1} &= 0
	\end{align*}
	So $\set{y_1,\dots,y_{n+1}}$ is linearly dependent.
\end{proof}

\begin{example}
	For $X=\mb R^n$ and $Y=\mb R^m$, any $m\times n$ matrix defines a linear operator from $X$ to $Y$ by matrix multiplication $Tx=Ax$.
\end{example}
\begin{definition}
	Let $T:\ms D(T)\subset X\ra Y$ be 1-1.
	Then the \ul{inverse operator} $T\inv:\ms R(T)\subset Y\ra X$ is defined by $T\inv y=x$ if $Tx=y$.
\end{definition}
\begin{theorem}
	Let $X,Y$ be vector spaces, and let $T:\ms D(T)\subset X\ra Y$ be a linear operator.
	\begin{enumerate}
		\item[a)] $T\inv$ exists if and only if $Tx=0$ implies $x=0$.
		\item[b)] If $T\inv$ exists, it is a linear operator.
		\item[c)] If $\dim\ms D(T)=n<\infty$, and $T\inv$ exists, then $\dim\ms R(T)=n$.
	\end{enumerate}
\end{theorem}
\begin{note}
	If $T:X\ra Y$ and $S:Y\ra Z$ are invertible and $ST:X\ra Z$ is defined, then $(ST)\inv = T\inv S\inv$.
	(like inverse of product of two invertible square matrices)
\end{note}
So far, the discussion has been algebraic.
Next we introduce norms + linear operators.

\newpage

\begin{definition}
	Let $X,Y$ be normed spaces, and let $T:\ms D(T)\subset X\ra Y$ be a linear operator.
	$T$ is \ul{bounded} if there exists $c\geq0$ such that $||Tx|| \leq c||x||$ for all $x\in\ms D(T)$.
\end{definition}
\begin{definition}
The \say{smallest $c$ that works} is called the \ul{norm} of $T$, denoted $||T||$.
For $x\neq0$, we have $\frac{||Tx||}{||x||}\leq c$ for all $x\in\ms D(T),x\neq0$.
So $$||T|| = \sup_{\us{x\neq0}{x\in\ms D(T)}}\frac{||Tx||}{||x||}.$$
\end{definition}
Alternatively, $$ ||T|| = \sup_{\us{x\neq0}{x\in\ms D(T)}}\frac{||Tx||}{||x||} = \sup_{\us{x\neq0}{x\in\ms D(T)}} \mlr{\mlr{T\plr{\frac x{||x||}}}} = \sup_{\us{||y||=1}{y\in\ms D(T)}}||Ty|| = \sup_{\us{||x||=1}{x\in\ms D(T)}}||Tx||.$$
\begin{note}
	It follows that if $T$ is bounded, then $||Tx|| \leq ||T||\,||x||$.
\end{note}
\begin{note}
	$||T||$ satisfies properties of  norm, and is a norm on the vector space of all bounded linear operators from $X$ to $Y$.
\end{note}
\begin{example}
	Identity operator $||I|| = 1$. zero operator $||0||=0$.
\end{example}
\begin{example}
	$T:\mb R^n\ra\mb R^m$ by $Tx=Ax$, where $A$ is $m\times n$ matrix.
	For any norms on $\mb R^m$ and $\mb R^n$, $T$ is a bounded linear operator.
\end{example}
\begin{example}
	[$X = C{[}0,1{]}$ with $||\cdot||_\infty$]
	Let $K(t,\tau)$ be continuous on $[0,1]\times[0,1]$. So $\exists K_0\geq 0$ such that $|K(t,\tau)|\leq K_0$ for all $t,\tau\in[0,1]$.
	Define $T:X\ra X$ by $(Tx)(t) = \int_0^t K(t,\tau)X(\tau)\,d\tau$.
	Can show $T$ is linear. Also $T$ is bounded because 
	\begin{align*}
		|| Tx||_\infty = \sup_{0\leq t\leq1}\mlr{\int_0^t K(t,\tau)x(\tau)\,d\tau}
		&\leq \sup_{0\leq t\leq 1}\int_0^t |K(t,\tau)|\,|x(\tau)|\,d\tau \\
		&\leq \sup_{0\leq t\leq 1}\int_0^t K_0||x||\,d\tau
					   = \sup_{0\leq t\leq 1}K_0||x||t
					   = K_0||x||_0
	\end{align*}
	So $||T||\leq K_0$.
\end{example}
\begin{example}
	[$X = C{[}0,1{]}$ with $||\cdot||_\infty$]
	$\ms D(T) = C^1[0,1]$.
	$(Tx)(t) = x'(t)$.
	Consider $x_n(t) = t^n$.
	Then $||x_n||=1$ for $n=1,2,\dots$
	but $||Tx_n||_\infty = ||nt^{n-1}||=n$.
	So there is  no $c$ such that $\frac{||Tx_n||}{||x_n||}\leq c$ for all $n$.
	So $T$ is unbounded.
\end{example}
\ul{HW} 2.6: 2,3,5,11; grad 14,15.

Let $x=(x_1,\dots,x_n)\in\mb R^n$.
$$\frac1{\sqrt n} ||x||_1 \leq ||x||_2 \iff \frac1{\sqrt n}(|x|_1+\dots+|x_n|)\leq\sqrt{|x_1|^2+\dots+|x_n|^2} \iff (|x_1|+\dots+|x_n|)^2 \leq n(|x_1|^2 + \dots + |x_n|^2) $$
See problem 1.2.3.
Case $n=2$: $(|x_1|+|x_2|)^2\leq2(|x_1|^2+|x_2|^2)$.
Observe: $\pm 2ab\leq a^2+b^2$ for all $a,b\in\mb R$ because $0\leq (a+b)^2$ and $0\leq(a-b)^2$.
For $n=2$, $(|x_1|+|x_2|)^2 = |x_1|^2+|x_2|^2+2|x_1|\,|x_2| \leq 2(|x_1|^2+|x_2|^2) \checkmark$.
For general $n$, by induction.
Assume for $n=k$:
$$(\norm{}xk)^2\leq k(|x_1|^2+\dots+|x_k|^2)$$
For $n=k+1$:
\begin{align*}
	(|x_1|+\dots+|x_k|+|x_{k+1}|)^2 &= (|x_1|+\dots+|x_k|)^2 + |x_{k+1}^2| + 2(|x_1|+\dots+|x_k|)|x_{k+1}| \\
									&\leq k(|x_1|+\dots+|x_k|)+|x_{k+1}|^2 + 2|x_1|\,|x_{k+1}| + \dots + 2|x_k|\,|x_{k+1}| \\
									&\leq k(|x_1|^2+\dots+|x_k|^2)+|x_{k+1}|^2+(|x_1|^2+|x_{k+1}|^2)+\dots+(|x_k|^2+|x_{k+1}|^2) \\
									&= k(|x_1|^2+\dots+|x_k|^2)+(|x_1|^2+\dots+|x_k|^2) + (k+1)|x_{k+1}|^2 \\
									&= (k+1)(|x_1|^2+\dots+|x_k|^2) + (k+1)|x_{k+1}|^2 \\
									&= (k+1)(|x_1|^2+\dots+|x_{k+1}|^2)\,\checkmark
\end{align*}

Last time: Bounded linear operators examples, examples of an unbounded linear operator.

\begin{example}
	[$X=\ell^\infty$ with $||\cdot||_\infty$]
	Given $x=(\xi_1,\xi_2,\dots)\in\ell^\infty$, define $Tx = (\xi_2,\xi_3,\dots)$ \say{left shift operator.}
	Easy to show $T$ is linear, $\ms D(T)=X$, so $T:X\ra X$.
	Also $||Tx||_\infty = \sup\set{|\xi_i|}_{i=2}^\infty\leq||x||_\infty$.
	This implies $T$ is bounded and $||T||\leq1$.
	Actually $||T||=1$, since for example, for $x=(0,2,0,\dots)$
	$$\nlrp{Tx}\infty = \nlrp{(2,0,0,\dots)}\infty = 2 = \nlrp x\infty.$$
	Thus it can't be possible for $||T||<1$.
\end{example}

\begin{theorem}
	Let $T:\ms D(T)\subset X\ra Y$ be a linear operator. If $X$ is finite dimensional, then $T$ is bounded.
\end{theorem}
\begin{recall}
	To show $T$ is bounded, show there is a constant $C$ such that $||Tx||\leq C||x||$ for all $x\in\ms D(T)$.
\end{recall}
\begin{recall}
	$\exists c>0$ such that for any scalars $\xi_1,\dots,\xi_n$, we have $||\xi_1e_1+\dots+\xi_ne_n||\geq c(|\xi_1|+\dots+|\xi_n|)$.
\end{recall}
\begin{proof}
	Assume $T$ is linear, $X,Y$, are normed spaces, and $X$ is finite dimensional.
	Let $n$ be the dimension of $X$ and $\set{e_1,\dots,e_n}$ be a basis for $X$.
	Let $B = \max\set{||Te_1||,\dots||Te_n||}$.
	Let $x\in\ms D(T)$. Then $x=\xi_1e_1+\dots+\xi_ne_n$ for some scalars $\xi_1,\dots,\xi_n$.
	Then 
	\begin{align*}
		||Tx|| &= ||T(\lc n\xi e)|| \\
			   &\leq \nlr{\lc n\xi{Te}}
			   \leq |\xi_1|\,||Te_1||+\dots+|\xi_n|\,||Te_n|| \\
			   &\leq B(|\xi_1+\dots+\xi_n|)
			   \leq \frac Bc\nlr{\lc n\xi e}
			   = \frac Bc||x||
	\end{align*}
	Thus $||Tx||\leq\frac Bc||x||$ for all $x\in\ms D(T)$.
	So $T$ is bounded.
\end{proof}

\begin{definition}
	Let $T:\ms D(T)\subset X\ra Y$ be any operator (not necessarily linear), where $X$ and $Y$ are normed vector spaces.
	We say $T$ is continuous at $x_0\in\ms D(T)$ if for all $\epsilon>0$, there exists $\delta>0$ such that $x\in\ms D(T)$ and $||x-x_0||<\delta$, then $||Tx-Tx_0||<\epsilon$.
	A continuous operator is continuous at every $x\in\ms D(T)$.
\end{definition}
\begin{theorem}
	Let $T:\ms D(T)\subset X\ra Y$ be linear.
	Then
	\begin{enumerate}
		\item[a.] $T$ is continuous if and only if $T$ is bounded.
		\item[b.] If $T$ is continuous at one point $x_0\in\ms D(T)$, then $T$ is continuous on $\ms D(T)$.
	\end{enumerate}
\end{theorem}
\begin{proof}
	[Proof of a.]
	When $T=0$ clearly true, so assume $T\neq0$, so $||T||\neq0$.

	\ul{$\Lla$}$\mid|$ Assume $T$ is bounded, and $||T||\neq0$.
	Let $x_0\in\ms D(T)$. Let $\epsilon>0$. Set $\delta=\frac\epsilon{||T||}$.
	If $x\in\ms D(T)$ and $||x-x_0||<\delta$, then 
	\begin{align*}
		||Tx-Tx_0|| &= ||T(x-x_0)||
					\leq ||T||\cdot||x-x_0||
					< ||T||\cdot\delta
					= ||T||\cdot\frac\epsilon{||T||}=\epsilon.
	\end{align*}
	Thus $T$ is continuous at $x_0$.
	Since $x_0\in\ms D(T)$ is arbitrary, $T$ is continuous for every $x\in\ms D(T)$.
	
%	\ul{$\implies$}$\mid$ Next time.
%\end{proof}
%\begin{proof}
%	[Proof of a.]
%	\ul{$\Lla$}$\mid$ last time.
	\ul{$\implies$}$\mid$ Assume $T$ is continuous.
	Fix $x_0\in\ms D(T)$, so $T$ is continuous at $x_0$. Let $\epsilon=1$.
	Then there exists $\delta>0$ such that if $||x-x_0||\leq\delta$ then $||Tx-Tx_0||\leq1$.
	Let $y\in\ms D(T)$, $y\neq0$.
	Set $x=x_0+\frac\delta{||y||}y$. Then $||x-x_0|| = \mlr{\mlr{\frac\delta{||y||}y}}=\delta$.
	Thus $||Tx-Tx_0||\leq 1$. But observe
	\begin{align*}
		||Tx-Tx_0|| = ||T(x-x_0)||
					= \mlr{\mlr{T\plr{\frac\delta{||y||}}}}
					= \frac\delta{||y||}||Ty||
	\end{align*}
	So $\frac\delta{||y||}||Ty||\leq1$, so $||Ty||\leq\frac1\delta||y||$.
\end{proof}
\begin{recall}
	$T$ bounded $\iff \exists C$ such that $||Tx||\leq C||x||$ for all $x\in\ms D(T)$.
\end{recall}
\begin{proof}
	[Proof of b.] Suppose $T$ is continuous at $x_0$. By proof of \ul{$\implies$}$\mid$ in a., this implies $T$ is bounded.
	By \ul{$\Lla$}$\mid$ in a., this implies $T$ is continuous on all of $\ms D(T)$.
\end{proof}
\ul{HW} 2.7: 2,7,9. Grad 6 
\begin{corollary}
	Let $T:\ms D(T)\subset X\ra Y$ be bounded linear operator.
	\begin{enumerate}
		\item[a.] If $x_n\ra x$ and $x_n,x\in\ms D(T)$, then $Tx_n\ra Tx$.
		\item[b.] $\ms N(T)$ is closed.
	\end{enumerate}
\end{corollary}
\begin{proof}
	[Proof of a.] Assume $x_n\ra x$, $x_n,x\in\ms (D)T$, and $T$ bounded. Then
	\begin{align*}
		||Tx_n-Tx|| = ||T(x_n-x)||
					\leq ||T||\,||x_n-x||^{\ra0}.
	\end{align*}
	So $||Tx_n-Tx||\ra0$, so $Tx_n\ra Tx$.
\end{proof}
\begin{proof}
	[Proof of b.] Assume $T$ is bounded. Let $(x_n)_{n=1}^\infty$ be a sequence in $\ms N(T)$, and furthermore $x_n\ra x$ for $x\in X$.
	Thus $Tx_n\ra Tx$. But all $Tx_n=0$, $n=1,\dots$, so $Tx=0$. Thus $x\in\ms N(T)$, so $\ms N(T)$ is closed.
\end{proof}

\begin{definition}
	A \ul{linear functional} $f$ is a linear operator with domain $\ms D(f)\subset X$, where $X$ is a vector space, and with range space the field of scalars $\mb R$ or $\mb C$.
	Notation: use $f,g,h$.
\end{definition}
\begin{note}
	A linear functional is a linear operator.
\end{note}
\begin{definition}
	A \ul{bounded} \ul{linear functional} is a linear funcitonal which is a bounded linear operator.
\end{definition}
	Thus for a bounded linear functional we have:
\begin{itemize}
	\item $\exists c\geq 0$ such that $|f(x)|\leq c||x||$,
		so $\ds ||f|| = \sup_{\us{x\neq0}{x\in\ms D(f)}} \frac{|f(x)|}{||x||}
		= \sup_{\us{||x||=1}{x\in\ms D(f)}} |f(x)|. $
		\item $|f(x)| \leq ||f||\,||x||$.
\end{itemize}
\begin{example}
	[$X=\mb R^3$ with Euclidean norm] Fix $a=(\alpha_1,\alpha_2,\alpha_3)\in\mb R^3$.
	Define $f(x)$ for $x=(\xi_1,\xi_2,\xi_3)\in\mb R^3$ by $f(x) = x\cdot a = \xi_1\alpha_1+\xi_2\alpha_2+\xi_3\alpha_3$.
	Clearly $f$ is a linear functional.
	By theorem we know $f$ is bounded. We have: $|f(x)|=|x\cdot a|\leq ||x||\cdot||a||$ by Cauchy-Schwarz.
	This implies $||f||\leq||a||$. To show $||f||=||a||$, find $x$ such that $|f(x)|=||a||\,||x||$.
	Take $x=a$: $$|f(x)|=|f(a)| = a\cdot a = ||a||^2 = ||a||\,||a|| = ||a||\,||x||.$$
	Thus $||f||=||a||$.
\end{example}
\begin{example}
	[$X= C{[}a,b{]}$ with $||\cdot||_\infty$] Define $f(x)$ for $x(t)\in X$ by $f(x) = \int_a^bx(t)\,dt$.
	Clearly $f$ is a linear functional.
	To see if $f$ is bounded,
	\begin{align*}
		|f(x)| = \mlr{\int_a^bx(t)\,dt}
			   \leq \int_a^b|x(t)|\,dt
			   \leq \int_a^b||x||_\infty\,dt
			   = \fbox{$(b-a)$}\,||x||_\infty.
	\end{align*}
	Thus $f$ is bounded, $||f||\leq b-a$.
	To see that $||f||=b-a$, consider $x(t)\equiv 1$.
	Then $||x||_\infty=1$, and $|f(x)| = \mlr{\int_a^b1\,dt} = b-a = (b-a)||x||$.
	So $||f||=b-a$.
\end{example}
\begin{example}
	[$X = C{[}a,b{]}$ with $||\cdot||_\infty$] Fix $c\in[a,b]$.
	Define $f(x) = x(c)$ (point evaluation), $f$ is linear. Easy to show $f$ is bounded.
\end{example}
\begin{example}
	[$X = C{[}0,1{]}$ with $||\cdot||_1$]
	Then $||x||_1 = \int_0^1|x(t)|\,dt$. Recall this is a normed space, but not complete.
	Define linear functional by $f(x) = x(0)$. We claim $f$ is not bounded.
	(There is no constant $C$ such that $|f(x)|\leq C||x||_1$ for all $x$).
	Consider $$x_n(t) = \begin{cases} 0 & \frac1n\leq t\leq 1 \\ -nt+1 & 0\leq t\leq\frac1n \end{cases}.$$
	Then $|f(x_n)| = |x_n(0)| = 1$ for all $n=1,2,\dots$ and $||x_n||_1 = \int_0^1|x_n(t)|\,dt = \frac1{2n}$ for $n=1,2\dots$.
	There is no $C$ such that $|f(x_n)|=1\leq C\frac1{2n} = C||x_n||_1$ for all $n$.
\end{example}
\ul{HW} 2.8: 3, G6.

\newpage
Last time: examples of linear functionals.

\begin{example}
	[$X=\ell^2$] Fix $a = (\alpha_j)\in\ell^2$.
	So $\sum_{j=1}^\infty |\alpha_j|^2<\infty$. Define $f:X\ra\mb R$ or $\mb C$ by $f(x) = \sum_{j=1}^\infty \alpha_j\xi_j$, where $x=(\xi_j)$.
	Clearly $f$ is linear.
	$f$ is bounded because 
	\begin{align*}
		|f(x)| &= \mlr{\sum_{j=1}^\infty \alpha_j\xi_j}
			   \leq \sum_{j=1}^\infty |\alpha_j\xi_j| \\
		\text{Cauchy-Schwarz}	   &\leq \sqrt{\sum_{j=1}^\infty |\alpha_j|^2}\sqrt{\sum_{j=1}^\infty |\xi_j|^2} 
			   = ||a||_2\cdot ||x||_2
	\end{align*}
	Thus $f$ is bounded and $||f||\leq||a||_2$.
	Notice for $x=a$ we get $|f(a)| = ||a||_2\cdot ||a||_2$.
	So $||f||=||a||_2$. $\checkmark$
\end{example}

\begin{definition}
	Let $X$ be a vector space. The vector space $X^* = \setc{f}{f\text{ is a linear functional on }X}$ is called the \ul{algebraic dual space} of $X$.
	$X^*$ is a vector space. 
\end{definition}
	What about $(X^*)^*$? This is called the second algebraic dual space.
Fix $x\in X$. Define $g_x\in X^{**}$ by:
For any $f\in X^*$, define $g_x(f) = f(x)$.
Claim: $g_x$ is linear: for any $f_1,f_2\in X^*$, scalars $\alpha,\beta$,
\begin{align*}
	g_x(\alpha f_1+\beta f_2) = (\alpha f_1+\beta f_2)(x) 
							  = \alpha f_1(x) + \beta f_2(x) 
							  = \alpha g_x(f_1) + \beta g_x(f_2)
\end{align*}
This defines a mapping $C:X\ra X^{**}$ by $Cx = g_x$.
$C$ is a linear operator, called the canonical mapping.
Are there any elements of $X^{**}$ besides those in $\ms R(C)$?
If $X^{**} = \ms R(C)$, we say $X$ is algebraically reflexive.

Linear operators on finite dimensional vector spaces. 
Let $X,Y$ be finite dimensional vector spaces and let $T:X\ra Y$ be a linear operator.
Let $\mc E=\set{e_1,\dots,e_n}$ be a basis for $X$ and $\mc B = \set{b_1,\dots,b_r}$ be a basis for $Y$.
Let $x\in X$. Then $x = \sum_{i=1}^n \xi_ie_i$
$$ y = Tx = \sum_{j=1}^n \xi_k Te_k = \sum_{k=1}^n \xi_ky_k, $$
where $y_k= Te_k$.
On the other hand, $y$ and $y_k$ have unique representation in terms of basis $\mc B$
$$ y = \sum_{j=1}^r \eta_jb_j, \qquad y_k = Te_k = \sum_{j=1}^r \tau_{jk}bj $$
Thus:
\begin{align*}
	\sum_{j=1}^r \eta_jb_j = y = \sum_{k=1}^n \xi_ky_k 
						= \sum_{k=1}^n \xi_k\plr{\sum_{j=1}^r \tau_{jk}b_j} 
						= \sum_{j=1}^r \plr{\sum_{k=1}^n \xi_k\tau_{jk}}b_j
\end{align*}
Thus $\eta_j = \sum_{k=1}^n \xi_k\tau_{jk}$.
Define matrix $T_{EB} = (\tau_{jk})_{r\times n}$.
Set $\tilde x = \pmat{\xi_1\\\vdots\\\xi_n}$, $\tilde y = \pmat{\eta_1\\\vdots\\\eta_r}$, then $\tilde y = T_{EB}\tilde x$.

\begin{example}
	[2.3-2] Let $(x_k)$ be a sequence in $c_0$, $x_k=(\xi_j^k)_{j=1}^\infty$ where $\xi_j^k\ra0$ as $j\ra\infty$.
	Suppose $x_k\ra x$ in $\ell^\infty$, $x=(\xi_j)_{j=1}^\infty$, that is $||x_k-x||_\infty\ra0$.
	Show $x\in c_0$. That is, show $\xi_j\ra 0$.
	Let $\epsilon >0$...
\end{example}
\begin{example}
	[2.3-3]
	Consider $x_n = (1,\frac12,\dots,\frac1n,0,0,0,\dots)$.
	Clearly each $x_n\in Y$ and $x_n\ra x\in\ell^\infty$, where $x = (1\frac12,\frac13,\dots)\notin Y$ because $||x_n-x||_\infty = \frac1{n+1}$.
\end{example}
\begin{example}
	[2.3-10] Let $(e_n)_{n=1}^\infty$ be a Schauder basis.
	Set $Y = \setc{\sum_{k=1}^n q_ke_k}{q_k\in\mb Q}$. Let $x\in X$ and $\epsilon>0$.
	Then 
	\begin{align*}
		\mlr{\mlr{x-\sum_{k=1}^nq_ke_k}} &\leq \mlr{\mlr{x-\lcs n\alpha ek}} + \mlr{\mlr{\sum_{k=1}^n(\alpha_k-q_k)e_k}}
	\end{align*}
	$\epsilon/2$.
\end{example}

\begin{example}
	[Test \#5] $X = \setc{p(x)}{p(x)\text{ is a polynomial}}$, $||p||_1 = \int_0^1 |p(x)|\,dx$ and $||p||_\infty = \max_{0\leq x\leq1}|p(x)|$.
	Consider $f_n(x) = x^n$. Then $||f_n||_\infty=1$ for all $n$ but $||f_n||_1 = \frac1{n+1}\ra0$.
	So there is no constant $c>0$ such that $||p||_\infty\leq c||p||_1$ for all $p\in X$.
\end{example}
\newpage
\ul{Last time}: Linear operators on finite dimensional spaces, matrix representations.

\begin{definition}
	[Dual Basis] Given a vector space $X$ with basis $\set{e_1,\dots,e_n}$, there is a unique set of linear functionals $\set{f_1,\dots,f_n}$ such that $f_i(e_j) = \delta_{ij}$. % = \begin{cases} 0 & i\neq j \\ 1 & i=j \end{cases}$.
	This is a basis for dual space $X^*$.
\end{definition}
Given vector spaces $X,Y$, in linear algebra we define $\ms L(X,Y) = $ vector space of all linear operators from $X$ to $Y$. 
If $X,Y$ are normed spaces, we define $B(X,Y) = $ vector space of all bounded linear operators from $X$ to $Y$.
$B(X,Y)$ is a normed space with norm $$||T|| = \sup_{\us{x\neq0}{x\in X}} \frac{||Tx||}{||x||} = \sup_{\us{||x||=1}{x\in X}}||Tx||.$$
Dual space of $X = B(X,\mb R)$ or $B(X,\mb C) = X'$.

\begin{theorem}
	$B(X,Y)$ is complete (hence a Banach space) if $Y$ is complete.
\end{theorem}
\begin{corollary}
	The dual space $X'$ is a Banach space.
\end{corollary}

\section{Hilbert spaces}

We motivate definition of inner product by considering dot product in $\mb R^3$.
\begin{itemize}
	\item geometric definition of dot product $x\cdot y = ||x||\ ||y||\cos\theta$, thus $\theta = \arccos \frac{x\cdot y}{||x||\ ||y||}$.
	\item algebraic definition of dot product of $x=(\xi_1,\xi_2,\xi_3),y = (\eta_1,\eta_2,\eta_3)$: $x\cdot y = \xi_1\eta_1 + \xi_2\eta_2 + \xi_3\eta_3$, can be easily extended to $\mb R^n$.
	\item $||x||^2 = x\cdot x$.
	\item parallelogram law: \fbox{$||x+y||^2 + ||x-y||^2 = 2(||x||^2+||y||^2)$}.
\end{itemize}
\begin{definition}
	Let $X$ be a vector space. An \ul{inner product} on $X$ is a mapping $\gen{\cdot,\cdot}:X\times X\ra K$ ($\mb R$ or $\mb C$) such that for all $x,y,z\in X$ and scalars $\alpha\in K$,
	\begin{enumerate}
		\item $\gen{x+y,z} = \gen{x,z} + \gen{y,z}$
		\item $\gen{\alpha x,y} = \alpha\gen{x,y}$.
		\item $\gen{x,y} = \conj{\gen{y,x}}$.
		\item $\gen{x,x}\geq0$ and $\gen{x,x}=0\iff x=0$.
	\end{enumerate}
	The space $X$ is then called an \ul{inner product space}.
	A Hilbert space is a complete inner product space.
\end{definition}
\begin{remark}
	$\gen{\cdot,\cdot}$ is sesquilinear. %, since $\alpha\gen{x,y} = \gen{\alpha x,y} = \gen{x,\conj\alpha y}$.
\end{remark}
\begin{itemize}
	\item An inner product defines a norm by $||x||=\sqrt{\gen{x,x}}$.
	\item If $X$ is real, then $\gen{x,y} = \gen{y,x}$.
	\item Not every norm is defined by an inner product.
	\item If $||\cdot||$ is defined by an inner product, then $||\cdot||$ satisfies the parallelogram law.
	\item If a norm satisfies the parallelogram law, then it \say{comes from} an inner product (polarization identity).
\end{itemize}
Hilbert spaces have certain important properties not found in general normed spaces or Banach spaces.
\begin{itemize}
	\item Hilbert space $H$ can be represented as $H = M\oplus M^\perp$.
	\item Hilbert spaces may have \say{orthonormal basis} (countable).
	\item Riesz Theorem characterizes all bounded linear functionals.
	\item Can define the \say{adjoint} of a linear operator.
\end{itemize}

\begin{example}
	$\mb R^n,\mb C^n$ with the \say{dot product} and Euclidean norm.
\end{example}
\newpage
\begin{example}
	$\ds \ell^2 = \setc{x = (\xi_j)_{j=1}^\infty}{\sum_{j=1}^\infty |\xi_j|^2<\infty}$, 
	$\ds ||x||_2 = \sqrt{\sum_{j=1}^\infty |\xi_j|^2}$, 
	$\ds \gen{x,y} = \sum_{j=1}^\infty \xi_j\conj\eta_j$,
	$x=(\xi_j),y=(\eta_j)$. %_{j=1}^\infty$.
\end{example}
\begin{example}
	$C[a,b]$ with $\gen{f,g} = \int_a^b f(x)\conj{g(x)}\,dx$ is an inner product space with  norm $||f||_2 = \sqrt{\int_a^b |f(x)|^2\,dx}$. This is \ul{not} complete.
	The \say{completion} is the Hilbert space $L^2(a,b)$.
\end{example}
\ul{HW} 2.9: 2,4,6,G8. 3.1: 3,4,6,7.

Last time: inner product, Hilbert space. 
We  noted in $\mb R^3$ dot product is related to Euclidean norm by $$||x||=\sqrt{\gen{x,x}}. \qquad (*)$$

\begin{lemma}
	Let $(X,\gen{\cdot,\cdot})$ be an inner product space, and define $||\cdot||$ by $(*)$.
	Then
	\begin{enumerate}
		\item[a.] $|\gen{x,y}|\leq||x||\,||y||$ Schwarz inequality,
			Equality holds only if $x$ is a scalar multiple of $y$.
		\item[b.] $||x+y||\leq||x||+||y||$ triangle inequality
	\end{enumerate}
\end{lemma}
\begin{proof}
	[Proof of a.]
	Clearly true when $y=0$. Assume $y\neq0$. For any scalar $\alpha$,
	\begin{align*}
		0 &\leq ||x-\alpha y||^2 = \gen{x-\alpha y,x-\alpha y}
		= \gen{x,x}-\conj\alpha\gen{x,y}-\alpha\blr{\gen{y,x}-\conj\alpha\gen{y,y}}
	\end{align*}
	Take $\ds\conj\alpha = \frac{\gen{y,x}}{\gen{y,y}}$.
	So 
	\begin{align*}
		0 &\leq \gen{x,x} - \frac{\gen{y,x}\gen{x,y}}{\gen{y,y}} \\
		0 &\leq \gen{x,x} - \frac{|\gen{x,y}|^2}{\gen{y,y}}
	\end{align*}
	So $
		|\gen{x,y}|^2 \leq \os{\ra||x||^2}{\gen{x,x}}\os{\ra||y||^2}{\gen{y,y}} \implies
		\gen{x,y} \leq ||x||\,||y|| \ \checkmark $
\end{proof}
\begin{proof}
	[b.] Consider 
	\begin{align*}
		||x+y||^2 = \gen{x+y,x+y} 
				  &= \gen{x,x} + \gen{x,y} + \gen{y,x} + \gen{y,y} \\ 
				  %= ||x||^2 + ||y||^2 + \gen{x,y} + \gen{y,x} \\
				  &\leq ||x||^2 + ||y||^2 + |\gen{x,y}| + |\gen{y,x}| \\
				  &\leq ||x||^2 + ||y||^2 + 2||x||\,||y|| \qquad (\text{Schwarz ineq.}) \\
				  &= (||x||+||y||)^2
	\end{align*}
	So $||x+y||\leq ||x||+||y||$ $\checkmark$
\end{proof}

Let $X$ be a normed space, $M$ a subset, and $x\in X$.
The \ul{distance} $\delta$ from $x$ to $M$ is defined by $$\delta = \inf_{\tilde y\in M} ||x-\tilde y||.$$

\begin{question}
	Is there a vector $y\in M$ such that $||x-y||=\delta$? If so, is it unique?
\end{question}
\begin{example}
	[In $\mb R^2$] The distance $\delta$ from a point $x$ to an open line segment $M$ is always defined, but there may be no vector $y\in M$ such that $||x-y||=\delta$.
\end{example}
\begin{example}
	If the boundary of $M$ has a concave circular boundary with a center $x$, then there are infinitely many $y\in M$ such that $||x-y||=\delta$.
\end{example}
\begin{definition}
	Let $x,y\in X$. The line segment from $x$ to $y$ is $\setc{z = \alpha x+(1-\alpha)y}{0\leq\alpha\leq 1}$.
\end{definition}
\begin{definition}
	$M\subset X$ is \ul{convex} if whenever $x,y\in M$, then the line segment from $x$ to $y$ is in $M$.
\end{definition}
\begin{remark}
	Any set can be made convex by taking it's convex hull.
\end{remark}

\begin{theorem}
	Let $X$ be an inner product space, and let $M\neq0$ be a convex set which is complete.
	Then for all $x\in X$, there exists unique $y\in M$ such that $\ds||x-y||=\delta = \inf_{\tilde y\in M}||x-y||$.
\end{theorem}
\begin{proof}
	[a. Existence.] By definition of $\inf$, there is a sequence $(y_n)\in M$ such that $\delta_n\ra\delta$, where $\delta_n=||x-y_n||$.
	Claim: $(y_n)$ is Cauchy. Let $v_n=x-y_n$. So $||v_n||=\delta_n$ and $y_n-y_m = v_m-v_n$.
	We have: $$||v_n+v_m|| = ||y_n+y_m-2x|| = 2\bigg|\bigg|\bigg(\ub{\in M\text{ by convex}}{\frac12y_n+\frac12y_m}\bigg)-x\bigg|\bigg| \geq2\delta.$$
	By parallelogram law,
	\begin{align*}
		||y_n-y_m||^2 = ||v_n-v_m||^2 &= -||v_n+v_m||^2 + 2(||v_n||^2+||v_m||^2) \\
									  &\leq -(2\delta)^2 + 2(\delta_n^2+\delta_m^2) \ra0
	\end{align*}
	as $n,m\ra\infty$. So $(y_n)$ is Cauchy.
	Since $M$ is complete, $y_n\ra y$, and $y\in M$. Also, $||x-y|| \geq \delta$.
	Also, $||x-y||\leq ||x-y_n||+||y_n-y|| = \delta_n + ||y_n-y||\ra\delta$.
	So $||x-y||\leq\delta$, so $||x-y||=\delta$ $\checkmark$
\end{proof}
\begin{proof}
	[b. Uniquenes.] see text.
\end{proof}

\begin{lemma}
	Let $X$ be an inner product space, and let $Y$ be a complete subspace.
	(Thus $Y$ is a nonempty, complete, convex subset).
	Fix $x\in X$ and let $y\in Y$ be the unique vector in $Y$ closest to $x$.
	Then $z = x-y$ is orthogonal to $Y$. That is, $\gen{z,\tilde y}=0$ for all $\tilde y\in Y$.
\end{lemma}

\ul{HW} 3.2: 5,7,9,G8

\begin{recall}
	[Last time]
Let $X$ be inner product space.
\begin{enumerate}
	\item Let $M\neq\emptyset$ be complete, convex subset of $X$, and $x\in X$.
		[Then there exists unique vector in $M$ closest to $x$.] Then $\exists!y\in M$ such that $$ \delta = \inf_{\tilde y\in M} ||x-\tilde y|| = ||x-y||. $$
	\item If $Y$ is a complete subspace of $X$ and $x\in X$, then $\exists!y\in Y$ such that $z = x-y\perp Y$ and $||z||=\delta$.
\end{enumerate}
\end{recall}
\begin{proof}
	Every subspace is convex, so by 1. $\exists!y\in Y$ such that $||z||=\delta$, where $z=x-y$. Remains to show that $z=x-y\perp Y$.
	BWOC, suppose $z\not\perp Y$. So $\exists y_1\in Y$ such that $\gen{z,y_1}=\beta\neq0$.
	Clearly $y_1\neq0$. For any scalar $\alpha$, we have 
	\begin{align*}
		||z-\alpha y_1|| &= \gen{z-\alpha y_1,z-\alpha y_1} 
						 = \gen{z,z} - \conj\alpha\beta - \alpha [\ub{\conj\beta}{\gen{y_1,z}}-\conj\alpha\gen{y_1,y_1}]
	\end{align*}
	Choose $\conj\alpha = \frac{\conj\beta}{||y_1||^2}$.
	Then 
	\begin{align*}
		||z-\alpha y_1||^2 &= ||z|| - \frac{|\beta|^2}{||y_1||^2}
						   = \delta^2 - \frac{|\beta|^2}{||y_1||^2} < \delta^2
	\end{align*}
	So $||z-\alpha y_1|| < \delta$. So $||x-\ul{(y+\alpha y_1)}|| < \delta$.
	Contradiction since $y+\alpha y_1\in y$.
\end{proof}

\begin{definition}
	Let $H$ be a Hilbert space and $Y$ a subspace.
	The \ul{orthogonal complement} of $Y$, denoted $Y^\perp$, is the set of all vectors orthogonal to $Y$.
	$$ Y^\perp = \setc{z\in H}{\gen{z,y}=0\ \forall y\in Y} $$
\end{definition}
This is a special case of
\begin{definition}
	If $M\neq\emptyset$ is a subset of $H$ the \ul{annihilator of $M$}, denoted $M^\perp$, is the set $$M^\perp = \setc{z\in H}{\gen{z,y}=0\ \forall y\in M}.$$
\end{definition}
\begin{note}
	[alternative definition] For $M\subset X$, $M^\circ = \setc{f\in X'}{f(x)=0\ \forall x\in M}$.
\end{note}
\begin{definition}
	A vector space $X$ is said to be the \ul{direct sum} of two subspaces $Y$ and $Z$ if each $x\in X$ has a unique representation $x=y+z$, $x\in X,y\in Z$.
	Notation: $X = Y\oplus Z$.
\end{definition}
\begin{example}
	Let $Y$ and $Z$ be any two non-parallel, intersecting subspaces of $\mb R^2$, then $Y\oplus Z = \mb R^2$.
\end{example}
\newpage
\begin{theorem}
	Let $H$ be a Hilbert space and $Y$ a closed subspace. Then $H = Y\oplus Z$, where $Z = Y^\perp$.
\end{theorem}
\begin{proof}
	Let $x\in H$. Since $H$ is complete and $Y$ is closed, then $Y$ is complete.
	By previous theorem, $\exists!y\in Y$ such that $z=x-y\in Y^\perp$.
	Clearly $x=y+z$, and $y\in Y,z\in Y^\perp$ $(*)$. 
	To see this is unique, suppose $x = y+z$ and $x = y_1+z_1$, where $y,y_1\in Y$, $z,z_1\in Y^\perp$.
	Then $y-y_1=z_1-z$. But $y-y_1\in Y$, so $z_1-z\in Y\cap Y^\perp$.
	Thus $z_1-z=0$, so $z=z_1$ and $y=y_1$.
\end{proof}
\ul{Notation}: The vector $y\in Y$ is called the \ul{orthogonal projection} of $x$ onto $Y$.
\begin{note}
	$(*)$ defines a linear operator on $H$ by $Px = y$. 
	$P$ is a bounded linear operator on $H$.
	Also $P^2x = Px$, so $P^2=P$. $\ms N(P) = Y^\perp$.
\end{note}
\begin{remark}
	In Hilbert space $H$, an idempotent operator $P$ will have $\ms R(P) \oplus \ms N(P) = H$ (requires $\ms R(P)$ is closed (maybe $P$ is boundedq), but not necessarily in Banach space.
\end{remark}
Notice that if $x\in Y$, then $x\perp Y^\perp$, so $x\in(Y^\perp)^\perp$. Thus $Y\subset(Y\perp)^\perp$.
\begin{lemma}
	Let $H$ be Hilbert space and $Y$ a closed subspace. Then $Y = (Y^\perp)^\perp$.
\end{lemma}
\begin{proof}
	We know $Y\subset (Y^\perp)^\perp$, need to show $(Y^\perp)^\perp\subset Y$.
	Let $x\in(Y^\perp)^\perp$. By previous result, since $Y$ is closed and hence complete, $x = y+z$, where $y\in Y,z\in Y^\perp$.
	Thus $z = x-y\in(Y^\perp)^\perp$, so $z\in Y^\perp\cap(Y^\perp)^\perp$, so $z=0$.
	Thus $x=y$, so $x\in Y$.
\end{proof}
\ul{HW} 3.3: 1,3,8,G6.

Last time: orthogonal complements, direct sums, projections.
\ul{Next}: sets and sequences of orthogonal vectors.
Motivation by considering $\mb R^3$.

For $x\in\mb R^3$, $x=(x_1,x_2,x_3)$ and basis $e_1,e_2,e_3$.
Then $x = \alpha_1e_1+\alpha_2e_2+\alpha_3e_3$, where $\alpha_1 = x_1 =\gen{x,e_1}$, $\alpha_2=x_2=\gen{x,e_2}$, $\alpha_3=x_3=\gen{x,e_3}$.

\begin{definition}
	An \ul{orthogonal set} $M$ in an inner product space is a subset $M\subset X$ where elements are pairwise orthogonal.
	If all elements have norm 1, we asy $M$ is \ul{orthonormal}.
	If $M$ is countable, we can write as an orthogonal or orthonormal \ul{sequence} $(x_n)_{n=1}^?$.
\end{definition}
\begin{note}
	$x\perp y \iff ||x+y||^2 = ||x||^2 + ||y||^2$.
\end{note}
\begin{lemma}
	An orthogonal set is linearly independent.
\end{lemma}
\begin{proof}
	Assume $M$ is an orthogonal set in inner product space $X$.
	Let $\set{e_1,\dots,e_n} \subset M$. Suppose $\alpha_1e_1+\dots+\alpha_ne_n=0$.
	For any $k=1,\dots,n$,
	\begin{align*} 
		0 = \gen{0,e_k} &= \gen{\alpha_1e_1+\dots+\alpha_ne_n,e_k} \\
						&= \alpha_1\gen{e_1,e_k} + \dots + \alpha_k\gen{e_k,e_k} + \dots + \alpha_n\gen{e_n,e_k} \\
						&= \alpha_k\gen{e_k,e_k} = \alpha_n||e_k||^2,
	\end{align*}
	so $\alpha_k=0$. Thus $\set{e_1,\dots,e_n}$ is linearly independent.
\end{proof}
\begin{example}
	$\mb R^n$, $e_1=(1,0,\dots,0),e_2=(0,1,0,\dots,0)$, $\set{e_1,\dots,e_n}$ is an orthonormal set.
\end{example}
\begin{example}
	$\ell^2$, $e_1=(1,0,0,\dots),e_2(0,1,0,\dots)$.
	Then $(e_k)_{k=1}^\infty$ is orthonormal.
\end{example}
\begin{example}
	$L^2(0,2\pi)$, $\gen{f,g} = \int_0^{2\pi} f(x)g(x)\,dx$.
	Define $u_n(t) = \cos nx$, $n=0,1,\dots$.
	Can show 
	\begin{align*}
		\gen{u_n,u_m} &= \int_0^{2\pi} \cos(nx)\cos(mx)\,dx = \begin{cases} 0 & n\neq m \\ \pi & n=m=1,2,\dots \\ 2\pi & n=m=0 \end{cases}.
	\end{align*}
	Thus $(u_n)_{n=0}^\infty$ is an orthogonal sequence.
	$e_0 = \frac1{\sqrt{2\pi}}, e_n = \frac1{\sqrt\pi}u_n$, then $(e_n)$ is orthonormal.
\end{example}
\begin{remark}
	Gram-Schmidt process can be used to construct an orthonormal set.
\end{remark}

Let $\set{e_1,\dots,e_n}$ be orthonormal, and let $x\in\spn\set{e_1,\dots,e_n}$.
Then $x = \sum_{k=1}^n \gen{x,e_k}e_k$.
\begin{proof}
	We know $\ds x=\sum_{j=1}^n \alpha_je_j$. Fix $k$. Then 
		$\ds \gen{x,e_k} = \gen{\sum_{j=1}^n \alpha_je_j,e_k}
					= \sum_{j=1}^n \alpha_j\gen{e_j,e_k}
					= \alpha_k \ \checkmark $
\end{proof}
\newpage
\ul{Next}, suppose $Y_n = \spn\set{e_1,\dots,e_n}\subset X$, and $x\notin Y_n$.
Define $y = \sum_{k=1}^n \gen{x,e_k}e_k$. Set $z=x-y$.
\ul{Claim} $z\perp Y_n$. In other words, $y$ is the unique vector in $Y_n$ closest to $x$.
Let $\tilde y\in Y_n$. Then $\tilde y=\sum_{j=1}^n\alpha_je_j$. Then
\begin{align*}
	\gen{z,\tilde y} &= \gen{x-y,\tilde y} = \gen{x,\tilde y} - \gen{y,\tilde y} \\
					 &= \gen{x,\sum_{j=1}^n\alpha_je_j} - \gen{\sum_{k=1}^n \gen{x,e_k}e_k,\sum_{j=1}^n \alpha_je_j} \\
					 &= \sum_{j=1}^n \gen{x,\alpha_jeJ} - \sum_{k=1}^n \gen{x_j,e_k} \gen{e_k,\sum_{j=1}^n\alpha_je_j} \\
					 &= \sum_{j=1}^n \conj\alpha_j\gen{x,e_j} - \sum_{k=1}^n\gen{x,e_k}\cdot\gen{e_k,\alpha_ke_k} \\
					 &= \sum_{j=1}^n \conj\alpha_j\gen{x,e_j} - \sum_{k=1}^n \conj\alpha_k \gen{x,e_k} = 0
\end{align*}
Also note, since $z\perp y$, $||x||^2 = ||z+y||^2 = ||z||^2 + ||y||^2$.
So $||z||^2 = ||x||^2 - ||y||^2$. Also
\begin{align*}
	||y||^2 &= \gen{y,y} = \gen{\sum_{k=1}^n\gen{x,e_k}e_k,\sum_{j=1}^n\gen{x,e_j}e_j}
			=\dots= \sum_{k=1}^n |\gen{x,e_k}|^2.
\end{align*}
So $\ds||z||^2 = ||x||^2 - \sum_{k=1}^n|\gen{x,e_k}|^2$.
So $\ds\sum_{k=1}^n |\gen{x,e_k}|^2 \leq ||x||^2 $ \fbox{Bessel's inequality.}
\begin{theorem}
	Let $(e_k)_{k=1}^\infty$ be an orthonormal sequence in an inner product space $X$.
	Then for any $x\in X$, $$\sum_{k=1}^\infty |\gen{x,e_k}| \leq ||x||^2.$$
\end{theorem}

Let $H$ be a Hilbert space and let $(e_k)_{k=1}^\infty$ be orthonormal sequence.
We consider series of the form $$\sum_{k=1}^\infty \alpha_k e_k \qquad (*) $$
\begin{definition}
	The series $(*)$ exists and has limit $s$ if $||s_n-s||\ra0$ as $n\ra\infty$, where $s_n = \sum_{k=1}^n \alpha_ke_k$.
\end{definition}
\begin{theorem}:
	\begin{enumerate}
		\item[a.] The series $(*)$ converges if and only if the series $\sum_{k=1}^\infty |\alpha_k|^2<\infty$.
		\item[b.] If the series converges, then $\alpha_k = \gen{x,e_k}$ where $x=\sum_{k=1}^\infty \alpha_ke_k$.
		\item[c.] For any $x\in H$, the series $\sum_{k=1}^\infty \gen{x,e_k}e_k$ converges.
	\end{enumerate}
\end{theorem}
\ul{HW} 3.4: 7,9,10.

\ul{Last time}: Bessel's Inequality: If $(e_k)_{k=1}^\infty$ is an orthonormal sequence in inner product space $X$, and $x\in X$, then $\sum_{k=1}^\infty|\gen{x,e_k}|^2\leq ||x||^2$.

\begin{recall}
	Let $(e_k)_{k=1}^\infty$ be orthonormal sequence in Hilbert space $H$, and consider $\sum_{k=1}^\infty \alpha_ke_k$ $(*)$.
	\begin{enumerate}
		\item[a.] The series $(*)$ converges if and only if the series $\sum_{k=1}^\infty |\alpha_k|^2$ converges.
		\item[b.] If series converges, let $x=\sum_{k=1}^\infty \alpha_ke_k$.
			Then $\alpha_k = \gen{x,e_k}$, $k=1,2,\dots$.
		\item[c.] For any $x\in H$, \ul{define} $\alpha_k = \gen{x,e_k}$ (called Fourier coefficients). Then the series $(*)$ converges.
	\end{enumerate}
\end{recall}

\begin{proof}:
	\begin{enumerate}
		\item[a.] Let $s_n = \sum_{k=1}^n \alpha_ke_k$ and $\sigma_n = \sum_{k=1}^n |\alpha_k|^2$.
			For any $m,n$ with $n>m$,
			\begin{align*}
				||s_n-s_m||^2 &= \mlr{\mlr{\sum_{k=m+1}^n \alpha_ke_k}}^2
							  = \sum_{k=m+1}^n ||\alpha_ke_k||^2
							  = \sum_{k=m+1}^n |\alpha_k|^2
							  = |\sigma_n-\sigma_m|.
			\end{align*}
			\begin{recall}
				$x\perp y \implies ||x+y||^2 = ||x||^2+||y||^2$.
			\end{recall}
			Thus $(s_n)$ is Cauchy if and only if $(\sigma_n)$ is Cauchy.
			Thus $\sum_{k=1}^\infty \alpha_ke_k$ converges $\iff (s_n)$ converges

				$\iff (s_n)$ is Cauchy (because $H$ is complete)

				$\iff (\sigma_n)$ is Cauchy

				$\iff (\sigma_n)$ is convergent (because $\mb R$ is complete)

				$\iff \sum_{k=1}^\infty|\alpha_k|^2$ converges.
		
		\item[b.] Suppose series converges, and let $x=\sum_{k=1}^\infty\alpha_ke_k$.
			Thus $s_n\ra x$. Fix $j$. For $n\geq j$, $\gen{s_n,e_j} = \gen{\sum_{k=1}^n \alpha_ke_k,e_j} = \alpha_j$. Thus 
			\begin{align*}
				\gen{x,e_j} &= \lim_{n\ra\infty}\gen{s_n,e_j}
				= \lim_{n\ra\infty} \alpha_j = \alpha_j.
			\end{align*}
		\item[c.] Let $x\in H$ and define $\alpha_k = \gen{x,e_k}$ for $k=1,\dots$.
			By Bessel's inequality, $\sum_{k=1}^\infty |\gen{x,e_k}|^2 \leq ||x||^2$.
			By part a., $\sum_{k=1}^\infty \gen{x,e_k}e_k$ converges.
	\end{enumerate}
\end{proof}

\begin{note}
	Bessel's is for orthonormal sequences. If $E = (e_k)$ wtih $k\in I$ is an uncountable orthonormal set in $H$, we can still form Fourier coefficients $\gen{x,e_k}$ for any $x\in H$. There are uncountably many Fourier coefficients. Can we sum them?
	By the argument for Bessel's inequality we have $\sum_{k=1}^n |\gen{x,e_k}|^2 \leq ||x||^2$ for any \ul{finite} subset $\set{e_1,\dots,e_n}$ of $E$.
	Thus for any $m=1,2,\dots$ the set $E_m = \setc{e_k\in E}{|\gen{x,e_k}|>\frac1m}$.
	The set of all nonzero Fourier coefficients is $\bigcup_{m=1}^\infty E_m$, hence countable.
\end{note}

Given $x\in H$i, and $E=(e_k)$ an orthonormal set, is $\sum_{k=1}^\infty \gen{x,e_k}e_k = x$?

\begin{definition}
	Let $X$ be normed space. A subset $M$ is \ul{total in $X$} if $\spn M$ is dense in $X$. That is, $M$ is total in $X\iff\conj{\spn M} = X$ (closure of span).
		If $X$ is an inner product space, an orthonormal (set, sequence) is a \ul{total orthonormal} (set, sequence) if it is a total set in $X$.
\end{definition}
Above question is same as: Is $E=(e_k)$ a total orthonormal set in $H$?

\begin{enumerate}
	\item Every nontrivial Hilbert space has a total orthonormal set.
		\begin{enumerate}
			\item[-] For finite dimensions use basis, $\dots$
			\item[-] For separable $H$, use Gram-Schmidt and induction on countable basis.
			\item[-] otherwise, Zorn's lemma.
		\end{enumerate}
	\item In a nontrivial Hilbert space, all total orthonormal sets have same cardinality.
\end{enumerate}

Last time: convergent orthonormal series, total subsets

\begin{lemma}
	Let $H$ be a Hilbert space, and $M\neq\emptyset$ a subset.
	Then $M^\perp = \set0$ if and only if $M$ is total. %$$\conj{\spn M}=H.$$
\end{lemma}
\begin{proof}
	\ul{$\Lla$}$\mid$ Suppose $M$ is total and $M\neq\emptyset$.
	Set $V = \spn M$, so $\conj V=H$.
	Let $x\in M^\perp$. It follows that $x\in V^\perp$.
	Also $x\in\conj V=H$. Thus $\exists$ sequence $(x_n)_{n=1}^\infty$ in $V$ such that $x_n\ra x$.
	Note $\gen{x_n,x}=0$ for all $n$ since $x\in V^\perp$ and $x_n\in V$. So 
	\begin{align*}
		||x||^2 &= \gen{x,x} = \gen{\lim_{n\ra\infty}x_n,x} = \lim_{n\ra\infty}\gen{x_n,x} = 0.
	\end{align*}
	So $x=0$, $M^\perp=\set0$.

	\ul{$\Lra$}$\mid$ Suppose $M^\perp=\set0$. Let $V=\spn M$.
	If $x\in V^\perp$, then $x\in M^\perp$, so $V^\perp=\set0$.
	Thus $\conj V^\perp = \set0$.
	By previous result, $H = \conj V\oplus\conj V^\perp = \conj V\oplus\set0=\conj V$.
	Thus $M$ is total.
\end{proof}
\begin{remark}
	If we are just in an inner product space (not Hilbert space), then $M^\perp=\set0$.
\end{remark}

\begin{recall}
	Let $(e_k)_{k=1}^\infty$ be an orthonormal sequence in Hilbert space.
	If $x\in H$, then $$ \sum_{k=1}^\infty |\gen{x,e_k}|^2 \leq ||x||^2 \qquad \text{(Bessel)}$$
	When this is an equality: $$ \sum_{k=1}^\infty |\gen{x,e_k}|^2 = ||x||^2 \qquad \text{(Parseval)} $$
\end{recall}
\begin{theorem}
	An orthonormal set $M$ in a Hilbert space $H$ is total if and only if Parseval's holds $\forall x\in H$.
\end{theorem}
\begin{proof}
	\ul{$\Lla$}$\mid$ Suppose Parseval's holds $\forall x\in H$.
	BWOC suppose $M$ is not total.
	By previous result, $M^\perp=\set0$, so $\exists x\in M^\perp$, $x\neq0$.
	Thus $||x||^2\neq0$. But $\gen{x,e_k}=0$ for $k=1,\dots$ because $e_k\in M$ and $x\in M^\perp$.
	So $\sum_{k=1}^\infty |\gen{x,e_k}|^2=0$, contradicting Parseval.

	\ul{$\Lra$}$\mid$ (For the case $M$ is countable).
	Assume $M=(e_k)_{k=1}^\infty$ is total orthonormal sequence.
	Let $x\in H$. Define $y=\sum_{k=1}^\infty \gen{x,e_k}e_k$.
	Note we know $||y||^2 = \sum_{k=1}^\infty |\gen{x,e_k}|^2$.
	Claim: $x-y\in M^\perp$ (note $M^\perp=\set0$).
	For any fixed $j$, 
	\begin{align*}
		\gen{x-y,e_j} &= \gen{x,e_j}-\gen{\sum_{k=1}^\infty\gen{x,e_k}e_k,e_j}
					  = \gen{x,e_j}-\sum_{k=1}^\infty \gen{x,e_k}\gen{e_k,e_j}
					  = \gen{x,e_j}-\gen{x,e_j}\cdot 1 = 0
	\end{align*}
	Thus claim is true, so $x=y$, and Parseval's holds.
\end{proof}

\begin{theorem}
	Let $H$ be a Hilbert space.
	\begin{enumerate}
		\item[a.] If $H$ is separable, then every orthonormal set is countable.
		\item[b.] If $H$ contains a total orthonormal sequence (countable), then $H$ is separable.
	\end{enumerate}
\end{theorem}
\begin{proof}:
	\begin{enumerate}
		\item[a.] Let $H$ be separable, and let $M$ be orthonormal subset.
			BWOC, suppose $M$ is uncountable.
			Let $B$ be any dense subset of $H$.
			Note if $x,y\in M$, $x\neq y$, then
			\begin{align*}
				||x-y||^2 &= ||x||^2 + ||y||^2 = 2
			\end{align*}
			Thus distance from $x$ to $y$ is $\sqrt2$.
			Let $N_x = \setc{z\in H}{||z-x||<\frac{\sqrt2}3}$.
			Thus all neighborhoods of vectors in $M$ are mutually disjoint.
			For each $x\in M$, $\exists b_x\in B$ such that $b_x\in B\cap N_x$.
			Thus $b_x\neq b_y$ if $x,y\in M$, $x\neq y$. Thus $B$ is uncountable.
			Contradiction to $H$ separable, which means $H$ has at least one countable dense subset.
			Thus $M$ is countable.
		\item[b.] Let $(e_k)_{k=1}^\infty$ be total orthonormal sequence.
			Consider the set of all finite linear combinations of $e_k's$ with rational coefficients. Look at textbook for remainder.
	\end{enumerate}
\end{proof}

\begin{recall}
	Let $X$ be a normed space.
	A bounded linear functional $f$ is bounded linear operator from $X$ to $\mb R$ or $\mb C$.
	For Banach spaces, can sometimes characterize dual space. For Hilbert spaces it is easy.
\end{recall}

\ul{HW} 3.5: 3,6 and 3.6: 1,9,10.

Last time: total orthonormal sequences and Parseval's equation, began discussion of bounded linear functionals.
For general normed spaces or Banach spaces, can sometimes characterize the dual space (section 2.10), not always easy.
For Hilbert spaces we have nice result.

\begin{example}
	Let $H$ be Hilbert space, and let $z\in H$.
	Can define a bounded linear functional $f$ on $H$ by $f(x) = \gen{x,z}$.
	Can show $f$ is linear, bounded, and $||f|| = ||z||$.
	Consider $\ms N(f) = \setc{x\in H}{\gen{x,z}=0}$.
	Then $$\ms N(f)^\perp = \spn\set z.$$
\end{example}
\begin{theorem}
	[Riesz Representation Theorem]
	Every bounded linear functional $f$ on Hilbert space $H$ can be represented by $f(x) = \gen{x,z}$ (1), where $z\in H$ is uniquely determined by $f$ and $||f||=||z||$ (2).
\end{theorem}
\begin{proof}
	We show
	\begin{enumerate}
		\item[a.] $\exists z\in H$ such that (1) is true,
		\item[b.] $z$ in a. is unique,
		\item[c.] $z$ satisfies (2).
	\end{enumerate}
	Note result clearly true for $f\equiv 0$, so assume $f\not\equiv0$.
	Thus $\ms N(f)\neq H$, so $\ms N(f)^\perp\neq\set0$.
	Let $z_0\in\ms N(f)^\perp$ satisfy $z_0\neq0$.
	Define $z = \frac{\conj{f(z_0)}}{\gen{z_0,z_0}}z_0$ so $z_0\in\ms N(f)^\perp$.
	Let $x\in H$. Define $v = f(x)z_0-f(z_0)x$.
	Observe $f(v) = f\blr{f(x)z_0-f(z_0)x} = 0$ so $v\in\ms N(f)$, which implies $z_0\perp v$.
	\begin{align*}
		0 = \gen{v,z_0} &= \gen{f(x)z_0-f(z_0)x,z_0} \\
						&= f(x)\gen{z_0,z_0} - f(z_0)\gen{x,z_0},
	\end{align*}
	so
	\begin{align*}
		f(x) = \frac{f(z_0)}{\gen{z_0,z_0}}\gen{x,z_0} = \gen{x,\frac{\conj{f(z_0)}}{\gen{z_0,z_0}}z_0} = \gen{x,z}.
	\end{align*}
	\begin{enumerate}
		\item[b.] To show $z$ is unique, suppose $\exists z_1,z_2$ such that $f(x) = \gen{x,z_1} = \gen{x,z_1}$ for all $x\in H$.
			Then $\gen{x,z_1-z_2}=0$ for all $x\in H$.
			Thus $z_1-z_2=0$, so $z_1=z_2$.
		\item[c.] When $f\equiv0$, then $z=0$, and $||f||=0=||z||$.
			So suppose $f\not\equiv0$, so $z\neq0$.
			$$||z||^2 = \gen{z,z} = f(z) = |f(z)| \leq ||f||\cdot||z||.$$
			So $ ||z|| \leq ||f||$.
			On the other hand, for all $x\in H$
			\begin{align*}
				|f(x)| &= |\gen{x,z}|
					   \leq ||x||\cdot||z||
			\end{align*}
			This implies $||f||\leq||z||$, so $||f|| = ||z||$.
	\end{enumerate}
\end{proof}
\begin{example}
	[$H = L^2(a,b)$] $\gen{f,g} = \int_a^bf(x)\conj{g(x)}\,dx$, $||f|| = \sqrt{\int_a^b |f(x)|^2\,dx}$.
	If $F$ is bounded linear functional on $H$, then $\exists!f\in H$ such that $F(g) = \int_a^bg(x)\conj{f(x)}\,dx$ for all $g\in H$.
\end{example}

\begin{definition}
	Let $X,Y$ be vector spaces over some field ($\mb R$ or $\mb C$).
	A \ul{sesquilinear form} $h$ on $X\times Y$ is a mapping $h:X\times Y\ra\mb R$ or $\mb C$ such that.
	\begin{enumerate}
		\item[a.] $h(x_1+x_1,y) = h(x_1,y)+h(x_2,y)$,
		\item[b.] $h(x,y_1+y_2) = h(x,y_1)+h(x,y_2)$,
		\item[c.] $h(\alpha x,y) = \alpha h(x,y)$,
		\item[d.] $h(x,\alpha y) = \conj\alpha h(x,y)$.
	\end{enumerate}
\end{definition}
\begin{definition}
	Let $X,Y$ be normed spaces.
	A sesquilinear form $h$ on $X\times Y$ is \ul{bounded} if $\exists c>0$ such that $|h(x,y)|\leq c||x||\,||y||$.
	If $h$ is bounded, then the \ul{norm} of $h$ is $$||h|| = \sup_{\us{y\in Y\bs\set0}{x\in X\bs\set0}} \frac{|h(x,y)|}{||x||\,||y||}.$$
\end{definition}
\begin{example}
	Let $H_1,H_2$ be Hilbert spaces.
	Suppose $S\in\ms L(H_1,H_2)$ be a bounded linear operator.
	Define $h:H_1\times H_2\ra\mb R$ or $\mb C$ by $h(x,y) = \gen{Sx,y}_{H_1}$.
	Easy to check that $h$ is a sesquilinear form on $H_1\times H_2$. Also
	\begin{align*}
		|h(x,y)| = |\gen{Sx,y}_{H_2}|
				 &\leq ||Sx||_{H_2} \cdot ||y||_{H_2} \\
				 &\leq ||S||\,||x||_{H_1}\,||y||_{H_2}
	\end{align*}
	So $h$ is a bounded sesquilinear form.
	Can also show $||h||=||S||$.
\end{example}

\ul{HW} 3.8: 1,2,3.

\begin{example}
	[Gram-Schmidt]
	$x_1,x_2$ vectors,
	$v_1 = x_1 \ra e_1=\frac1{||v_1||}v_1$, 
	$v_2 = x_2-\gen{x_2,e_1}e_1$, 
	$e_2 = \frac1{||v_2||}v_2$.
\end{example}

\ul{Last time}: Riesz Representation Theorem: If $f$ is a bounded linear functional on a Hilbert space $H$ (that is, $f\in H'$), then $\exists! z\in H$ such that $f(x) = \gen{x,z}$ for all $x\in H$.
A bounded sesquilinear form $h$ on $H_1\times H_2$ satisfies $|h(,y)| \leq ||h||\,||x||\,||y||$.

If $S$ is bounded linear operator from $H_1$ to $H_2$, then $h(x,y) = \gen{Sx,y}$ is a bounded sesquilinear form, and $||h||=||S||$.

\begin{theorem}
	[Representation Theorem]
	Let $H_1,H_2$ be Hilbert spaces, and let $h:H_1\times H_2\ra\mb R$ or $\mb C$ be a bounded sesquilinear form.
	Then $\exists!$ bounded linear operator $S$ from $H_1$ to $H_2$ such that $h(x,y) = \gen{Sx,y}$ $\forall x\in H_1,\forall y\in H_2$, and $||h||=||S||$.
\end{theorem}
\begin{proof}
	Assume $h$ is bounded sesquilinear form on $H_1\times H_2$.
	Fix $x\in H_1$. Define a bounded linear functional on $H_2$ by $f(y)=\conj{h(x,y)}$.
	Easy to check that $f$ is bounded linear functional on $H_2$.
	By Riesz Representation Theorem, $\exists z\in H_2$ such that $f(y) = \gen{y,z}_{H_2}$ for all $y\in H_2$.
	Note $z$ depends uniquely on $x$.
	Define $S:H_1\ra H_2$ by $Sx=z$. $S$ is linear (see text).
	Notice $h(x,y) = \gen{Sx,y}$.
	Also,
	\begin{align*}
		||S|| &= \sup_{x\neq0} \frac{||Sx||}{||x||} = \sup_{\us{Sx\neq0}{x\neq0}} \frac{\gen{Sx,Sx}}{||Sx||\,||x||}
			  \leq \sup_{\us{y\neq0}{x\neq0}} \frac{\gen{Sx,y}}{||y||\,||x||}
			  = \sup_{\us{y\neq0}{x\neq0}} \frac{|h(x,y)|}{||y||\,||x||} = ||h||
	\end{align*}
	So $S$ is bounded and $||S||\leq||h||$.
	Also 
	\begin{align*}
		||h|| = \sup_{\us{y\neq0}{x\neq0}} \frac{|h(x,y)|}{||x||\,||y||} = \sup_{\us{||y||\neq0}{||x||\neq0}} \frac{|\gen{Sx,y}|}{||x||\,||y||}
		\leq \sup_{\us{y\neq0}{x\neq0}} \frac{||Sx||\,||y||}{||x||\,||y||} = ||S||.
	\end{align*}
	So $||h||=||S||$. Finally, $S$ is unique (see text).
\end{proof}
\begin{example}
	[$H_1=H_2=\mb R^3$] 
	Let $x = \pmat{\xi_1\\\xi_2\\\xi_3}, y = \pmat{\eta_1\\\eta_2\\\eta_3}$, 
	then $\gen{x,y} = \xi_1\eta_1+\xi_2\eta_2+\xi_3\eta_3 = y^Tx$.
	Define $h(x,y) = (\xi_2+\xi_3)\eta_1+2\xi_1\eta_2+\xi_2\eta_3$, \ul{HW}: Show $h$ is (sesqui)linear and bounded.
	By theorem, $\exists T:\mb R^3\ra\mb R^3$ such that $h(x,y) = \gen{Tx,y}$.
	So $Tx = \pmat{\xi_2+\xi_3\\2\xi_1\\\xi_2}$.
\end{example}
\begin{example}
	[$H_1=H_2=\ell^2$]
	Let $x = (\xi_k)_{k=1}^\infty, y = (\eta_k)_{k=1}^\infty$, then $\gen{x,y} = \sum_{k=1}^\infty \xi_k\eta_k$.
	Define $h(x,y) = \xi_1\eta_2+\xi_2\eta_3+\dots$.
	\ul{HW}: Show $h$ is sesquilinear and bounded (Cauchy-Schwartz p.14).
	Determine the operator $T$ such that $h(x,y) = \gen{Tx,y}$.
\end{example}

Consider $H_1=\mb R^n$, $H_2=\mb R^m$ wih usual inner product $\gen{x,y}= y^Tx = x^Ty$.
If $A$ is $m\times n$ matrix, it defines linear operator from $H_1$ to $H_2$, $A:H_1\ra H_2$.
\begin{align*}
	\gen{Ax,y} &= y^TAX
			   = (y^TAx)^T
			   = x^TA^Ty
			   = \gen{A^Ty,x^T}
			   = \gen{x,A^Ty}.
\end{align*}
In complex case, $\gen{x,y} = \conj y^Tx$ and we get $\gen{Ax,y}=\dots=\gen{x,\conj A^Ty}$.
\begin{definition}
	Let $H_1,H_2$ be Hilbert spaces, and let $T:H_1\ra H_2$ be a bounded linear operator.
	The \ul{Hilbert-adjoint} operator $T^*$ of $T$ is the unique bounded linear operator satisfying $T^*:H_2\ra H_1$ $$\gen{Tx,y}_{H_2} = \gen{x,T^*y}_{H_1}$$ for all $x\in H_1,y\in H_2$.
\end{definition}

\newpage

\begin{theorem}
	The Hilbert-adjoint operator $T^*$ exists, is unique, and satisfies $||T^*||=||T||$.
\end{theorem}
Some properties of adjoint:
\begin{align*}
	(S+T)^* &= S^*+T^* \\
	(\alpha T)^* &= \conj\alpha T^* \\
	(T^*)^* &= T \\
	||T^*T|| &= ||TT^*|| = ||T^2|| \\
	(ST)^* &= T^*S^*
\end{align*}
So $(T^*T)^* = T^*T^{**} = T^*T$.

\end{document}
