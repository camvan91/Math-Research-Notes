\documentclass[]{article}
\input{../mathdoc}
\input{../mathsym}

\author{Book: Brown \& Churchill 8th, Presenter: Richard Fabiano, Notes by Michael Reed}
\title{Fourier Series and Boundary Value Problems}
\date{April 27, 2017}

\begin{document}
\maketitle

\section{A peek ahead}

Consider a cylinder solid with perfectly insulated sides, from $x=0$ to $x=c$. Let $u(x,t)$ be the temperature at position $x$ and time $t$. Under appropriate assumptions, a mathematical model is the \underline{heat equation} PDE
\begin{equation}
	u_t(x,t)=k u_{xx}(x,t),
\end{equation}
where $0<x<c$ and $t>0$. The boundary conditions are $u_x(0,t)=0$ and $u_x(c,t)=0$ for $t>0$. For the initial conditions we have $u(x,0)=f(x)$ for $0<x<c$. We shall assume the thermal diffusivity $k>0$.
This is derived in section 22 of the textbook. We will consider a solution method from section 36 in the textbook.

\underline{Idea}: Look for solutions of the PDE (1) and the boundary conditions. There are infinitely many of them. Since (1) and the BC are linear and homogeneous, linear combinations are also solutions by the superposition principle. Then we try to determine a particular linear combination which also satisfies the initial conditions.

\underline{Idea}: Separation of variables: Seek solutions of the form $u(x,t)=X(x)T(t)$, where $X,T\neq 0$. Plug in to (1) and BC to get
\begin{equation}
X(x)T'(t)=kX''(x)T(t)
\end{equation}
with $0<x<c$ and $t>0$. Let's separate the variables to get
\begin{equation}
\frac{T'(t)}{kT(t)}=\frac{X''(x)}{X(x)}.
\end{equation}
Since LHS is a function of only $t$ and RHS is a function of only $x$, so both must be constant. $\frac{T'(t)}{kT(t)}=-\lambda=\frac{X''(x)}{X(x)}$, where $\lambda\in\mb R$. This gives two separate ODEs.
\begin{note}
	According to the boundary conditions we have $X'(0)T(t)=0$ and $X'(c)T(t)=0$.
\end{note}
So we end up with
\begin{align}
X''(x)+\lambda X(x)&=0, &\qquad
X'(0)&=0, &\qquad X'(c)&=0,
\end{align}
which is the Sturm-Liouville BVP and
\begin{equation}
T'(t)+k\lambda T(t)=0.
\end{equation}
Equation (5) has a solution for any $\lambda$, i.e. $T(t)=e^{-k\lambda t}$. Equation (4) has solutions only for certain values of $\lambda$. Next we investigate (4) for different $\lambda$'s.

When $\lambda=0$, $X''(x)=0$, $X'(0)=0$, $X'(c)=0$. Then $X(x)=Ax+B$ and $X'(x)=A$, so $A=0$. So $X(x)=1$ and any constant multiple.

When $\lambda>0$, lets assume that we can write $\lambda=\alpha^2$, where $\alpha>0$. Then $X''(x)+\alpha^2 X(x)=0$. The general solution is $X(x)=c_1 \cos{\alpha x} + c_2 \sin{\alpha x}$. Then $X'(x)=-\alpha c_1 \sin{\alpha x}+ \alpha c_2 \cos{\alpha x}$. $X'(0)=0$ implies $0=\alpha c_2 \cos{0}$, so $c_2=0$ and $X(x)=c_1 \cos{\alpha x}$. $X'(c)=0$ implies $0=\alpha c_1 \sin{\alpha c}$, where $c_1\neq 0$. Therefore $\sin{\alpha c}=0$. So $\alpha=n\pi /c$, for $n\in\mb N$.
$X(x)=\cos\left(\frac{n\pi}{c}x\right),n\in\mb N$ and any constant multiple.

When $\lambda<0$ set $\lambda=-\alpha^2$ for $\alpha>0$. $X''(x)-\alpha^2 X(x)=0$. The general solution is $X(x)= c_1 e^{\alpha x} + c_2 e^{-\alpha x}$. Then $X'(x)=\alpha c_1 e^{\alpha x} - \alpha c_2 e^{-\alpha x}$. With $X'(0)=0$ we get $\alpha c_1-\alpha c_2 = 0$ so $c_1=c_2$. That means that $X'(x)=\alpha c_1 e^{\alpha x} - \alpha c_1 e^{-\alpha x}$ with $X'(c)=0$ implying $0=\alpha c_1(e^{\alpha c}-e^{-\alpha c})$. This implies $c_1=0$, so we only get trivial solution $X(x)=0$.

Set $\lambda_0=0$, then $\lambda_n=\left(\frac{n\pi}{c}\right)^2$ for $n\in\mb N$. $X_0(x)=1$, $T_0(t)=1$, then $X_n(x)=\cos{\frac{n\pi}{c}x}$ and $T_n(t)=e^{-k\frac{n^2\pi^2}{c^2}t}$. Then $u_0(x,t)=1$ and $u_n(x,t)=\cos\left(\frac{n\pi}{c}x\right)e^{-k\frac{n^2\pi^2}{c^2}t}$ solve (1) and BCs. By superposition, $u(x,t)=A_0+\sum_{n=1}^{\infty} A_n \cos\left(\frac{n\pi}{c}x\right)e^{-k\frac{n^2\pi^2}{c^2}t}$ is a solution. Can such a solution also satisfy the initial conditions? Can we determine $A_0,A_1,\dots$ so that $A_0 + \sum_{n=1}^{\infty} A_n \cos\frac{n\pi}{c}x = f(x)$?

HW: Sec 5 p.13: 2,3,4,6,8

\section{Fourier Series}

Consider the finite interval $(a,b)$.
\begin{definition}
	$f(x)$ is piecewise continuous (PWC) if $f$ is continuous for all except a finite set of points on $(a,b)$, and if those points and at endpoints the one-sided limits exist. $C_p(a,b)$ is the set of all functions that are PWC on the interval $(a,b)$.
\end{definition}
\begin{example}
	$y=\tan x$ is \underline{not} PWC on $(-\pi/2,\pi/2)$ because $\lim_{x\ra\pi/2^-}f(x)$ does  not exist.
\end{example}
\begin{example}
	%$f(x)=0$ for $-1<x<0$ and $f(x)=1$ for $0\leq x<1$: $f$ is PWC.
	$f(x)=\begin{cases}0 & \text{for }-1<x<0 \\ 1 & \text{for }0\leq x<1\end{cases}$: then $f$ is PWC.
\end{example}
\begin{example}
	$f(x)=\sin(1/x)$ on $(0,1)$ is not PWC.
\end{example}
\begin{note}
	If $f\in C_p(a,b)$, then $\int_a^bf(x) \, dx$ exists.
	If $f,g\in C_p(a,b)$, then $c_1f(x) + c_2 g(x) \in C_p(a,b)$.
	Thus $C_p(a,b)$ is a vector space. It is an example of \underline{function spaces}.
	If $f,g\in C_p(a,b)$, then $f\cdot g\in C_p(a,b)$.
\end{note}
We can define an inner product $(f,g)=\int_a^b f(x) g(x) \, dx$.
Further, we can define orthogonal functions as $f\perp g \iff (f,g)=0$.
We can also define norm (length) as $||f||=\sqrt{(f,f)}=\left(\int_a^b f^2(x) \, dx\right)^{1/2}$.
Thus $C_p(a,b)$ is an infinite dimensional normed vector space.

Let $f\in C_p(0,\pi)$. \underline{Assume} $f$ has a Fourier cosine series
\begin{equation}
f(x)=\frac{a_0}{2} + \sum_{n=1}^{\infty}a_n \cos{nx}
\end{equation}
for $0<x<\pi$.
Can we determine the the coefficients $a_i$? Yes, if we assume also we can integrate term by term.
$\int_0^\pi f(x) \, dx = \int_0^\pi \frac{a_0}{2} \, dx + \sum_{n=1}^{\infty} \int_0^\pi a_n \cos{nx} \, dx$. $\int_0^\pi f(x) \, dx = \frac{\pi}{2}a_0$, so $a_0 = \frac{2}{\pi} \int_0^\pi f(x) \, dx$ because $\int_0^\pi a_n \cos{nx} \, dx = \frac{1}{n} \sin{nx}\big\rvert_0^\pi=0$.
In HW: $\int_0^\pi\cos{mx}\cdot\cos{nx} \, dx = \begin{cases}0 & \text{for } m\neq n \\ \pi/2 & \text{for }m=n\end{cases}$.
Rewrite $f$ as $f(x)=\frac{a_0}{2}+\sum_{m=1}^\infty a_m \cos{mx}$. Multiply by $\cos{nx}$ and integrate:
$$\int_0^\pi f(x) \cos{nx} \, dx = \frac{a_0}{2}\int_0^\pi \cos{nx} \, dx + \sum_{m=1}^\infty a_m \int_0^\pi \cos{mx} \cdot \cos{nx} \, dx$$
$\int_0^\pi f(x) \cos{nx} \, dx = a_n \frac{\pi}{2}$, so $a_n = \frac{2}{\pi} \int_0^\pi f(x) \cos{nx} \, dx$.
We write: $f(x) \sim \frac{a_0}{2} + \sum_{n=1}^\infty a_n \cos{nx}$, where $a_n=\frac{2}{\pi} \int_0^\pi f(x)\cos{nx} \, dx$ for $n\in\mb N$.

\begin{example}
	Consider $f(x) = x$ on $(0,\pi)$, $f\in C_p(0,\pi)$. Then
	$$a_0 = \frac{2}{\pi}\int_0^\pi x \, dx = \frac{2}{\pi} \frac{x^2}{2}\bigg\rvert_0^\pi = \pi$$
	Set $x=u$ and $\cos nx = dv$ so that
	$$a_n = \frac{2}{\pi}\int_0^\pi x\cos{nx} \, dx = \frac{2}{\pi} x \frac{1}{n} \sin{nx} \bigg\rvert_0^\pi - \frac{2}{\pi} \frac{1}{n} \int_0^\pi \sin{nx} \, dx = \frac{2}{\pi} \frac{1}{n^2} \cos{nx}\bigg\rvert_0^\pi = \frac{2}{n^2\pi} \left( (-1)^n - 1\right)$$
	So $x\sim \frac{\pi}{2} + \frac{2}{\pi}\sum_{n=1}^\infty \frac{1}{n^2}((-1)^n-1) \cos{nx}$, where even index terms are 0. So we re-index $n=2k-1$ with $$x\sim \frac{\pi}{2} + \frac{2}{\pi} \sum_{k=1}^{\infty}\frac{-2}{(2k-1)^2}\cos(2k-1)x.$$
\end{example}

\underline{Assume} $f$ has a Fourier sine series
$$f(x) = \sum_{n=1}^\infty b_n \sin{nx}$$
for $0<x<\pi$.
We can determine a formula for $b_n$ just like for the cosine series.
In HW you show $\int_0^\pi \sin{mx} \sin{nx} \, dx = \begin{cases}0 &\text{if }m\neq n \\ \pi/2 &\text{if }m=n\end{cases}$.
Write $f(x) = \sum_{m=1}^{\infty} b_m \sin{mx}$. Multiply by $\sin{nx}$ and integrate
$$ \int_0^\pi f(x) \sin{nx} \, dx = \sum_{m=1}^\infty b_m \int_0^\pi \sin{mx} \sin{nx} \, dx = b_n \frac{\pi}{2},$$
so $b_n = \frac{2}{\pi}\int_0^\pi f(x) \sin{nx} dx$.

\begin{example}
	Calculate Fourier sine series for $f(x)=x$ on $(0,\pi)$
	$$b_n = \frac{2}{\pi}\int_0^\pi x\sin{nx} \, dx = \frac{2}{\pi} \left(x\frac{-1}{n} \cos{nx}\bigg\rvert_0^\pi + \frac{1}{n}\int_0^\pi \cos{nx} \, dx\right) = \frac{2}{\pi}\frac{-\pi}{n}(-1)^n=\frac{2}{n}(-1)^{n+1}$$
	So $x\sim \sum_{n=1}^\infty \frac{(-1)^{n+1}}{n}\sin{nx}$.
\end{example}

\begin{note}
	Observe, even though $f(x)$ is only defined on $(0,\pi)$, the Fourier sine or cosine series are defined for all $x\in(-\infty,\infty)$.
	So on $(0,\pi)$, the series is 'equal' to $f(x)$. What does the series look like outside the interval?
\end{note}
\begin{note}
	Note that every term in cosine series is an even function and every term in sine series is odd.
\end{note}
\begin{example}
	$f(x) = x$ on $(0,\pi)$, $f(x) = $ cosine series. So on $(-\pi,\pi)$, the cosine series will be the even extension of $f$. It can also be extended periodically on the entire $x$-axis.
\end{example}
\begin{example}
	Assuming on $[0,\pi)$ that the Fourier sine series converges. Then on $(-\infty,\infty)$.
\end{example}

Last time: Fourier cosine + sine series on $0<x<\pi$.
\begin{align} f(x) &\sim \frac{a_0}{2} + \sum_{n=1}^{\infty} a_n \cos{nx}, \qquad a_n=\frac{2}{\pi} \int_0^\pi f(s) \cos{ns} \, ds \\
f(x) &\sim \sum_{n=1}^{\infty} b_n \sin{nx}, \qquad b_n \frac{2}{\pi} \int_0^\pi f(s) \sin{ns} \, ds\end{align}
with even, odd, periodic extensions.

Thus, we can construct a Fourier series on $-\pi<x<\pi$ for any even or odd function.

What about other functions?
Let $f\in C_p(-\pi,\pi)$.
Observe $f(x) = g(x) + h(x)$, where $g(x) = \frac{f(x) + f(-x)}{2}$ and $h(x) = \frac{f(x) - f(-x)}{2}$. Then $g$ is even and $h$ is odd.
Thus, $g(x) \sim \frac{a_0}{2} + \sum_{n=1}^\infty a_n \cos{nx}$ and $h(x)\sim\sum_{n=1}^\infty b_n \sin{nx}$.
If the series converge on $0<x<\pi$, then they also converge on $-\pi<x<\pi$. So \begin{equation}f(x) \sim \frac{a_0}{2} + \sum_{n=1}^\infty \left( a_n \cos{nx} + b_n \sin{nx}\right) \label{eqn1} \end{equation} on $-\pi < x < \pi$.
Set $x=-s$.
Observe that \begin{align*}a_n &= \frac{2}{\pi} \int_0^\pi g(x)\cos{nx} \, dx = \frac{1}{\pi} \left[ \int_0^\pi f(x) \cos{nx} \, dx + \int_0^\pi f(-s) \cos{ns} \, ds \right] \\ &=\frac{1}{\pi} \left[ \int_0^\pi f(x) \cos{nx}\, dx + \int_{-\pi}^0 f(x) \cos{nx} dx \right] = \frac{1}{\pi} \int_{-\pi}^\pi f(x) \cos{nx} \, dx .\end{align*}

Similarly,
\begin{align*}
b_n = \frac{1}{\pi} \int_{-\pi}^{\pi} f(x) \sin{nx} \, dx.
\end{align*}

Equation (\ref{eqn1}) is called the Fourier series for $f$ on $-\pi < x <\pi$. If $f$ is even, it reduces to Fourier cosine series on $0<x<\pi$. If $f$ is odd it reduces to Fourier sine series on $0<x<\pi$.

\begin{recall}
	$\cos{(A-B)} = \cos{A} \cos{B} + \sin{A} \sin{B}$.
\end{recall}

From equation (\ref{eqn1}),
\begin{align*} f(x) &\sim \frac{1}{2\pi} \int_{-\pi}^\pi f(s) \, ds + \frac{1}{\pi} \sum_{n=1}^\infty \left[ \cos{nx} \int_{-\pi}^\pi f(s) \cos{ns} \, ds + \sin{nx} \int_{-\pi}^\pi f(s) \sin{ns} \, ds \right] \\
&\sim \frac{1}{2\pi} \int_{-\pi}^\pi f(s) \, ds + \frac{1}{\pi} \sum_{n=1}^\infty \int_{-\pi}^\pi f(s) \left[ \cos{ns}\cos{nx} + \sin{ns}\sin{nx} \right] \, ds \\
&\sim \frac{1}{2\pi} \int_{-\pi}^\pi f(s) \, ds + \frac{1}{\pi} \sum_{n=1}^\infty \int_{-\pi}^\pi f(s) \cos{n(s-x)} \, ds .\end{align*}
Will be useful later in convergence proof.

\begin{example}
	$f(x) = \begin{cases} 0 & -\pi<x<0 \\ \pi & 0<x<\pi \end{cases}$. Then	\begin{align*}a_0 &= \frac{1}{\pi} \int_{-\pi}^\pi f(x) \, dx = \frac{1}{\pi} \int_{-\pi}^\pi \pi \, dx = \pi, \\
	a_n &= \frac{1}{\pi} \int_{-\pi}^\pi f(x) \cos{nx} \, dx = \frac{\pi}{\pi} \int_0^\pi \cos{nx}\, dx = 0, \\
	b_n &= \frac{1}{\pi} \int_{-\pi}^\pi f(x) \sin{nx} \, dx = - \frac{1}{n} \cos{nx} \big\rvert_0^\pi = \begin{cases} \frac{2}{n} & n \text{ odd} \\ 0 & n \text{ even} \end{cases}, \\
	f(x) &\sim \frac{\pi}{2} + \sum_{n=1}^\infty b_n \sin{nx} = \frac{\pi}{2} + 2\sum_{k=1}^\infty \frac{1}{2k-1} \sin{(2k-1)x} .
	\end{align*}
	\begin{note}
		$f(x) - \frac{\pi}{2}$ is odd, only requiring terms from the Fourier sine series.
	\end{note}
\end{example}

More general intervals of form $-c<x<c$.
Let $f\in C_p(-c,c)$. Change of variables to interval $-\pi < s <\pi$.
Define $g(s) = f(\frac{cs}{\pi})$, so $-c<\frac{cs}{\pi}<c$. Use $x=\frac{cs}{\pi}$, $s=\frac{\pi x}{s}$.
$f(x) = f(\frac{cs}{\pi}) = g(s) \sim \frac{a_0}{2} + \sum_{n=1}^\infty \left[ a_n \cos{ns} + b_n \sin{ns} \right]$ on $-\pi < s< \pi$, where $a_n = \frac{1}{\pi} \int_{-\pi}^\pi f(\frac{cs}{\pi}) \cos{ns} \, ds$ and $b_n = \frac{1}{\pi} \int_{-\pi}^\pi f(\frac{cs}{\pi}) \sin{ns} \, ds$. By change of variables, $$ f(x) \sim \frac{a_0}{2} + \sum_{n=1}^\infty \left[ a_n \cos{\frac{n\pi x}{c}} + b_n \sin{\frac{n\pi x}{c}} \right]$$ where $a_n = \frac{1}{\pi} \frac{\pi}{c} \int_{-c}^c f(x) \cos{n\pi x}{c} \, dx$ and $b_n = \frac{1}{c} \int_{-c}^c f(x) \sin{\frac{n\pi x}{c}} \, dx$.

Homework: Sec. 7 p.18: 2,3,4; Sec. 8 p.22: 3,4 (Tuesday)

\section{Convergence of Fourier Series}

Goal is to prove a Fourier theorem-
conditions on $f(x)$ which guarantee convergence of Fourier series for $f$.
Also analyze convergence behavior. Develop theory for $-\pi<x<\pi$ then extend to $-c<x<c$.

\begin{recall}
	$f'(x_0) = \lim_{x\ra x_0} \frac{f(x)-f(x_0)}{x-x_0}$ provided the limit exists.
\end{recall}
Notation for one-sided limits: $g(x_0+) = \lim_{x\ra x_0^+} g(x)$ and $g(x_0-) = \lim_{x\ra x_0^-} g(x)$.
\begin{definition}
	Suppose $f(x_0+)$ exists. Then the \underline{right hand derivative} of $f$ at $x_0$ is \begin{equation}f_+'(x_0) = \lim_{x\ra x_0^+} \frac{f(x)-f(x_0+)}{x-x_0}\end{equation} provided the limit exists.
	Similarly if $f(x_0-)$ exists, then the \underline{left hand derivative} is \begin{equation}f_-'(x_0) = \lim_{x\ra x_0^-} \frac{f(x)-f(x_0-)}{x-x_0}\end{equation} if it exists.
\end{definition}
\begin{note}
	$f(x_0)$ need not be defined. Other texts do require $f(x_0)$ to be defined.
\end{note}
\begin{note}
	If ordinary derivative exists at $x_0$, then $f$ is continuous at $x_0$ and $f_+'(x_0)=f_-'(x_0) = f'(x_0)$.
\end{note}
Converse not necessarily true: $f(x) = \begin{cases} 0 & x<0 \\ 1 & x\geq 0 \end{cases}$, so $f_+'(0)=0$ and $f_-'(0)=0$ but $f'(0)$ does not exist and $f$ is not continuous at $x=0$.
\begin{note}
	Usual derivative rules apply to right + left hand derivatives.
\end{note}

\begin{definition}
	$C_p^1(a,b) = \{f\in C_p(a,b):f'\in C_p(a,b)\} = \{f: f\text{ is piecewise smooth (PWS)}\}$.
\end{definition}
\begin{theorem}
	If $f\in C_p^1(a,b)$, then at each point $x_0\in(a,b)$, the one-sided derivatives exist and \begin{align} f_+'(x_0) &= f'(x_0+), &\qquad f_-'(x_0) &= f'(x_0-).\end{align}
\end{theorem}
\begin{proof}
	If $f$ is PWS, then $f$ and $f'$ are continuous on the interiors of subintervals.
	It is sufficient to prove this at the end points assuming $f,f'$ are continuous on $(a,b)$.
	We will show $f_+'(a)$ exists and equal to $f'(a+) = \lim_{x\ra a^+} f'(x)$.
	Let $s\in(a,b)$. Since $f'$ is continuous on $(a,b)$, by mean value theorem (MVT) $\frac{f(s)-f(a+)}{s-a} = f'(c)$ for some $c\in(a,s)$.
	As $s\ra a^+$, then $c\ra c^+$. This tells us $ f_+'(a) = \lim_{s\ra a+} \frac{f(s) - f(a+)}{s-a} = \lim_{s\ra a+} f'(c) = \lim_{c\ra a+} f'(c) = f'(a+)$.
	Similarly $f_-'(b) = f'(b-)$.
\end{proof}
\begin{example}
	$f(x) = \begin{cases} x^2\sin{\left(\frac{1}{x}\right)} & x\neq 0 \\ 0 & x=0 \end{cases}$
	\begin{note}
		$f(0+) = 0 = f(0-)$, so $f$ is continuous on $\mb R$ for all $x$.
	\end{note}
	For $x\neq 0$, $f$ is differentiable and $f'(x) = 2x\sin{\left(\frac{1}{x}\right)} - \cos{\left(\frac{1}{x}\right)}$.
	One sided limits of $f'$ do not exist at $x=0$, so $f'(0+)$ does not exist but $f_+'(0)=\lim_{x\ra 0+} \frac{f(x)-f(0+)}{x-0} = \lim_{x\ra 0+} x \sin{\frac{1}{x}}=0$ as with $f_-'(0)=\cdots=0$. In other words, $f\notin C_p^1(a,b)$ if $0\in [a,b]$.
\end{example}

\begin{recall}
	We have numerical evidence that Fourier coefficients satisfy $a_n\ra0$ and $b_n\ra 0$.
\end{recall}
Geometric argument: If $f(x) = c$ is constant, then $a_n=\frac{2}{\pi} c\int_0^\pi \cos{nx}\, dx = 0$. When $f$ is not constant, it is \say{almost} constant over small subintervals.

Let $f\in C_p(a,b)$ and $a_n=\frac{2}{\pi} \int_0^\pi f(x) \cos{nx} \, dx$ for $n=0,1,\dots$ with the partial sum $S_N$ defined as $S_N(x) = \frac{a_0}{2} + \sum_{n=1}^N a_n \cos{nx}$.
Then $\int_0^\pi \left[ f(x) - S_N(x) \right]^2 \, dx = \int_0^\pi \left[ f(x) \right]^2 \, dx + \int_0^\pi \left[ S_N(x) \right]^2 \, dx - 2\int_0^\pi f(x) S_N(x) \, dx$.
\begin{align*}I_N &= \int_0^\pi f(x) S_N(x) \, dx = \frac{a_0}{2} \int_0^\pi f(x) \, dx + \sum_{n=1}^N a_n \int_0^\pi f(x) \cos{nx} \, dx = \frac{\pi}{2} \left[ \frac{a_0^2}{2} + \sum_{n=1}^N a_n^2 \right] \end{align*}
For $J_N$: $\int_0^\pi S_N(x)\cdot1\,dx = \int_0^\pi \left[ \frac{a_0}{2} + \sum_{n=1}^N a_n \cos{nx} \right] \, dx = \frac{a_0}{2}$
and $$\int_0^\pi S_N(x) \cdot \cos{nx} \, dx = \int_0^\pi \left[ \frac{a_0}{2} + \sum_{m=1}^N a_m \cos{mx} \right] \cos{nx} \, dx = \frac{\pi}{2} a_n.$$
So $J_N = \int_0^\pi \left[ S_N(x) \right]^2 \, dx = \int_0^\pi S_N(x) S_N(x) \, dx $ and $$J_N = \frac{a_0}{2} \int_0^\pi S_N(x)\, dx + \sum_{n=1}^N a_n \int_0^\pi S_N(x) \cos{nx} \, dx = \frac{\pi}{2} \left[ \frac{a_0^2}{2} + \sum_{n=1}^N a_n^2 \right].$$
So $0\leq \int_0^\pi \left[ f(x) - S_N(x) \right]^2 \, dx = \int_0^\pi [f(x)]^2\, dx - \frac{\pi}{2} \left[ \frac{a_0^2}{2} + \sum_{n=1}^N a_n^2 \right]$.
So \begin{equation}0\leq \frac{a_0^2}{2} + \sum_{n=1}^N a_n^2 \leq \frac{2}{\pi} \int_0^\pi [f(x)]^2 \, dx\end{equation} for all $N=1,2,\dots$. This is known as \underline{Bessel's inequality}. The partial sums form a non-decreasing sequence bounded above, hence converges. Hence, series (sequence of partial sums) converges.
$\frac{a_0^2}{2} + \sum_{n=1}^\infty a_n^2 <\infty$. Thus $a_n^2\ra 0$, so $a_n\ra0$.

HW Sect. 11, p.33: 1,2,4

\section{Fourier Theorem}

\underline{Last time}: one-sided derivatives, Bessel's inequality: $ \displaystyle \frac{a_0}{2} + \sum_{n=1}^\infty a_n^2 \leq \frac{2}{\pi} \int_0^\pi [f(x)]^2 \, dx$, this implies $\displaystyle \lim_{n\ra\infty} a_n =0$, similarly for Fourier sine coefficients $b_n$.

\begin{lemma}
	[Riemann-Lebesgue] If $G(u)$ is PWC on $0<u<\pi$ then $ \displaystyle \lim_{N\ra\infty} \int_0^\pi G(u) \sin\left(\frac{u}{2} + Nu\right) \, du =0$.
\end{lemma}
\begin{proof}
	Observe $\displaystyle \sin\left(\frac{u}{2}+Nu\right) = \sin{\frac{u}{2}}\cos{Nu}+\cos{\frac{u}{2}}\sin{Nu}$. Hence \begin{align*}\int_0^\pi G(u) \sin \left(\frac{u}{2} + Nu\right) \, du &= \frac{\pi}{2} \cdot \frac{2}{\pi} \int_0^\pi \left[ G(u) \sin{\frac{u}{2}} \right] \cos{Nu} \, du + \frac{\pi}{2} \cdot \frac{2}{\pi} \int_0^\pi \left[ G(u) \cos{\frac{u}{2}}\right] \sin{Nu} \, du \\ &=\frac{\pi}{2} a_n + \frac{\pi}{2} b_n, \end{align*} where $a_n$ is Fourier cosine coefficient for $G(u)\sin{\frac{u}{2}}$ and $b_n$ is Fourier sine coefficient for $G(u)\cos{\frac{u}{2}}$. By previous result, $a_n\ra 0$ and $b_n\ra 0$ as $N\ra\infty$.
\end{proof}
\begin{definition}
	[Dirichlet Kernel] $\displaystyle D_N(u) = \frac{1}{2} + \sum_{n=1}^N \cos{nu}$. Observe
	\begin{enumerate}
		\item $D_N(u)$ is continuous, even, and has period $2\pi$.
		\item $\int_0^\pi D_N(u) \, du = \frac{\pi}{2}$.
		\item $\displaystyle D_N(u) = \frac{\sin{\left(\frac{u}{2} + Nu\right)}}{2\sin{\frac{u}{2}}}$, $u\neq 2n\pi$, $n=0,\pm1,\pm2,\dots$.
	\end{enumerate}
	To see this: $\sin{(A+B)} = [\sin{A} \cos B + \cos A \sin B]$ and $\sin(A-B) = [\sin A \cos B - \cos A \sin B] $
	and $2\sin A \cos B = [\sin(A+B) + \sin(A-B)]$. So \begin{align*}
	2\sin{\frac{u}{2}} D_N(u) &= \sin{\frac{u}{2}} + 2 \sum_{n=1}^N \sin{\frac{u}{2}}\cos{nu} = \sin{\frac{u}{2}} + \sum_{n=1}^N \left[ \sin{\left(\frac{u}{2} + nu \right)} + \sin{\left(\frac{u}{2} - nu \right)} \right] \\ &= \sin{\frac{u}{2}} + \left[ \left( \sin{\frac{3}{2}u} - \sin{\frac{u}{2}} \right) + \left(\sin{\frac{5}{2}u}-\sin{\frac{3}{2}u} \right) + \cdots + \left( \sin{\frac{2N+1}{2}u} - \sin{\frac{2N-1}{2}u} \right) \right] \\ & = \sin{\left(\frac{u}{2}+Nu\right) },\end{align*}
	which is a telescoping sum.
\end{definition}
\begin{lemma}
	Suppose $g(u)$ is PWC on $(0,\pi)$ and $g_+'(0)$ exists. Then $\lim_{N\ra\infty} \int_0^\pi g(u) D_N(u) \, du = \frac{\pi}{2} g(0+)$.
\end{lemma}
\begin{proof} Since $g(u)=g(u)-g(0+)+g(0+)$, define $I_N$ and $J_N$ by
	\begin{align*} \int_0^\pi g(u) D_N(u) \, du &= \int_0^\pi [g(u) - g(0+)]D_N(u)\, du + \int_0^\pi g(0+) D_N(u) \, du = I_N + J_N. \end{align*}
	Then $\displaystyle I_N = \int_0^\pi [g(u) - g(0+)] \frac{\sin{\left(\frac{u}{2}+Nu\right)}}{2\sin{\frac{u}{2}}}\, du = \int_0^\pi G(u) \sin{\left(\frac{u}{2} + Nu\right)} \, du, $
	where $\displaystyle G(u) = \frac{g(u)-g(0+)}{2\sin{\frac{u}{2}}}$.
	From the Riemann-Lebesgue lemma, we know that $\lim_{N\ra\infty} = 0$ as long as $G(u)$ is PWC on $(0,\pi)$.
	One possible problem is at $u=0$, where denominator is 0. $G(u)$ is PWC on $(0,\pi)$ as long as $\displaystyle G(0+) = \lim_{u\ra0+} G(u)$ exists. $\displaystyle G(0+) = \lim_{u\ra0+} \frac{g(u)-g(0+)}{u} \cdot \frac{u}{2\sin{\frac{u}{2}}}$. But $\displaystyle \lim_{u\ra0+} \frac{g(u)-g(0+)}{u}$ exists because it is $g_+'(0)$ which is assumed to exist. And $\displaystyle \lim_{u\ra0+} \frac{u}{2\sin{\frac{u}{2}}} = 1$. Also $J_N = g(0+) \int_0^\pi D_N(u) \, du = \frac{\pi}{2} g(0+)$.
\end{proof}

Given $f\in C_p(-\pi,\pi)$, use notation $\displaystyle S(x) = \frac{a_0}{2} + \sum_{n=1}^\infty [a_n \cos{nx} + b_n\sin{nx}]$, where $a_n = \frac{1}{\pi} \int_{-\pi}^\pi f(x) \cos{nx} \, dx$ for $n=0,1,\dots$ and $b_n = \frac{1}{\pi} \int_{-\pi}^\pi f(x) \sin{nx} \, dx$. Also define partial sum $S_N(x) = \frac{a_0}{2} + \sum_{n=1}^N [ a_n \cos{nx} + b_n \sin{nx}]$. Observe: \begin{align*} S_N(x) &= \frac{1}{2\pi}\int_{-\pi}^\pi f(x) \, dx + \frac{1}{\pi} \sum_{n=1}^N \left[ \cos{nx} \int_{-\pi}^\pi f(s) \cos{ns}\, ds + \sum_{n=1}^N f(s) \sin{ns} \, ds \right] \\ &= \frac{1}{2\pi} \int_{-\pi}^\pi f(x) \, dx + \frac{1}{\pi} \sum_{n=1}^N \int_{-\pi}^\pi f(s) [\cos{nx}\cos{ns} + \sin{nx}\sin{ns}] \, ds \\ &= \frac{1}{2\pi} \int_{-\pi}^\pi f(x) \, dx + \frac{1}{\pi} \sum_{n=1}^N \int_{-\pi}^\pi f(s) \cos{n(s-x)} \, ds .\end{align*}

\begin{theorem}
	Let $f$ be PWC on $(-\pi,\pi)$, and is periodic with period $2\pi$ on $\mb R$. The Fourier series for $f$ converges to the mean value \begin{equation}\frac{f(x+)-f(x-)}{2}\label{eqn2}\end{equation} at each $x\in(-\infty,\infty)$ where both one sided derivatives $f_+'(x)$ and $f_-'(x)$ exist.
\end{theorem}
\begin{note}
	When $f$ is continuous at $x$, then equation (\ref{eqn2}) $= f(x)$, so Fourier series converges to $f(x)$.
\end{note}
\begin{proof}
	We want to show $S_N(x) \ra \frac{f(x+) + f(x-)}{2}$. We will set $x\pm\pi $ because $f$, $D_N$ are period $2\pi$: \begin{align*} S_N(x) &= \frac{1}{2\pi} \int_{-\pi}^\pi f(x) \, dx + \frac{1}{\pi} \sum_{n=1}^N \int_{-\pi}^\pi f(s) \cos{n(s-x)}\, ds = \frac{1}{\pi} \int_{-\pi}^\pi f(s) \left[ \frac{1}{2} + \sum_{n=1}^N \cos{n(s-x)} \right] \, dx \\ &= \frac{1}{\pi}\int_{-\pi}^\pi f(s) D_N(s-x) \, ds = \frac{1}{\pi} \int_{x-\pi}^{x+\pi} f(s) D_N(s-x) \, ds = \frac{1}{\pi} [I_N + J_N ], \end{align*} where $I_N = \int_x^{x+\pi} f(s) D_N(s-x)\, ds$ and $J_N = \int_{x-\pi}^x f(s) D_N(s-x) \, ds$. Consider $I_N$: Let $u=s-x$, so $\displaystyle I_N = \int_0^\pi f(x+u) D_N(u)\, du = \int_0^\pi g(u) D_N(u)\, du$, where $g(u) = f(x+u)$.
	Observe $g$ is PWC on $(0,\pi)$. Also, $\displaystyle g_+'(0) = \lim_{u\ra0+} \frac{g(u)-g(0+)}{u} = \lim_{u\ra0+} \frac{f(x+u)-f(x+)}{u} = \lim_{v\ra x+} \frac{f(v) - f(x+)}{v-x} = f_+'(x)$, which \underline{exists}. We can apply the previous theorem, which says $\displaystyle \lim_{N\ra\infty} I_N = \lim_{N\ra\infty} \int_0^\pi g(u) D_N(u) \, du = \frac{\pi}{2} g(0+) = \frac{\pi}{2} f(x+)$. Similarly, for $J_N$ we get $\displaystyle{\lim_{N\ra\infty}} J_N $ $= \frac{\pi}{2} f(x-)$. $S_N(x) = \frac{1}{\pi} [I_N + J_N]$, so $S_N(x) \ra \frac{1}{2} f(x+) + \frac{1}{2} f(x-)$.
\end{proof}

Last time: Proved a Fourier theorem, conditions on $f(x)$ which guarantee Fourier series converges.
\begin{corollary}
	Let $f$ be PWS on $(-\pi,\pi)$ and let $F(x)$ be $2\pi$-periodic extension to $(-\infty,\infty)$. At each $x\in(-\infty,\infty)$, the Fourier series (for $f(x)$ on $(-\pi,\pi)$) converges to $\frac{F(x+)+F(x-)}{2}$.
\end{corollary}
\begin{example}
	$f(x)=x$ on $(-\pi,\pi)$. $f$ is PWS on $(-\pi,\pi)$. Let $F(x)$ be $2\pi$-periodic extension.
	The Fourier series for $f(x)$ is $S(x) = 2\sum_{n=1}^\infty \frac{(-1)^{n+1}}{n}\sin{nx}$ (Example 5.1).
	At $x = \frac{\pi}{2} = 2\sum_{n=1}^{\infty} \frac{(-1)^{n+1}}{n}\sin{\left(\frac{n\pi}{2}\right)}$, where all even terms are 0. $\frac{\pi}{4} = \sum_{k=1}^\infty \frac{(-1)^{2k}}{2k-1} \sin{\frac{(2k-1)\pi}{2}} = \sum_{k=1}^\infty \frac{(-1)^{k+1}}{2k-1} = 1-\frac{1}{3} + \frac{1}{5} - \frac{1}{7}\cdots$.
\end{example}

\begin{example}
	$f(x) = \begin{cases} 0 & -\pi<x\leq 0 \\ x & 0<x<\pi \end{cases}$. We know from Example 7.1 that the Fourier series is $$S(x) = \frac{\pi}{4} + \sum_{k=1}^\infty \left[ \frac{(-1)^n-1}{\pi n^2}\cos{nx} + \frac{(-1)^{n+1}}{n}\sin{nx}\right].$$ $f$ is PWS on $(-\pi,\pi)$ ($f'$ not exist at 0). At $x=\pi$, $S(\pi) = \frac{\pi}{2}$. So $\frac{\pi}{2} = \frac{\pi}{4} + \sum_{n=1}^\infty \frac{(-1)^n-1}{\pi n^2} \cos{n\pi} + 0$. $\frac{\pi^2}{4} = \sum_{n=1}^\infty \frac{1-(-1)^n}{n^2} = \sum_{k=1}^\infty \frac{2}{(2k-1)^2}$ and $\frac{\pi^2}{8} = 1 + \frac{1}{9} + \frac{1}{25} + \cdots$.
\end{example}

Other Intervals.
Given $f(x)$ on $-c<x<c$, we use $g(s) = f\left(\frac{cs}{\pi}\right)$ using $x=\frac{cs}{\pi}$. $g$ defined on $-\pi<s<\pi$. Apply results to $g$, then translate them back to $f$.
\begin{theorem}
	Suppose $f$ is PWS on $(-c,c)$. Let $F(x)$ be the $2c$-periodic extension of $f(x)$. Def. Fourier series
	$S(x) = \frac{a_0}{2} + \sum_{n=1}^\infty \left[ a_n \cos{\left(\frac{n\pi x}{c}\right)} + b_n \sin{\left(\frac{n\pi x}{c} \right)} \right]$
	where $a_n = \frac{1}{c} \int_{-c}^c f(x) \cos{\frac{n\pi x}{c}} \, dx$, $b_n = \frac{1}{c} \int_{-\pi}^\pi f(x) \sin{\frac{n\pi x}{c}} \, dx$. Then the Fourier series converges to $\frac{F(x+)-F(x-)}{2}$ for all $x\in (-\infty,\infty)$.
\end{theorem}

Next: further investigation of convergence \say{behavior}.
\begin{example}
	$f(x) = \begin{cases} 0 & -\pi<x<0 \\ 1 & 0<x<\pi \end{cases}$. Fourier series is $S(x) = \frac{1}{2} + \frac{2}{\pi} \sum_{n=1}^\infty \frac{\sin{(2n-1)x}}{2n-1}$ (use problem 7.2).
\end{example}
\begin{example}
	$f(x) = x^2 $ on $-\pi<x<\pi$
	\begin{note}
		$F(x)$ is continuous.
	\end{note}
\end{example}

Last time: Fourier theorem on other intervals, numerical investigation of convergence, Gibb's phenomenon, \say{nonuniform} convergence.

Next we consider further the convergence behavior of  Fourier series.
Since a Fourier series is a sequence of partial sums of functions, that is, a sequence of functions, we begin with convergence for sequences of functions.
Let $\{g_n(x)\}_{n=1}^\infty$ be a sequence of functions on domain $E$ and let $g(x)$ also be a function on $E$.
\begin{definition}
	We say $\{g_n\}$ \underline{converges point-wise} to $g(x)$ on $E$ if $\lim_{n\ra\infty} g_n(x) = g(x)$ for each fixed $x\in E$.
	This means for each $x\in E$ and any $\epsilon>0$, there exists $N = N(\epsilon,x)$ such that if $n\geq N$, then $|g_n(x) - g(x)|<\epsilon$.
\end{definition}
\begin{definition}
	We say $\{g_n\}$ converges \underline{uniformly} to $g$ on $E$ if for any $\epsilon>0$ there exists $N(\epsilon)$ such that if $n\geq N$, then $|g_n(x)-g(x)|<\epsilon$ for all $x\in E$.
\end{definition}
\begin{note}
	$N$ does not depend on $x$.
\end{note}
\begin{example}
	$g_n(x) = \begin{cases} 1-nx &0\leq x\leq \frac{1}{n} \\ 0 & \frac{1}{n} \leq x \leq 1	\end{cases}$. $\{g_n\}$ converges point-wise to $g(x) = \begin{cases} 1 & x=0 \\ 0 & 0<x\leq1 \end{cases}$ but not uniformly.
\end{example}
\begin{note}
	If each $g_n(x)$ is continuous on $E$ and $g_n \ra g(x)$ uniformly on $E$, then $g$ is continuous on $E$.
\end{note}
Let's apply ideas to series of functions. Consider sequence $\{f_n(x)\}_{n=1}^\infty$ on $a\leq x\leq b$. Define partial sums $S_N(x) = \sum_{n=1}^N f_n(x)$.
The series $S(x) = \sum_{n=1}^\infty f_n(x)$ converges if the sequence $S_N(x)$ converges point-wise to $S(x)$.
\begin{note}
	Our Fourier theorem showed point-wise convergence.
\end{note}
The series converges uniformly on $a\leq x\leq b$ if for any $\epsilon>0$ there exists $N$ such that if $n\geq N$, then $|\sum_{k=1}^n f_k(x) - S(x)|<\epsilon$.

To show this type of convergence it is often useful to use Weierstrass M-test: If there is a convergent series (of positive real numbers) $\sum_{n=1}^\infty M_n < \infty$ such that $|f_n(x)|\leq M_n$ for each $n$ and all $x\in[a,b]$, then $\sum_{n=1}^\infty f_n(x)$ is uniformly convergent on $[a,b]$.
\begin{theorem}
	Let $f$ be a function satisfying:
	\begin{enumerate}
		\item $f$ is continuous on $-\pi\leq x \leq \pi$
		\item $f(-\pi) = f(\pi)$
		\item $f'$ is PWC on $-\pi< x < \pi$.
	\end{enumerate}
	The Fourier series $\frac{a_0}{2} + \sum_{n=1}^\infty (a_n\cos{nx}+b_n\sin{nx})$, where $a_n=\frac{1}{\pi}\int_{-\pi}^\pi f(x) \cos{nx}\, dx$ and \\ $b_n=\frac{1}{\pi} \int_{-\pi}^\pi f(x) \sin{nx}\, dx$, converges uniformly to $f(x)$ on $-\pi \leq x \leq \pi$.
\end{theorem}
\begin{proof}
	Observe that $|a_n \cos{nx} + b_n\sin{nx} | \leq |a_n\cos{nx}| + |b_n\sin{nx}|\leq |a_n|+ |b_n| \leq 2\sqrt{a_n^2+b_n^2}$. the result follows from Weierstrass M-test once we verify that $\sum_{n=1}^\infty 2\sqrt{a_n^2 + b_n^2} <\infty$ (next).
\end{proof}
\begin{definition}
	%\underline{Aside}:
	[Cauchy-Schwarz inequality] $|\langle p,q\rangle |\leq ||p||\cdot||q||$ on $\mb R^N$ with Euclidean norm $\vp = \mat{ p_1 & \cdots & p_N}$ and $\vq = \mat{q_1 & \cdots & q_N}$. Then
	\begin{align*}
		\left|\sum_{n=1}^N p_nq_n\right| &\leq \sqrt{\sum_{n=1}^N p_n^2}\sqrt{\sum_{n=1}^N{q_n^2}}, \qquad & \qquad
		\left| \sum_{n=1}^N p_n q_n \right|^2 &\leq \sum_{n=1}^N p_n^2 \sum_{n=1}^N q_n^2.
	\end{align*}
\end{definition}
%\underline{End aside}.
\begin{lemma}
	Assume hypotheses on $f$ from previous theorem. Then $\sum_{n=1}^\infty \sqrt{a_n^2+b_n^2}<\infty$.
\end{lemma}
\begin{proof}
	Since $f'$ is PWC, its Fourier series exists with coefficients $\alpha_n = \frac{1}{\pi}\int_{-\pi}^\pi f'(x) \cos{nx}$ and \\ $\beta_n = \frac{1}{\pi} \int_{-\pi}^\pi f'(x) \sin{nx} \, dx$. Observe: $\alpha_0 = \frac{1}{\pi} \int_{-\pi}^\pi f'(x) \, dx = \frac{1}{\pi}[f(\pi)-f(-\pi)] = 0$.
	For $n=1,2,\dots$ \begin{align*}\alpha_n &= \frac{1}{\pi} \int_{-\pi}^\pi f'(x) \cos{nx} \,dx = \frac{1}{\pi} \left[ f(x)\cos{nx}\bigg\rvert_0^\pi + n\int_{-\pi}^\pi f(x)\sin{nx}\, dx \right] = nb_n, \\ \beta_n &= \frac{1}{\pi} \int_{-\pi}^\pi f'(x) \sin{nx} \, dx = \frac{1}{\pi} \left[ f(x)\sin{nx} \bigg\rvert_{-\pi}^\pi - n\int_{-\pi}^\pi f'(x)\cos{nx} \, dx \right] = -na_n. \end{align*}
	We have $T_N = \sum_{n=1}^N \sqrt{a_n^2 + b_n^2} = \sum_{n=1}^N \frac{1}{n}\sqrt{\alpha_n^2 + \beta_n^2}$. Then
	$$T_N^2 = \left(\sum_{n=1}^N \frac{1}{n}  \sqrt{\alpha_n^2 + \beta_n^2} \right)^2 \leq \left( \sum_{n=1}^N \frac{1}{n^2} \right) \left( \sum_{n=1}^N(\alpha_n^2 + \beta_n^2) \right).$$ Converges to $\zeta(2)$. By Bessel's inequality $\sum_{n=1}^N(\alpha_n^2 + \beta_n^2) \leq \frac{1}{\pi} \int_{-\pi}^\pi [f'(x)]^2 \, dx$.
	Thus $T_N^2$ are increasing and bounded above, so convergent. Thus $T_N$ is convergent. So $\sum_{n=1}^\infty \sqrt{a_n^2 + b_n^2}<\infty$.
\end{proof}
HW Sec 14. p41, 1,2,4,5,6
Sec 15, p45, 1,3.

Last time: conditions under which Fourier series converges uniformly.
We next investigate differentiating Fourier series.

\begin{theorem}
	Let $f$ be a function which satisfies:
	\begin{itemize}
		\item[a.] $f$ is continuous on $-\pi\leq x\leq \pi$
		\item[b.] $f(-\pi)=f(\pi)$
		\item[c.] $f'$ is PWC on $-\pi<x<\pi$
	\end{itemize}
	Then the Fourier series $f(x)=\frac{a_0}{2} + \sum_{n=1}^\infty [a_n\cos{nx} + b_n\sin{nx}]$, where $a_n=\frac{1}{\pi}\int_{-\pi}^\pi f(x) \cos{nx} \, dx$ and $b_n = \frac{1}{\pi} \int_{-\pi}^\pi f(x) \sin{nx}\, dx$, is differentiable at each $x$ in $-\pi<x<\pi$ where $f''(x)$ exists; and in this case $f'(x) = \sum_{n=1}^\infty [-na_n\sin{nx} + nb_n\cos{nx}]$.
\end{theorem}
\begin{proof}
	Fix $x$ such that $f''(x)$ exists. Thus $f'$ is continuous at $x$. Apply Fourier Theorem to $f'$.
	For fixed $x$: $f'(x)=\frac{\alpha_0}{2} + \sum_{n=1}^\infty [\alpha_n \cos{ns} + \beta_n\sin{nx}]$, where $\alpha_n = \frac{1}{\pi}\int_{-\pi}^\pi f'(x) \cos{nx}\, dx$ and $\beta_n = \frac{1}{\pi}\int_{-\pi}^\pi f'(x) \sin{nx} \, dx$.
	From last time: $\alpha_0 = 0$, $\alpha_n = nb_n$, $\beta_n = -na_n$, $n=1,2,\dots$. The result follows.
\end{proof}
\begin{example}
	$f(x) = x$ on $0<x<\pi$.
	Sine series: $S(x) = 2\sum_{n=1}^\infty \frac{(-1)^{n+1}}{n}\sin{nx}$. Calculate derivative term by term. $S'(x) = 2\sum_{n=1}^\infty (-1)^{n+1} \cos{nx}$. This series doesn't even converge for any $x$.
	Cosine series: $C(x) = \frac{\pi}{2} - \frac{4}{\pi} \sum_{n=1}^\infty \frac{\cos{(2n-1)x}}{(2n-1)^2}$. Calculate derivative term by term: $C'(x) = \frac{4}{\pi} \sum_{n=1}^\infty \frac{\sin{(2n-1)x}}{2n-1}$
	\begin{note}
		The odd extension of $f(x) = x$ to $(-\pi,\pi)$ is (plot), $f(-\pi)\neq f(\pi)$. $S(x)$ is the full Fourier series for this function. The even extension $\tilde{f}$ is (plot), satisfies $\tilde{f}(-\pi)=\tilde{f}(\pi)$. $C(x)$ is the full Fourier series for this function. (HW)
	\end{note}
	We can verify that $C'(x)$ is the actual Fourier series for $\tilde{f}'(x) = \begin{cases} -1 & -\pi<x<0 \\ 1 & 0<x<\pi \end{cases}$.
\end{example}
\begin{example}
	Suppose we want to compute Fourier series for $f(x)=x^2$ on $-\pi<x<\pi$. We know it has the form $f(x) = \frac{A_0}{2} + \sum_{n=1}^\infty A_n\cos{nx}$. Rather than compute the $A_n$ directly, we know the series is differentiable and $2x = f'(x) = \sum_{n=1}^\infty -nA_n\sin{nx}$.
	Also we know $2x = 4\sum_{n=1}^\infty \frac{(-1)^{n+1}}{n}\sin{nx}$. So $A_n = \frac{4}{n^2}(-1)^n$.
	Must compute $A_0$ directly: $A_0 = \frac{1}{\pi}\int_{-\pi}^\pi x^2\, dx = \frac{2\pi^2}{3}$. So $x^2 = \frac{\pi^2}{3} + 4\sum_{n=1}^\infty \frac{(-1)^n}{n^2}\cos{nx}$.
\end{example}

%\newpage

\begin{theorem}
	Let $f$ be PWC on $-\pi<x<\pi$ with Fourier series $f(x) = \frac{a_0}{2} + \sum_{n=1}^\infty [ a_n\cos{nx} + b_n\sin{nx}]$. Then term-by-term integration is valid. That is, for any $x\in[-\pi,\pi]$, $$\int_{-\pi}^\pi f(s) \, ds = \frac{a_0}{2}(x+\pi) + \sum_{n=1}^\infty \frac{1}{n}\left[ a_n\sin{nx} - b_n\left(\cos{nx} +(-1)^{n+1} \right)\right]. $$
	\begin{note}
		This may no longer be a Fourier series.
	\end{note}
\end{theorem}
HW: Sec.20 p.58: 1,2,3,5
\begin{example}
	[Quiz 1, Problem 1]
	$f(x) = 1$ on $0<x<\pi$. $$b_n = \frac{2}{\pi}\int_0^\pi\sin{nx}\, dx = \frac{2}{\pi} \left( -\frac{1}{n} \right) \cos{nx} \bigg\rvert_0^\pi = \frac{-2}{n\pi} \left[ (-1)^n-1 \right] = \frac{2}{\pi} [1-(-1)^n] = \begin{cases} \frac{4}{n\pi} & n \text{ odd} \\ 0 & n \text{ even} \end{cases}$$ So $f(x) \sim \sum_{n=1}^\infty b_n \sin{nx} $ and set $n=2k-1$ to get $f(x) = \sum_{k=1}^\infty \frac{1}{2k-1}\sin{(2k-1)x}$.

	The Fourier sine series on $(0,\pi)$ represents the odd extension of $f$ on $(-\pi,\pi)$ and the $2\pi$-periodic extension (of the odd extension) on $(-\infty,\infty)$.
\end{example}

\begin{example}
	[Quiz 2, Problem 1] $f(x) = \frac{\pi}{2} - x$ on $0<x<\pi$. Given Fourier cosine series $f(x) \sim \frac{4}{\pi} \sum_{n=1}^\infty \frac{1}{(2n-1)^2} \cos{(2n-1)x}$. The even extension to $(-\pi,\pi)$ is *graph*.
	Use $S(0)=\frac{\pi}{2}$ to get $\frac{\pi}{2} = \frac{4}{\pi} \sum_{n=1}^\infty \frac{1}{(2n-1)^2}$.
\end{example}
\begin{example}
	[Quiz 2, Problem 2] $S(x)$ is the Fourier series for $f(x) = x^3$ on $-1<x<1$. Find $S(\pi)$. $S(x)$ \say{converges} to periodic extension of period 2 of $F(x) = x^3$. *graph*. So $S(\pi) = (\pi-4)^3$.
\end{example}

\begin{theorem}
	Let $f$ be PWC on $-\pi<x<\pi$, with Fourier series $f(x)\sim \frac{a_0}{2} + \sum_{n=1}^\infty (a_n\cos{nx} + b_n\sin{nx})$. Then term by term integration is valid. That is, for any $x\in[-\pi,\pi]$, $$\int_{-\pi}^\pi f(s)\, ds = \frac{a_0}{2}(x+\pi) + \sum_{n=1}^\infty \frac{1}{n}\left[a_n\sin{nx} + b_n\left( \cos{nx} + (-1)^{n+1} \right) \right].$$
\end{theorem}
\begin{proof}
	Define $F(x) = \int_{-\pi}^x f(s)\, ds - \frac{a_0}{2}x$. $F(x)$ is continuous on $-\pi\leq x\leq \pi$. If $f$ is continuous at $x$, then $F$ is differentiable at $x$ and $F'(x) = f(x) - \frac{a_0}{2}$. Thus $F$ is PWS on $(-\pi,\pi)$, since $f$ is PWC there.
	Also, $F(-\pi) = \frac{a_0\pi}{2}$ and $F(\pi) = \int_{-\pi}^\pi f(s) \, ds - \frac{a_0\pi}{2} = \pi a_0 - \frac{\pi a_0}{2} = \frac{\pi a_0}{2}$. So $F(-\pi) = F(\pi)$. We can apply our Fourier theorem to $F(x)$.
	\begin{equation}
		F(x) = \frac{A_0}{2} + \sum_{n=1}^\infty (A_n\cos{nx} + B_n\sin{nx})
		\label{star1}
	\end{equation}
	on $-\pi\leq x \leq \pi$, where $A_n = \frac{1}{\pi} \int_{-\pi}^\pi F(x) \cos{nx} \, dx$ and $B_n = \frac{1}{\pi} \int_{-\pi}^\pi F(x) \sin{nx} \, dx$. For $n = 1,2,\dots$, set $u=F(x)$ and $dv = \cos{nx} \, dx$ so that
	\begin{align*}
		A_n &= \frac{1}{\pi} \int_{-\pi}^\pi F(x)\cos{nx} \, dx = \frac{1}{\pi} F(x) \left(\frac{1}{n}\right) \sin{nx} \bigg \rvert_{-\pi}^\pi - \frac{1}{n\pi} \int_{-\pi}^\pi \left[ f(x) - \frac{a_0}{2} \right] \sin{nx} \, dx \\ &= -\frac{1}{n\pi} \int_{-\pi}^\pi f(x)\sin{nx} \, dx = -\frac{b_n}{n} \\
		B_n &= \frac{1}{\pi} \int_{-\pi}^\pi F(x) \sin{nx}\, dx = \frac{1}{\pi} \left[ -F(x) \frac{1}{n} \cos{nx} \bigg \rvert_{-\pi}^\pi + \frac{1}{n} \int_{-\pi}^\pi \left( f(x) - \frac{a_0}{2}\right) \cos{nx} \, dx \right] = \frac{1}{n}a_n \\
		A_0 &: \frac{\pi a_0}{2} = F(\pi) =  \frac{A_0}{2} + \sum_{n=1}^\infty \left[ A_n\cos{\pi n} + B_n\sin{\pi n} \right] = \frac{A_0}{2} + \sum_{n=1}^\infty A_n(-1)^n \implies \frac{A_0}{2} = \frac{\pi a_0}{2} + \sum_{n=1}^\infty A_n(-1)^n
	\end{align*}
	Plug in $A_n, B_n$ to F(x), check.
\end{proof}

\section{Derivation of heat equation}

Three types of models of heat transfer.
\begin{enumerate}
	\item Conduction: due to molecular activity.
	\begin{itemize}
		\item energy transfer from more active to less active particles
		\item Fourier's law
	\end{itemize}
	\item Convection: due to bulk transfer/motion of mass.
	\begin{itemize}
		\item Newton's law of cooling
	\end{itemize}
	\item Radiation: electromagnetic waves, i.e. sun heating Earth.
\end{enumerate}
We consider heat transfer in a solid body, where conduction is the appropriate model.
Let $u(x,y,z,t) = $ temperature at location $(x,y,z)$ and time $t$.
Given a surface $S$ through the point $P(x,y,z)$ with unit normal $\vn$. Let $\Phi(x,y,z,t) = $ flux of heat across $S$ in the direction $\vn$ $ = $ quantity of heat per unit of area per unit of time conducted across $S$ in direction $\vn$.

\begin{definition}
	\underline{Fourier's Law}: magnitude of flux is proportional to magnitude of directional derivative $\frac{du}{d\vn}$.
	In other words, $\Phi(x,y,z,t) = -K \frac{du}{dn}$, for $K>0$. $K = $ thermal conductivity.
\end{definition}

\begin{example}
	[Sec. 20, Problem 5] $f(s) = s $ has Fourier series $f(s) \sim 2\sum_{n=1}^\infty \frac{(-1)^{n+1}}{n}\sin{ns}$. Integrate the series from 0 to $x$ + sketch graph. From the theorem, $\int_0^x s\, ds = 2 \sum_{n=1}^\infty \int_0^x \frac{(-1)^{n+1}}{n} \sin{ns} \, ds$. Then $\frac{x^2}{2} = 2\sum_{n=1}^\infty \frac{(-1)^{n+1}}{n^2}(-1)\cos{ns} \big\rvert_0^x = 2\sum_{n=1}^\infty \frac{(-1)^n}{n^2} [\cos{nx}-1] = \frac{\pi^2}{6} + 2\sum_{n=1}^\infty \frac{(-1)^n}{n^2}\cos{nx} $.
\end{example}

\underline{Last time}: Began derivation of heat equation $u(x,y,z,t) = $ temperature at $(x,y,z)$ at time $t$. $\Phi(x,y,z,t) = $ flux $\dots$.
Fourier's law: $\Phi(x,y,z,t) = -K \frac{du}{dn}$.

\begin{definition}
	$\sigma = $ specific heat = energy required to raise temperature of one unit of mass one degree.
	$\delta = $ mass density.
	\begin{note}
		In general, $K,\sigma,\delta$ may not be constant and may depend on $x,y,z$ or even $t$ or $u$. We usually assume constant.
	\end{note}
\end{definition}

\begin{definition}
	[\underline{One-dimensional heat equation}]
	\underline{Assume}:
	\begin{itemize}
		\item the solid is a circular cylinder with a constant cross sectional area $A$ in $yz$-plane.
		\item heat flows only parallel to $x$-axis. Thus: $\Phi = \Phi(x,t)$ and $u(x,t)$.
		\item $K,\sigma,\delta,A$ are constant.
		\item temperature is constant over a cross-section.
		\item perfect insulation, so no heat escapes through the side of cylinder.
		\item  no heat generated or lost inside cylinder (no sources or sinks).
	\end{itemize}
\end{definition}

We derive a model by considering conservation of thermal energy in a small segment of width $\Delta x$.
WLOG (without loss of generality) assume thermal energy flows left to right.
Conservation law: (1) net rate of heat accumulation = (2) rate of heat entering - rate of heat leaving.
From definition of specific heat: (1) rate of heat change per unit time $\approx  \sigma \cdot m \cdot u_t(x^*,t)$ on $x<x^*<x+\Delta x$.
But $m=\delta A \Delta x$, $A$ = cross sectional area (in text, $A=\Delta y \Delta z$). So (1) $\approx \sigma \delta A \Delta x u_t(x^*,t)$. Also $$(2) \approx \Phi(x,t) \cdot A - \Phi(x+\Delta x,t)\cdot A = -K u_x(x,t)\cdot A + Ku_x(x+\Delta x,t)\cdot A.$$
Set equal: $\sigma \delta A \Delta x u_t(x^*,t) = K\cdot A [ u_x(x+\Delta x,t)- u_x(x,t)]$. So $u_t(x^*,t) = \frac{1}{\sigma\delta}K \left[ \frac{u_x(x+\Delta x,t) - u_x(x,t)}{\Delta x} \right]$.
Take $\lim$ as $\Delta x \ra 0$, so $x^* \ra x$, $u_t(x,t) = k u_{xx}(x,t)$, where $k = \frac{K}{\sigma\delta}>0$ is the thermal diffusivity.

HW: derive the 1-$d$ heat equation when $K=K(x)$.

\begin{note}
	In this 1-$d$ model, thermal energy can only enter or leave through boundaries at left + right end.
	The full mathematical model consists of
	\begin{enumerate}
		\item The PDE $u_t = ku_{xx}$ on $0\leq x\leq c$.
		\item Initial temperature distribution (IC) $u(x,0) = f(x)$ on $0<x<c$.
		\item Two boundary conditions at $x=0$ and $x=c$.
		\underline{For example}: Dirichlet: $u(0,t) = 0$ and $u(c,t)=0$.
		or Neumann: $u_x(0,t) = 0$ and $u_x(c,t) = 0$.
		Third: $\Phi \rvert_{x=0,c} = H(T-u\rvert_{x=0,c})$.
	\end{enumerate}
\end{note}

\begin{example}
	Let $u(x) $ denote steady state temperature in a cylinder whose faces at $x=0$ and $x=c$ are kept at constant temperature $u=0$ and $u=u_0>0$.
	Since it's steady state, $u_t = 0$. So $ku_{xx}(x,t) = 0$. Can write $u(x,t) = u(x)$, so $u''(x) = 0$, $u(0) = 0$, and $u(c) = u_0$.
	So $u(x) = ax+b$ and $u(0) = 0$ implies $b=0$, so $u(x) = ax$. To determine constant $a$, use other BC: $u(c) = u_0$ implies $u_0 = ac$, where $a= \frac{u_0}{c}$. So $u(x) = \frac{u_0}{c}x$.
\end{example}

\underline{TEST}: verify PWC, left right derivative, Convergence theorem, calculate fourier series, quizzes, heat equation

\begin{example}
	[Q3.1] $f(x) = \begin{cases} 1-x & 0<x\leq 1 \\ 0 & 1 < x \leq 2 \end{cases}$, $C(s) = $ cosine series, $S(s) = $ sine series. $C(s)$ is full Fourier series of even extension to $(-2,2)$. $S(s)$ is full Fourier series of odd extension of $f$ to $(-2,2)$. (graph).
\end{example}
\begin{example}
	[Q3.2] $S(x)$ is the Fourier series for $f(x) = \begin{cases} 0 & -\pi \leq x \leq 0 \\ \sin{x} & 0\leq x \leq \pi \end{cases}$. So $S\left(\frac{5\pi}{2}\right) = 1$ and $S(3\pi) = 0$. Can differentiate term by term to get series for $S'(x)$. Note, $f'(0)$ not defined. So $S'\left( \frac{\pi}{2} \right)$ and $S'(\pi) = -\frac{1}{2}$.
\end{example}

\underline{Last time}: Heat equation.

\section{Model of vibrating elastic string}

\begin{definition}
	Consider a tightly stretched elastic string.
	\underline{Assume}:
	\begin{itemize}
		\item motion consists only of vertical displacements, which are small. $y(x,t) = $ vertical displacement at time $t$ of the point whose equilibrium position is $(x,0)$ in $xy$-plane.
		\item string is perfectly flexible, so there is an elastic restoring force, but no resistance to bending.
		\item horizontal component of tensile force is constant, $H>0$.
	\end{itemize}

\end{definition}
	$V(x,t) = $ vertical component of tensile force, exerted by left part of string on the right part of string at $(x,y)$. At $(x,y)$, if sloped down, then $V$ is negative (downward) and $y_x(x,t)$ is positive. Then $y_x(x,t) = \frac{-V(x,t)}{H}$. On the other hand, if at $(x,y)$ the slope is downward, then $V$ is positive (upward) and $y_x(x,t)$ is negative. Again, $y_x(x,t) = \frac{-V(x,t)}{H}$. So $V(x,t) = -Hy_x(x,t)$ and $V(x+\Delta x,t) = Hy_x(x+\Delta x, t)$. Apply Newton's law $F=ma$. $\delta = $ density = mass per unit length. So $\delta \Delta x = $ mass of piece of string. Then $\delta \Delta x y_{tt} (\bar{x},t) = Hy_x(x+\Delta x, t) - Hy_x(x,t)$. Then the one dimensional wave equation can be derived as $y_{tt}(x,t) = a^2 y_{xx}(x,t)$, where $a^2 = \frac{H}{\delta}$.
Can apply separation of variables to wave equation, just like we did previously for the heat equation.

HW: Sec. 27: 2,3. Sec. 29, 1.

\begin{example}
	[Sec. 27, problem 2] At $x=0$ flux into cylinder is constant $\Phi_0$. At $x=c$ temperature is held constant to value 0. Steaty state means $u_t(x,t) = 0$. So $u(x,t) = u(x)$ and PDE becomes ODE $u''(x)=0$. BC are: At $x=c$: $u(c) =0$. At $x=0$: $\Phi_0 = -K u'(0)$. The general solution is $u(x) = Ax+B$.
\end{example}
\begin{example}
	[HW Sec. 20, 1] $ f(x) = \begin{cases} 0 & -\pi \leq x \leq 0 \\ \sin{x} & 0\leq x \leq \pi \end{cases}$ continuous on $[-\pi,\pi]$, PWS, $f(-\pi)=0=f(\pi)$. By Theorem in \S 17 get uniform convergence of Fourier series $S(x) = \frac{1}{\pi} + \frac{1}{2} \sin{x} - \frac{2}{\pi} \sum_{n=1}^\infty \frac{\cos{2nx}}{4n^2-1}$. Observe $\left| \frac{\cos{2nx}}{4n^2-1} \right| \leq \frac{1}{4n^2 -1} \leq \frac{1}{3n^2} = M_n$ and $\sum M_n <\infty$.
	Theorem in \S 19 implies $S(x)$ is differentiable at all $x$ except $x=0$ in $(-\pi,\pi)$ because $f''(x) $ exists except at $x=0$.
	Graph $S'(x)$. Use fact that $S'(x)$ is Fourier series for %$f'(x)$.
	$f'(x) = \begin{cases} 0 & -\pi < x < 0 \\ \cos{x} & 0<x<\pi \end{cases}$.
\end{example}
\begin{example}
	[HW \S 20, 2] $f(x) = x \sim S(x) = $ Fourier cosine series on $(0,\pi)$. $S(x)$ is the Fourier series for $g(x) = |x|$ on $(-\pi,\pi)$. $g$ is continuous on $[-\pi,\pi]$, satisfies $g(-\pi) = g(\pi)$, and $g$ is PWS. By Theorem, $S'(x)$ is Fourier series for $f'(x)$ and converges for all $x\neq 0$, so all $x\in(0,\pi)$ since $f''(x)$ exists for all $x$ except $x=0$.
\end{example}
\begin{example}
	[HW \S 20, \#3] Theorem: Let $f$ be a function satisfying
	\begin{enumerate}
		\item[i)] $f$ is continuous on $0\leq x \leq \pi$
		\item[ii)] $f(0) = 0 = f(\pi)$
		\item[iii)] $f'$ is PWC on $0<x<\pi$.
	\end{enumerate}
	Then the Fourier sine series for $f$ is differentiable at each point where $f''(x)$ exists.
\end{example}
\begin{example}
	[HW \S 14, \#1] $f(x) = x \sim S(x) = $ Fourier sine series on $(0,\pi)$. $S(x)$ is the Fourier series for odd extension to $(-\pi,\pi)$, which is continuous on $(-\pi,\pi)$. Theorem says $S(x)$ converges to mean value of $2\pi$-periodic extension of $g(x)$.
\end{example}
\begin{example}
	[HW \S 14, \#4] $f(x) = \begin{cases} 0 \\ \sin{x} \end{cases}$
\end{example}

\section{The Fourier Method}
(Previously did \S36)
Some ideas aboud linear combinations.
\begin{definition}
	[\underline{Function space}] A vector space whose elements are functions
\end{definition}
\begin{example}
	$C_p(a,b)$, $C(a,b)$, $L^2(a,b)$.
\end{example}
\begin{definition}
	[Linear Operator] A \underline{linear operator} $L$ on a function space $V$ is a map from $V$ to $V$ with the properties:
	For all $u_1,u_2\in V$ and scalars $c_1,c_2$ we have $L(c_1u_1+c_2u_2) = c_1L(u_1)+c_2L(u_2)$.
\end{definition}
\begin{example}
	Differential operator: $L(u) = \frac{du}{dx}$.
\end{example}
\begin{example}
	Multiplication operator: $L(u) = f(x)\cdot u(x)$.
\end{example}
\begin{definition}
	[\underline{Superposition Principle}] If $L$ is a linear operator and $L(u_1)=0$ and $L(u_2) = 0$, then $L(c_1,u_1+c_2u_2) =0$. This extends to any finite linear combination $L(c_1u_1+c_2u_2+\dots+c_nu_n) = 0$.
\end{definition}
\begin{example}
	$L(u)=u_t-ku_{xx}=0$, with function space defined  by the BVP.
	Under suitable assumptions we can extend to infinite linear combinations, which we need for Fourier method (separation of variables).
	\underline{We did one example} (\S 36) for a heat equation.
\end{example}
\begin{example}
	[A wave equation example] $y_{tt}(x,t) = a^2 y_{xx}(x,t)$ on $0<x<c$ and $0<t$ with BC $y(0,t)=0$ and $y(c,t)=0$. IC is $y(x,0)=f(x)$ and $y_t(x,0)=0$.
	Assume solution has the form $y(x,t)=X(x)T(t)$. Plug in: $\frac{T''(t)}{a^2T(t)}=\frac{X''(x)}{X(x)} = -\lambda \implies$\underline{$X''(x)+\lambda X(x)=0$, $X(0)=0$, and $X(c)=0$}. Also $T''(t)+\lambda a^2 T(t)=0$ and $T'(t)=0$.

	\underline{$\lambda=0$}: $X''(x)=0 \implies X(x)=Ax+B$ but BC imply $X(x)=0$.

	\underline{$\lambda<0$}: $\lambda=-\alpha^2$, $X''(x)-\alpha^2 X(x)=0$. Then $X(x) = c_1e^{\alpha x} + c_2 e^{-\alpha x}$. At $X(0)=0$: $c_1+c_2=0$, so $c_1=-c_2$. At $X(c)=0$: $c_1e^{\alpha c} - c_1e^{-\alpha c} = 0 = c_1 \left[ e^{\alpha c} - e^{-\alpha c}\right]$, which implies $c_1 = 0$, so $c_2=0$.

	\underline{$\lambda>0$}: $\lambda = \alpha^2$, $X''(x) + \alpha^2 X(x) = 0$ and $X(x) = c_1 \cos{\alpha x} + c_2 \sin{\alpha x}$. At $X(0)=0$: $c_1+0=0$, so $c_1=0$. So $X(x) = c_2\sin{\alpha x}$. At $X(c)=0$: $\sin{(\alpha c)} = 0$, so $\alpha = \pm\frac{n\pi}{c}$, $n=1,2,\dots$.
	So $\lambda_n = \frac{n^2\pi^2}{c^2}$, $n=1,2,\dots$. with corresponding solutions (eigenfunctions) $X_n(x) = \sin{\frac{n\pi}{c}x}$.
	Use $\lambda_n$ to get corresponding $T_n(t)$: $T''(t) + \frac{n^2\pi^2a^2}{c^2}T(t) = 0$, $T_n(t) = c_1\cos{\frac{n\pi a}{c}t} + c_2\sin{\frac{n\pi a}{c}t}$. So $T_n(t) = \cos{\frac{n\pi a}{c}t}$.

	So $y_n(x,t) = \sin{\frac{n\pi}{c}x} \cos{\frac{n\pi a}{c} t}$ for $n=1,2,\dots$ is a solution of PDE and BC and $y_t(x,0)=0$.
	Thus the series (Infinite linear combination) also satisfies these.
	$y(x,t) = \sum_{n=1}^\infty B_n \sin{\frac{n\pi}{c}x}\cos{\frac{n\pi a}{c}t}$ satisfies PDE, BC, and $y_t(x,0)=0$.
	Can we pick $B_n$ so $y(x,t)$ also satisfies $y(x,0) = f(x)$?
	That is, $f(x) \stackrel{?}{=} \sum_{n=1}^\infty B_n \sin{\frac{n\pi}{c}x}$?
	Yes, if $f(x)$ has a Fourier series.
\end{example}
HW: \S34: 2,4,5,6. \S37 1,3.

Previously, we used Fourier method (separation of variables) to solve two different problems:
\begin{enumerate}
	\item Heat Equation with insulated BC. PDE: $u_t(x,t) = ku_{xx} (x,t)$, BC: $u_x(0,t) = 0 = u_x(c,t)$, IC: $u(x,0) = f(x)$. This leads to the BVP $X''(x) + \lambda X(x) = 0$, $X'(0)=0$, $X'(c)=0$. Eigenvalues: $\lambda_0 = 0$, $\lambda_n = \frac{n^2\pi^2}{c^2}$, $n=1,2,\dots$. Eigenfunctions: $X_0(x) = 1$, $X_n(x) = \cos{\frac{n\pi}{c}x}$.
	\item Wave equation. PDE: $y_{tt}(x,t)=a^2y_{xx}(x,t)$. BC: $y(0,t)=0 = y(c,t)$, IC: $y(x,0)=f(x)$, $y_t(x,0)=0$. This leads to the BVP: $X''(x) + \lambda X(x)=0$, $X(0)=0$, $X(c)=0$. Eigenvalues $\lambda_n = \frac{n^2\pi^2}{c^2}$ for $n=1,2,\dots$. Eigenfunctions: $X_n(x) = \sin{\frac{n\pi}{c}x}$. We will study other BC's and BVP's later (Sturm-Liouville).
\end{enumerate}
\begin{example}
	Heat Equation with zero temperature BC $u_t(x,t)=ku_{xx}(x,t)$, $u(0,t)=0=u(\pi,t)$, $u(x,0)=f(x)$.
	Apply Fourier Method, $X''(x) + \lambda X(x) = 0$, $X(0)=0$, $X(\pi) = 0$, and $T'(t) + \lambda k T(t) = 0$. So $\lambda_n = n^2$, $X_n(x) = \sin{(nx)}$. $T_n(t) = e^{-n^2kt}$. So $u(x,t) = \sum_{n=1}^\infty B_n \sin{(nx)} e^{-n^2kt}$. From IC: $f(x) = \sum_{n=1}^\infty B_n \sin{(nx)}$. So $B_n = \frac{2}{\pi} \int_0^\pi f(x) \sin{(nx)} \, dx$.
\end{example}
\begin{example}
	Heat equation with nonzero temperature BC: $u_t(x,t) = ku_{xx}(x,t)$, $u(0,t) = 0$, $u(\pi,t) = u_0$, $u(x,0) = 0$.
	Note: BC is nonhomogeneous, so Fourier method doesn't apply directly (because Superposition Principle only applies to linear, homogeneous problems).
	Look for solution of form $u(x,t) = U(x,t) + \Phi(x) \ra$ Plug in: $U_t(x,t) = u_t(x,t) = ku_{xx}(x,t) = k U_{xx}(x,t) + k \Phi''(x)$. At boundary conditions: $0=u(0,t) = U(0,t) + \Phi(0)$ and $u_0 = u(\pi,t) = U(\pi, t) + \Phi(\pi)$. Suppose we select $\Phi(x)$ to satisfy $\Phi''(x) = 0$, $\Phi(0) = 0$, $\Phi(\pi) = u_0$. If such a $\Phi(x)$ is used, then $U(x,t)$ must satisfy $U_t(x,t) = kU_{xx}(x,t)$, $U(0,t)=0$, $U(\pi,t) = 0$, $U(x,0) = -\Phi(x)$. We just solved this for $U(x,t)$. $\Phi''(x) = 0$ implies $\Phi(x) = Ax+B$ or $\Phi(x) = \frac{u_0}{\pi}x$. So $U(x,t) = \sum_{n=1}^\infty B_n \sin{(nx)}e^{-n^2kt}$, where $\sum_{n=1}^\infty B_n \sin{(nx)} = -\frac{u_0}{\pi}x$.
	We know $x = \sum_{n=1}^\infty 2\frac{(-1)^{n+1}}{n}\sin{nx}$, so $B_n = \frac{-u_0}{\pi} \cdot \frac{2(-1)^{n+1}}{n} = \frac{2u_0}{\pi n}(-1)^n$. So $$u(x,t) = \frac{u_0}{\pi}x + \frac{2u_0}{\pi} \sum_{n=1}^\infty \frac{(-1)^n}{n} \sin{(nx)}e^{-kn^2t}.$$
\end{example}
\begin{example}
	Two numerical examples:
	\begin{enumerate}
		\item $u_t = ku_{xx}$, $u_x(x,t) = 0 = u_x(1,t)$, $u(x,0)=x$. \\Solution $u(x,t) = \frac{1}{2} - \frac{4}{\pi^2} \sum_{n=1}^\infty \frac{1}{(2n-1)^2} e^{-(2n-1)^2\pi^2 kt} \cos{(2n-1)\pi x}$
		\item $u_t = ku_{xx}$, $u(0,t) = 0 = u(\pi,t)$, $u(x,0) = x(\pi-x)$. \\Solution $u(x,t) = \frac{8}{\pi} \sum_{n=1}^\infty \frac{1}{(2n-1)^3} e^{-(2n-1)^2 kt} \sin{(2n-1)x}$.
	\end{enumerate}
\end{example}
HW \S39: 1, 2

\begin{example}
	Heat equation with a heat source:
	$u_t(x,t) = ku_{xx}(x,t) + q(t)$, $u(0,t) = 0$, $u(\pi,t) = 0$, $u(x,0)=f(x)$.
	We generalize the \say{variation of parameters} idea from ODE's and seek a solution of the form $u(x,t) = \sum_{n=1}^\infty B_n(t) \sin{nx}$.
	Plug in to PDE: $\sum_{n=1}^\infty B_n'(t) \sin{nx} = k \sum_{n=1}^\infty -n^2 B_n(t) \sin{(nx)} + q(t) \cdot \sum_{n=1}^\infty \frac{2[1-(-1)^n]}{n\pi} \sin{nx}$, where we used $ 1= \sum_{n=1}^\infty \frac{2[1-(-1)^n]}{n\pi} \sin{nx}$ on $0<x<\pi$.
	Thus \begin{equation}
		B_n'(t) + n^2kB_n(t) = \frac{2[1-(-1)^n]}{n\pi}q(t),
		\label{eqn16}
	\end{equation} where $n=1,2,\dots$.
	Also $u(x,0) = f(x)$ implies $\sum_{n=1}^\infty B_n(0) \sin{(nx)} = f(x)$, so $$B_n(0) = b_n = \frac{2}{\pi} \int_0^\pi f(x) \sin{(nx)}.$$
	We can solve equation (\ref{eqn16}) using integrating factor $e^{n^2kt} B_n'(t) + n^2ke^{n^2kt} B_n(t) = \frac{2[1-(-1)^n]}{n\pi}e^{n^2kt} q(t)$, where the LHS is $\frac{d}{dt} \left[ e^{n^2kt} B_n(t) \right] = \frac{2[1-(-1)^n]}{n\pi} e^{n^2kt} q(t)$. Integrate 0 to $t$: $e^{n^2kt} B_n(t) - b_n = \frac{2[1-(01)^n]}{n\pi} \int_0^t e^{n^2k\tau} q(\tau) \, d\tau$. So $B_n(t) = b_n e^{-n^2kt} + \frac{2[1-(-1)^n]}{n\pi} \int_0^t e^{-n^2k(t-\tau)}q(\tau) \, d\tau$.
	So the solution
	\begin{align*}
		u(x,t) &= \sum_{n=1}^\infty B_n(t) \sin{nx} = \sum_{n=1}^\infty b_n e^{-n^2kt} \sin{nx} + \sum_{n=1}^\infty \frac{2[1-(-1)^n]}{n\pi} \left[ \int_0^t e^{-n^2k(t-\tau)} q(\tau) \, d\tau \right] \sin{nx} \\
		&=\sum_{n=1}^\infty b_n e^{-n^2kt} \sin{nx} + \frac{4}{\pi} \sum_{j=1}^\infty \frac{\sin{(2j-1)x}}{2j-1} \int_0^t e^{-(2j-1)^2k(t-\tau)} q(\tau) \, d\tau
	\end{align*}
\end{example}

HW: $\S42: 1,2$. \underline{Extra Credit}: Use separation of variables to find a solution of $u_t(x,t) = k u_{xx} (x,t)$, $u(0,t)=0$, $u(1,t)=0$, $u(x,0)=\pi x$. Put in all the details to the derivation.

We continue to use the two basic BVP's.
We solved several heat equation examples.

\begin{example}
	[already solved] $y_{tt}(x,t) = a^2 y_{xx}(x,t)$ on $0<x<c$ with $y(0,t)=0$ and $y(c,t)=0$; $y(x,0)=f(x)$ and $y_t(x,0)=0$; where $f$ is continuous on $[0,c]$ and $f(0)=0=f(c)$. We used separation of variables to get the solution $y(x,t)=\sum_{n=1}^\infty B_n \sin{\frac{n\pi x}{c}} \cos{\frac{n\pi a t}{c}}$, where $B_n = \frac{2}{c} \int_0^c f(x) \sin{\frac{n\pi x}{c}}\, dx$.
	We observe the solution can be written in a different form, not involving series.
	\underline{Observe}: $$\sin{\frac{n\pi x}{c}}\cos{\frac{n\pi a t}{c}} = \frac{1}{2} \left[ \sin{\frac{n\pi}{c}(x+at)} + \sin{\frac{n\pi}{c}(x-at)} \right],$$ where we used $2\sin{E}\cos{F} = \sin{(E+F)}+\sin{(E-F)}$. Then
	$$y(x,t) = \frac{1}{2} \left[ \sum_{n=1}^\infty B_n \sin{\frac{n\pi}{c}(x+at)} + \sum_{n=1}^\infty B_n \sin{\frac{n\pi}{c}(x-at)} \right].$$
	Also, $f(x) \sim \sum_{n=1}^\infty B_n \sin{\frac{n\pi}{c}x}$.
	Let $F(x)$ be the $2c$ periodic extension of the odd extension of $f(x)$ to $(-c,c)$. Then $F(x) = \sum_{n=1}^\infty B_n \sin{\frac{n\pi x}{c}}$ for all $x\in(-\infty,\infty)$.
	Thus $$y(x,t) = \frac{1}{2} \left[ F(x+at) + F(x-at) \right].$$

	Let's check that this is a solution. $y_x(x,t) = \frac{1}{2} \left[ F'(x+at) + F'(x-at) \right]$, $y_{xx}(x,t) = \frac{1}{2} [ F''(x+at) + F''(x-at)]$, $y_{tt}(x,t) = \frac{1}{2} [a^2 F''(x+at) + a^2 F''(x-at)] = a^2 y_{xx}(x,t)$.
	BC: $y(0,t) = \frac{1}{2} [ F(at) + F(-at)] = \frac{1}{2} [ F(at)-F(at)] = 0$ because $F$ is odd; $y(c,t) = \frac{1}{2} [F(c+at) + F(c-at)] = 0$ since $F$ is odd and $2c$ periodic. IC: $y(x,0) = F(x) = f(x)$ on $(0,c)$; $y_t(x,0) = \frac{1}{2} [ aF'(x) - aF'(x) ] =0$.
	Thus $y(x,t)$ is a solution to the given wave equation.
\end{example}
What about other IC? Consider $y_{tt}(x,t) = a^2 y_{xx}(x,t)$ on $0<x<c$ with $y(0,t)$ and $y(c,t)=0$ using IC $y(x,0)=0$ and $y_t(x,0)=g(x)$.
Separation of variables: $y(x,t) = X(x)T(t)$ gives $X''+\lambda X=0$, $X(0)=0$, and $X(c)=0$; and $T''(t) + \lambda a^2 T(t) = 0$, $T(0)=0$.
Eigenvalues: $\lambda_n = \frac{n^2\pi^2}{c^2}$, eigenfunctions $X_n(x)=\sin{\frac{n\pi}{c}x}$, $T_n(t) = \sin{\frac{n\pi a}{c}t}$. Then
\begin{equation}
	y(x,t) = \sum_{n=1}^\infty C_n \sin{\frac{n\pi x}{c}} \cos{\frac{n\pi a t}{c}}.
	\label{eqnytgx}
\end{equation}
This satisfies PDE, BC, and $y(x,0)=0$. To get the other IC, $y_t(x,t) =\sum_{n=1}^\infty \frac{n\pi a}{c} C_n \sin{\frac{n\pi x}{c}} \cos{\frac{n\pi at}{c}}$. From $y_t(x,0) = g(x) = \sum_{n=1}^\infty \frac{n\pi a}{c} \sin{\frac{n\pi x}{c}}$. So $\frac{n\pi a}{c} C_n$ are the Fourier sine coefficients of $g(x)$, i.e. $\frac{n\pi a}{c} C_n = \frac{2}{c} \int_0^c g(x) \sin{\frac{n\pi x}{c}} \, dx$ or $C_n = \frac{2}{n\pi a} \int_0^c g(x) \sin{\frac{n\pi x}{c}}\, dx$.
From equation (\ref{eqnytgx}), like last example, $y_t(x,t) = \frac{1}{2} \left[ \sum_{n=1}^\infty \frac{n\pi a}{c} C_n \sin{\frac{n\pi}{c}(x+at)} + \sum_{n=1}^\infty \frac{n\pi a}{c} C_n \sin{\frac{n\pi}{c}(x-at)} \right]$. So if $G(x)$ is the odd, $2c$ periodic extension of $g(x)$, then $y_t(x,t) = \frac{1}{2} [G(x+at) + G(x-at)]$. Hence, $y(x,t) = \frac{1}{2} \left[ \int_0^t G(x+a\tau) \, d\tau + \int_0^t G(x-a\tau) \, d\tau \right]$. Substitute: $s = x+a\tau$ and $s=x-a\tau$ $\ra y(x,t) = \frac{1}{2a} \left[ \int_x^{x+at} G(s) \, ds - \int_x^{x-at} G(s) \, ds \right] = \frac{1}{2a} \int_{x-at}^{x+at} G(s) \, ds$.

For general case: $y_{tt} = a^2 y_{xx}$; BC: $y(0,t) = 0$, $y(c,t) = 0$; IC: $y(x,0) = f(x)$, $y_t(x,0) = g(x)$. Solution is $$\displaystyle y(x,t) = \frac{1}{2} [F(x+at)+F(x-at)] + \frac{1}{2a} \int_{x-at}^{x+at} G(s)\, ds$$

HW \S45; 1,2,3,4

\newpage

\section{Orthonormal Sets}

We will generalize geometry of vectors in 3-space to more general vector spaces whose elements (vectors) are functions.
In 3-space, vectors are defined as directed line segments. %Can then
Define the following geometrically:
\begin{itemize}
	\item Length of vector
	\item Angle between vectors
	\item Add two vectors (parallelogram)
	\item Multiply by a real number $a$: get new vector in same direction if $a > 0$, opposite direction if $a<0$, and length is the original length multiplied by $|a|$.
	\item Given a vector and plane in 3-space, can define the projection of vector onto the plane as follows: move to equivalent vector with tail in plane, then drop a perpendicular line from head to plane. Then connect those two points in the plane.
	\begin{note}
		The length of the projection is always less than or equal to length of original vector and only equal if original vector is in the plane.
	\end{note}
\end{itemize}
All these geometric properties and definitions can be given algebraically. This is important because it is the algebraic definitions which can extend to higher dimensions and more general vector spaces.

\begin{definition}
	Given a `geometric' vector, take an equivalent vector with tail at origin $(0,0,0)$. Define `algebraic' vector to have the coordinates of the point at the head: $x = (x_1,x_2,x_3)$.
	\begin{itemize}
		\item Define addition of two vectors and multiplication by a real number $a$, component-wise. $x+y = (x_1+y_1,x_2+y_2,x_3+y_3)$, $ax = (ax_1,ax_2,ax_3)$.
		This is consistent with the geometric definition.
		\item Define algebraic length by Euclidean norm: $||x|| = \sqrt{x_1^2+x_2^2 + x_3^2}$. This is consistent with the geometric definition (Pythagorean Theorem).
		\item Define the dot product: $x\cdot y = x_1y_1 + x_2y_2 + x_3y_3$. This has important geometric interpretations.
		If $\theta$ is the `geometric' angle between vectors $x$ and $y$, then $\cos{\theta} = \frac{x\cdot y}{||x|| \cdot ||y||}$ (Law of cosines). Two vectors are orthogonal if and only if $x\cdot y = 0$.
		\begin{note}
			$||x|| = \sqrt{x\cdot x}$.
		\end{note}
	\end{itemize}
	Recall the Euclidean basis vectors $e_1=(1,0,0)$, $e_2 = (0,1,0)$, and $e_3=(0,0,1)$.
	Observe following properties: $||e_i|| = 1$, $i=1,2,3$; $e_i\cdot e_j = \begin{cases} 0 & \text{if }i\neq j \\ 1 & \text{if }i=j \end{cases}$. Let $x = (x_1,x_2,x_3)$. Then $\displaystyle x = \sum_{i=1}^3 x_i e_i = \sum_{i=1}^3 (x\cdot e_i)e_i$.
	Also $||x||^2 = \sum_{i=1}^3 |x_i|^2 = \sum_{i=1}^3 (x\cdot e_i)^2$. Also, if $y\cdot e_i = 0$, $i=1,2,3$, then $y=(0,0,0)$.
	Thus $\{e_1,e_2,e_3\}$ forms an orthonormal basis of $\mb R^3$.
\end{definition}
\begin{example}
	This works for any orthonormal basis in any vector space. Consider in $\mb R^3$: $u_1 = \frac{1}{\sqrt{6}}(1,2,1)$, $u_2 = \frac{1}{\sqrt{21}}(2,1,-4)$, $u_3 = \frac{1}{\sqrt{4}}(3,-2,1)$. Can check $\{u_1,u_2,u_3\}$ is orthonormal set. Define $W = \spn{u_1,u_2}$. Let $x\in \mb R^3$. Define $\hat{x} = \sum_{i=1}^2 (x\cdot u_i)u_i = (x\cdot u_1)u_1 + (x\cdot u_2)u_2$. Then $\hat{x}$ is the orthogonal projection of $x$ onto $W$. Actually, $x=\sum_{i=1}^3 (x\cdot e_i)e_i$.
\end{example}

\begin{example}
	Recall our first class: $u_t(x,t) = ku_{xx}(x,t)$, $u_x(0,t) = 0$, $u_x(c,t) = 0$, and $u(x,0) = f(x)$. Apply Fourier Method and seek solutions of form $u(x,t) = X(x)T(t)$. Plug in to PDE: $X''(x) + \lambda X(x) = 0$, $X'(0) = 0$, $X'(c) = 0$, and $T'(t) + k\lambda T(t) = 0$. For $\lambda = 0$, $X_(x) = 1$. For $\lambda = \left(\frac{n\pi}{c}\right)^2$, $X_n(x) = \cos{\frac{n\pi}{c}x}$. Also, $T_0(t) = 1$ and $T_n(t) = e^{-\frac{n^2\pi^2}{c^2}kt}$. Then get $u_0(x,t) = 1$ and $u_n(x,t) = \cos{\frac{n\pi}{c}x}\cdot e^{-\frac{n^2\pi^2}{c^2}kt}$ for $n=1,2,\dots$. Each is a solution of PDE + BC, so $u(x,t) = A_0 \cdot 1 + \sum_{n=1}^\infty A_n \cos{\frac{n\pi}{c}x} \cdot e^{-\frac{n^2\pi^2}{c^2}kt}$ is also a solution. Next step is to determine coefficients $A_0,A_1,\dots$ so $u(x,t)$ also satisfies $u(x,0) = f(x)$.
\end{example}
\begin{example}
	For 37.1, seek solution of form $u(x,t) = X(x)Y(y)$ for $u_{xx}(x,y) + u_{yy}(x,y) = 0$ on $0<x<\pi$ and $0<y<2$ with $u_x(0,y) = 0$, $u_x(\pi,y) = 0$, $u(x,0) = 0$, and $u(x,2) = f(x)$. Plug in to PDE: $X''(x) + \lambda X(x) = 0$ with $X'(0) = 0$ and $X'(\pi) = 0$. So $\lambda_0 = 0$, $X_0(x) = 1$, $\lambda_n = n^2$, and $X_n(x) = \cos{nx}$. Do on your own, get $Y'' - \lambda_n Y = 0$, $Y(0) = 0$, etc.
\end{example}
\newpage
Last time: geometry of dot product in $\mb R^3$, to extend to general function spaces.
\begin{recall}
	$C_p(a,b) = \{f:f \text{ is PWC on }[a,b]\}$. This is a vector space.
\end{recall}
\begin{definition}
	Define an inner product on $C_p(a,b)$ by $(f,g) = \int_a^b f(x) \conj{g(x)} \, dx$.
\end{definition}
\begin{recall}
	Recall in $\mb R^3$, $u = \mat{a_1,a_2,a_3}^T$, $u\cdot u = \sum a_i^2 = ||u||^2$.
\end{recall}
So $C_p(a,b)$ is an inner product space (infinite dimensional).
Compatible norm: $$||f|| = \sqrt{(f,f)} = \left( \int_a^b [f(x)]^2 \, dx \right)^{1/2}.$$
\begin{definition}
	Functions $f$ and $g$ are \underline{orthogonal} if $(f,g) = 0$, that is $\int_a^b f(x) \conj{g(x)} \, dx = 0$
\end{definition}
A set of functions $\{\psi_n\}_{n=1}^\infty$ is \underline{orthogonal} if $(\psi_m,\psi_n) = 0$ when $m\neq n$. If $\{\psi_n\}_{n=1}^\infty$ is an orthogonal set, then define $\phi_n = \frac{1}{||\psi_n||}\psi_n$. Then $||\phi_n|| = 1$ and $(\phi_n,\phi_m) = 0$ if $m\neq n$, so $\{\phi_n\}_{n=1}^\infty$ is an orthonormal set.
This means that $(\phi_n,\phi_m) = \delta_{mn} = \begin{cases} 1 & \text{if }m=n \\ 0 & \text{if } m\neq n \end{cases}$.
\begin{example}
	$\psi_n(x) = \sin{nx}$, $n=1,2,\dots$ on $0\leq x \leq \pi$. Then $(\psi_m,\psi_n) = \int_0^\pi \sin{mx}\sin{nx} \, dx = \begin{cases} 0 & \text{if }m\neq n \\ \frac{\pi}{2} & \text{if }m=n \end{cases}$. So $\{\psi_n\}_1^\infty$ is orthogonal. Define $\phi_n(x) = \sqrt{\frac{2}{\pi}} \sin{nx}$. Then $||\phi_n|| = 1$ for $n=1,2,\dots$, so $\{\phi_n\}_1^\infty$ is an orthonormal set.
\end{example}
\begin{example}
	$\phi_n = \sqrt{\frac{2}{\pi}}\cos{nx}$ for $n=1,2,\dots$ and $\phi_0(x) = \frac{1}{\sqrt{\pi}}$. Then $\{\phi_n\}_{n=0}^\infty$ is an orthonormal set.
\end{example}
\begin{example}
	$\phi_0(x) = \frac{1}{\sqrt{2\pi}}$, $\phi_{2n-1}(x) = \frac{1}{\sqrt{\pi}} \cos{nx}$, $\phi_{2n}(x) = \frac{1}{\sqrt{\pi}} \sin{nx}$ for $n=1,2,\dots$. So $\{\phi_n\}_{n=0}^\infty$ is an orthonormal set.
\end{example}
\begin{example}
	$\{1,x,x^2,\dots\}$, then use Gram-Schmidt process to make the functions orthonormal.
\end{example}
\begin{question}
	Given an orthonormal set $\{\phi_n\}_{n=1}^\infty$ in $C_p(a,b)$, is it possible to represent every $f\in C_p(a,b)$ as a linear combination (infinite series) of the $\phi_n$'s. That is, can we write $f(x) = \sum_{n=1}^\infty C_n \phi_n(x)$? We write $f(x) \sim \sum_{n=1}^\infty C_n\phi_n(x)$ if they are equal for all but a finite number of $x$ values on $(a,b)$.
\end{question}
Suppose the answer is yes. Then $f(x) = \sum_{m=1}^\infty C_m \phi_m(x)$. Then $$(f(x),\phi_n(x)) = \left(\sum_{m=1}^\infty C_m \phi_m(x), \phi_n(x) \right) = \sum_{m=1}^\infty C_m (\phi_m(x),\phi_n(x)) = \sum_{m=1}^\infty C_m \delta_{mn} = C_n.$$ So $C_n = (f,\phi_n)$.

HW Sect 61, 1,2,4,5

\underline{Last time}: inner product spaces, orthonormal sets of functions, $C_p(a,b)$.
Given an orthonormal set $\{\phi_n(x)\}_{n=1}^\infty$ in $C_p(a,b)$, can we represent any function $f$ (in $C_p(a,b)$ or in a subspace $W$ of $C_p(a,b)$), as $\sum_{n=1}^\infty C_n \phi_n(x)$? If yes, then $C_n = (f(x),\phi_n(x)) = \int_a^b f(x) \phi_n(x) \, dx$. The constants $C_n$ are called Fourier constants or coefficients.
\begin{definition}
	A sequence of functions $\{S_N(x)\}_{N=1}^\infty$ in $C_p(a,b)$ is said to \underline{converge in the mean} to the function $f(x)$ in $C_p(a,b)$ if $E_N = ||f-S_N||^2 = \int_a^b |f(x)-S_N(x)|^2 \, dx$ satisfies $\displaystyle\lim_{N\ra\infty} E_n = 0$, or equivalently $\displaystyle\lim_{N\ra\infty} ||f-S_N|| = 0$.
\end{definition}
\begin{note}
	not the same as pointwise or uniform convergence.
\end{note}
\begin{definition}
	An orthonormal set $\{\phi_n\}_{n=1}^\infty$ is \underline{complete} in a subspace $W$ of $C_p(a,b)$ if, for every $f\in W$, the partial sums of the generalized Fourier series $S_N(x) = \sum_{n=1}^N C_n \phi_n(x)$, $C_n = (f,\phi_n)$ converge in the mean to $f$. $||f-S_n|| \ra 0$ as $N\ra \infty$.
\end{definition}
\begin{remark}
	Consider $C[a,b]$ is a vector space and is a subspace of $L_2(a,b)$. Define $||f||_\infty = \underset{a\leq x \leq b}{\max}|f(x)|$. Then $C[a,b]$ with $||\cdot||_\infty$ is a complete normed space. But $C[a,b]$ with our norm is not complete. $||f||_2 = \sqrt{\int_a^b |f(x)|^2 \, dx}$. But $L_2(a,b)$ \underline{is} complete with $||\cdot ||_2$.
\end{remark}

Consider $\mb R^3$. Given vetor $\vv\in\mb R^3$, which vector in $W = \spn{\vi, \vj} = $ $xy$-plane is closest to $\vv$? $\vv=(x,y,z)$, then closest vector in $xy$-plane is $(x,y,0)$, that is $(\vv\cdot\vi)\vi + (\vv\cdot\vj)\vj$. So closest vector to $\vv$ is the Fourier sum.

Let's extend to general inner product space. Let $\{\phi_n\}_{n=1}^\infty$ be an orthonormal set in $C_p(a,b)$, and let $f\in C_p(a,b)$. Which vector in $\spn{\phi_N}_{n=1}^\infty$ is closest to $f$?
Let $\Phi_n (x) = \sum_{n=1}^N \gamma_n \phi_n(x)$. $\ra$ which choice of $\gamma_1,\dots,\gamma_N$ minimizes $||f-\Phi_N||?$ It is equivalent to minimize $E = ||f-\Phi_N||^2$.
\begin{align*}
E &= ||f-\Phi_n||^2 = \left(f - \sum_{n=1}^N \gamma_n \phi_n, f-\sum_{n=1}^N \gamma_n \phi_n \right) = (f,f) + \left(\sum_{n=1}^N \gamma_n \phi_n, \sum_{n=1}^N \gamma_n \phi_n \right) - 2\left( f, \sum_{n=1}^N \gamma_n \phi_n \right) \\
&= ||f||^2 + \sum_{n=1}^N \gamma_n^2 - 2\sum_{n=1}^N \gamma_n C_n + \sum_{n=1}^N C_n^2 - \sum_{n=1}^N C_n^2 = ||f||^2 + \sum_{n=1}^N(\gamma_n - C_n)^2 - \sum_{n=1}^N C_n^2
\end{align*}
The \say{best approxmation} which minimizes $E$ is obtained by choosing $\gamma_n = C_n$: In this case, since $E\geq 0$, $\sum_{n=1}^N C_n^2 \leq ||f||^2$, called Bessel's Inequality.
\begin{theorem}
	If $\{C_n\}_{n=1}^\infty$ are the Fourier constants for $f\in C_p(a,b)$ (or any vector in any inner product space) with respect to some orthonormal set $\{\phi_n\}_{n=1}^\infty$, then $\lim_{n\ra\infty} C_n = 0$
\end{theorem}
\begin{proof}
	$\sum_{n=1}^\infty C_n^2 \leq ||f||^2$. So $C_n^2\ra 0$, so $C_n\ra 0$.
\end{proof}
Suppose $\{\phi_n\}_{n=1}^\infty$ is orthonormal set in $W\subset C_p(a,b)$ and $f\in W$. Set $C_n = (f,\phi_n)$. Let $S_N(x) = \sum_{n=1}^N C_n\phi_n(x)$. So $||f-S_n(x)||^2 = ||f||^2 - \sum_{n=1}^N C_n^2$. If $\{\phi_n\}_{n=1}^\infty$ is complete, then $||f(x)-S_N(x)|| \ra 0$, $\ra$ so $\sum_{n=1}^\infty C_n^2 = ||f||^2$, which is Parseval's equation.
\begin{remark}
	Whether an orthonormal set is complete is equivalent to Parseval's equation.
\end{remark}

Last time: orthonormal sets, complete, Parseval's equation.

\begin{recall}
	Two fundamental BVP's:
	\begin{enumerate}
		\item $X''(x) + \lambda X(x) = 0$, $X'(0) = 0$, $X'(c) = 0$.
		Eigenvalues: $\lambda_0 = 0$, $\lambda_n = \left( \frac{n\pi}{2} \right)^2$ for $n=1,2,\dots$.
		Eigenfunctions: $\psi_0(x) = 1$, $\psi_n(x) = \cos{\frac{n\pi}{c}x}$
		\item $X''(x) + \lambda X(x) = 0$, $X(0) = 0$, $X(c) = 0$. Eigenvalues: $\lambda_n = \left(\frac{n\pi}{c}\right)^2$ for $n=1,2,\dots$. Eigenfunctions $\psi_n(x) = \sin{\frac{n\pi}{c}x}$ for $n=1,2,\dots$.
	\end{enumerate}
	These arise by applying separation of variables to certain PDE's.
	For other more general PDE's or BC's, the method of separation of variables leads to more general BVP, which we now consider.
\end{recall}
Consider the Sturm-Liouville problem (SL) on $a<x<b$: $$\left( r(x)X'(x) \right)' + \left[ q(x) + \lambda p(x) \right] X(x) = 0.$$
with `separated BC's' $a_1 X(a) + a_2 X'(a) = 0$ and $b_1 X(b) + b_2 X'(b) = 0$, where $a_1,a_2$ not both 0 and $b_1,b_2$ not both 0. The functions $p,q,r$ and parameters $a_1,a_2,b_1,b_2$ are real and also independent of $\lambda$.
\begin{definition}
	The SL problem is \underline{regular} if interval $(a,b)$ is bounded and
	\begin{enumerate}
		\item[(i)] $p,q,r,r'$ are continuous on $[a,b]$.
		\item[(ii)] $p(x) >0$ and $r(x)>0$ on $[a,b]$.
	\end{enumerate}
	Otherwise $SL$ problem is singular.
\end{definition}
\begin{definition}
	$\lambda$ is an eigenvalue (possibly complex) of (SL) if for that value of $\lambda$ there is a nontrivial solution $X(x)$, which is called an eigenfunction.
	The \underline{spectrum} of (SL) is the set of all eigenvalues.
\end{definition}
\begin{fact}
	[which will be assumed without proof] A regular SL problem has countably infinite many eigenvalues, $\lambda_1,\lambda_2,\dots$.
\end{fact}
Next we prove that eigenvalues and eigenfunctions of regular SL problems have many similar properties to these of problems (1) and (2).
\begin{recall}
	For $f,g\in C_p(a,b)$, $(f,g) = \int_a^b f(x) g(x) \, dx$. $f$ is orthogonal to $g \iff 0 = (f,g)$. Also $||f||\sqrt{(f,f)} = \left( \int_a^b |f(x)|^2 \, dx \right)^{1/2}$.
\end{recall}
\begin{definition}
	Let $p\in C_p(a,b)$ satisfy $p(x)>0$ and $f,g\in C_p(a,b)$. $f$ and $g$ are orthogonal with respect to weight function $p$ if $(f,g) = \int_a^b p(x) f(x) g(x) \, dx = 0$.
	We define weighted norm $||f|| = \left( \int_a^b p(x) |f(x)|^2 \, dx \right)^{1/2}$.
\end{definition}
Consider the SL problem: (1) $[r(x) X'(x)]' + [g(x) + \lambda p(x)] X(x) = 0$ and (2) $a_1 X(a) + a_2 X'(a) = 0$, $b_1 X(b) + b_2 X'(b) = 0$, where
\begin{enumerate}
	\item[(i)] $p,r,r'$ are continuous on $[a,b]$ and $q$ is continuous on $(a,b)$.
	\item[(ii)] $p(x) > 0$ and $r(x) > 0$ and $a<x<b$.
\end{enumerate}
This includes all regular SL problems, plus some singular.
\begin{theorem}
	If $\lambda_m$ and $\lambda_n$ are distinct eigenvalues of (1)-(2), then the corresponding eigenfunction $X_m(x)$ and $X_n(x)$ are orthogonal with respect to $p(x)$.
\end{theorem}

\underline{Last time}: (1) $[r(x)X'(x)]' + [q(x)+\lambda p(x)]X(x) = 0$, (2) $a_1 X(a) + a_2 X'(a) = 0$ and $b_1 X(b) + b_2 X'(b) = 0$, where
\begin{enumerate}
	\item[(i)] $p,r,r'$ continuous on $[a,b]$, $q$ continuous on $(a,b)$
	\item[(ii)] $p(x)>0$, $r(x)>0$ on $(a,b)$
\end{enumerate}
\begin{recall}
	[\underline{Theorem}] If $\lambda_m,\lambda_n$ are distinct eigenvalues of (1)-(2), then the corresponding eigenfunctions $X_m(x)$ and $X_n(x)$ are orthogonal with respect to weight function $p(x)$.
	This is also true when:
	\begin{enumerate}
		\item[a.] $r(a) = 0$ and left BC is dropped
		\item[b.] $r(b) = 0$ and right BC is dropped
		\item[c.] $r(a) = r(b)$ and $(2)$ is replaced with $X(a) = X(b)$ and $X'(a) = X'(b)$
	\end{enumerate}
\end{recall}
\begin{proof}
	We have $[rX_m']' + [q+\lambda_m p]X_m = 0$ and	$[rX_n']' + [q+\lambda_n p] X_n = 0$. Multiply by $X_n$ and $X_m$ respectively and subtract the equations to get
	\begin{align*}
	(\lambda_m - \lambda_n) p X_m X_n &= X_m (rX_n')' - X_n (rX_m')' = [ X_m (rX_n')' + X_m' r X_n'] - [X_n (rX_m')' + X_m' r X_n'] \\
	&= \frac{d}{dx} [X_m (r X_n') - X_n ( r X_m')]
	\end{align*}
	Integrate from $a$ to $b$
	$(\lambda_m - \lambda_n) \int_a^b p X_m X_n \, dx = r(x) \left[ X_m(x) X_n'(x) - X_m'(x) X_n(x) \right]_a^b = r(b) \Delta(b) - r(a) \Delta(a)$,
	where $$\Delta(x) = \left| \mat{X_m(x) & X_n(x) \\ X_m'(x) & X_n'(x)} \right|.$$ Left BC implies $a_x X_m(a) + a_2 X_m'(a) = 0$ and $a_1 X_n(a) + a_2 X_n'(x) = 0$ is $$\mat{ X_m(a) & X_m'(a) \\ X_m'(a) & X_n'(a) } \mat{ a_1 \\ a_2} = \mat{0 \\ 0}.$$ This implies $\Delta(a) = 0$. Similarly right BC implies $\Delta(b) = 0$. Thus $(\lambda_m - \lambda_n) \int_a^b p(x) X_m(x) X_n(x) \, dx = r(a) \Delta(a) - r(b) \Delta(b) = 0$. Since $\lambda_m - \lambda_n \neq 0$, so $\int_a^b p X_m X_n \, dx =~0$.
	If $r(a) = r(b)$ and BC become $X(a) = X(b)$ and $X'(a)= X'(b)$, then BC imply $\Delta(a) = \Delta(b)$, so again $r(a) \Delta(a) - r(b) \Delta(b) = 0$.
\end{proof}
\begin{theorem}
	If $\lambda$ is an eigenvalue for SL problem in previous theorem, then $\lambda$ is real.
\end{theorem}
\begin{proof}
	Suppose $\lambda$ is an eigenvalue with corresponding eigenfunction $X(x)$. We write $\lambda = \alpha + i\beta, \alpha,\beta\in\mb R$ and $X(x) = u(x) = iv(x)$, $u,v\in\mb R$.
	Take conjugate of (1)-(2), use fact that $p,q,r,a_1,a_2,b_1,b_2$ are real. So $[r(x) \conj{X'}(x)]' + [q(x) + \conj{\lambda} p(x)] \conj{X}(x) = 0$, $a_1\conj{X}(a) + a_2 \conj{X'}(a) = 0$, and $b_1 \conj{X}(b) + b_2\conj{X'}(b) = 0$. Thus $\conj{\lambda}$ is also an eigenvalue, with corresponding eigenfunction $\conj{X}(x)$. \underline{By way of contradiction}, suppose $\lambda$ not real, so $\beta\neq 0$. Then $\lambda \neq \conj{\lambda}$, so $X(x)$ and $\conj{X}(x)$ are orthogonal with respect to weight function $p$. Thus $0 = \int_a^b p(x) X(x) \conj{X}(x) \, dx = \int_a^b p(x) |X(x)|^2 \, dx = \int_a^b p(x) (u(x)^2 + v(x)^2)\, dx$. This implies $u(x) \equiv 0$ and $v(x) \equiv 0$, so $X(x) \equiv 0$. Contradiction since $X(x)$ is an eigenfunction.
\end{proof}
\begin{theorem}
	If $\lambda$ is an eigenvalue of regular SL problem, then it has a real eigenfunction. If $X,Y$ are eigenfunctions for same eigenvalue $\lambda$, then $Y(x) = cX(x)$, $c\neq 0$ ($*$).
\end{theorem}
\begin{proof}
	Prove 2$^\text{nd}$ statement first. Suppose $X(x), Y(x)$ are eigenfunctions for $\lambda\in\mb R$. Define (linear combination) $Z(x) = Y'(a) X(x) - X'(a) Y(x)$. Thus $Z(x)$ satisfies: $[rZ']' + [q+\lambda p] Z = 0$ and $Z'(a) = 0$. Also: $a_1 X(a) + a_2 X'(a) = 0$ and $a_1Y(a) + a_2Y'(a) = 0$. This implies that $Z(a) = 0$, $\mat{ X(a) & X'(a) \\ Y(a) & Y'(a)} \mat{ a_1 \\ a_2} = \mat{0\\0}$. By Existence and Uniqueness Theorem for 2$^\text{nd}$ order linear IVP, since 0 function is also a solution, $Z(x) \equiv 0$. Thus $Y'(a) X(x) - X'(a) Y(x) \equiv 0$. Must have either $Y'(a)$ and $X'(a)$ both zero or both nonzero. If $Y'(a)\neq 0$ and $X'(a)\neq0$, then ($*$) holds. If $Y'(a) = 0$ and $X'(a) = 0$, then $Y(a)\neq0$ and $X(a)\neq0$. In this case, define $W(x) = Y(a) X(x) - X(a) Y(x)$. Follow argument similar to $Z(x)$, conclude $W(x)\equiv0$, so $Y(x) = \frac{Y(a)}{X(a)} X(x)$, so ($*$) holds. Let $X(x) = U(x) + iV(x)$ be eigenfunction for $\lambda$, where $U(x),V(x)$ are real. Plug in to DE and see that $U(x)$ and $V(x)$ are also eigenfunctions for $\lambda$. Thus $V(x) = \beta U(x)$, so $\beta$ is real. Thus $X(x) = (1+ i\beta) U(x)$.
\end{proof}
HW Sect. 69: 1,2

\begin{example}
	[\S69.1] $[x X'(x)]' + \frac{\lambda}{x} X(x) = 0$. Let $x=e^s$ so $s=\ln x$. $X'(x) = \frac{dX}{dx} = \frac{dX}{ds}\cdot \frac{ds}{dx}$ or $\frac{d}{dx} [e^s X'(x)]$. $X'(x) = \frac{d}{dx} X(x) = \frac{dX}{dx} \cdot \frac{ds}{dx} = e^{-s} \frac{dX}{ds}$.
\end{example}
\begin{recall}
	Regular SL problems
	$[r(x) X'(x)]' + [q(x) + \lambda p(x)] X(x) = 0$ with $a_1 X(a) + a_2 X'(a) = 0$, $b_1 X(b) + b_2 X'(b) = 0$, where $p,q,r,r'$ continuous on $[a,b)$, $p>0$, $r>0$ on $[a,b]$.
	We know
	\begin{itemize}
		\item countably infinitely many real eigenvalues,
		\item each eigenvalue has a real eigenfunction (dimension of eigenspace is 1),
		\item eigenfunctions corresponding to distinct eigenvalues are orthogonal with respect to $p(x)$.
	\end{itemize}
\end{recall}
\begin{theorem}
	Let $\lambda$ be an eigenvalue of a regular SL problem. If $q(x)\leq 0$ on $[a,b]$ and $a_1 a_2 \leq 0$, $b_1b_2 \geq 0$, then $\lambda \geq 0$.
\end{theorem}
\begin{proof}
	Let $X(x)$ be a real eigenfunction for eigenvalue $\lambda$. So $[r X']' + [q + \lambda p] X = 0$. Multiply by $X$ and integrate: \begin{align*}\lambda \int_a^b p(x) X^2(x) \, dx &= - \int_a^b [rX']' X \, dx + \int_a^b (-q) X^2 \,dx \\ &= -r(x) X'(x) X(x) \big\rvert_a^b + \int_a^b r(x) [X'(x)]^2 \, dx + \int_a^b (-q) X^2 \, dx \\ &= r(a) X(a) X'(a) - r(b) X(b) X'(b) + \int_a^b r(X')^2 \, dx + \int_a^b (-q)X^2\, dx, \end{align*} using integration by parts. Consider $r(a) X(a) X'(a)$: If either $a_1=0$ or $a_2 =0$, then $r(a)X(a) X'(a) = 0$. If $a_1\neq 0$ and $a_2\neq 0$, $r(a) X(a) X'(a) = - r(a) X(a) \left( \frac{a_1}{a_2} \right) X(a) = r(a) [X(a)]^2 \left( -\frac{a_1}{a_2} \right) \geq 0$ because $-\frac{a_1}{a_2}>0$.
	Similar argument shows $-r(b)X(b)X'(b) \geq 0$, so $\lambda \int_a^b p(x) [X(x)]^2 \, dx \geq 0$, so $\lambda \geq 0$.
\end{proof}
\begin{example}
	$X''(x) + \lambda X(x) = 0$ with $X'(0) = 0$ and $hX(c) + X'(c) = 0$, $h>0$. This is a regular SL problem, $r(x) \equiv 1$, $p(x) \equiv 1$, $q(x) \equiv 0$, $a_1 = 0$, $a_2 = 1$, $b_1 = h$ and $b_2 = 1$.

	Case $\lambda = 0$: Then $X''(x) = 0$. Genereal solution is $X(x) = Ax+B$. $X'(0)$ implies $A= 0$, so $X(x) = B$. Then $hX(c) + X'(c) = 0$ implies $hB = 0$, so $B = 0$. So $X(x) = 0$, $\lambda = 0$ not an eigenvalue.

	Consider $\lambda>0$, say $\lambda = \alpha^2$, where $\alpha >0$. Thus $X''(x) + \alpha^2 X(x) = 0$. General solution is $X(x) = c_1 \cos{\alpha x} + c_2 \sin{\alpha x}$. $X'(0) = 0$ implies $\alpha c_2 \cos{(0)} = 0$, so $c_2 = 0$. So $X(x) = c_1 \cos{\alpha x}$. $hX(c) + X'(c) = 0$ implies $c_1 h \cos{(\alpha c)} - \alpha c_1 \sin{(\alpha c)} = 0 = h\cos{(\alpha c)} - \alpha \sin{(\alpha c)}$, so $\frac{h}{\alpha} = \tan{(\alpha c)}$ or $\frac{hc}{\alpha c} = \tan{(\alpha c)}$. $\ra$ so $\frac{hc}x = \tan{x}$ for $x = \alpha c$. If $x$ is a root, then $\alpha = \frac{x}{c}$ and $\lambda = \alpha^2$ is an eigenvalue. Plot $y = \tan{x}$ and $y = \frac{hc}{x}$: geometrically there are countably infinite number of solutions at the intersection points. As $n\ra \infty$, $x_n \sim (n-1)\pi$. Then $\alpha_n = \frac{x_n}{c} \sim \frac{(n-1)\pi}{c}$ as $n\ra \infty$. So $\lambda_n = \alpha_n^2$. Corresponding eigenfunction $X_n(x) = \cos{\alpha_n x}$, for $n=1,2,\dots$. Also $\{\cos{\alpha_n x}\}_{n=1}^\infty$ is orthogonal. Note: $||X_n(x)||^2 = \int_0^c \cos^2{\alpha_n x}\, dx = \dots = \frac{ch + \sin^2{(\alpha_n c)}}{2h}$. So $\phi_n(x) = \frac{1}{||X_n||} X_n(x) = \sqrt{\frac{ 2h}{ch + \sin^2{(\alpha_n c)}}}\cos{(\alpha_n x)}$, where $\{\phi_n\}_{n=1}^\infty$ is an orthonormal set.
\end{example}

HW Section 72: 1,2,6,9

Exam: Chapter 3, Starting with \S26 we did other boundary conditions, \S28. \S32-34, all of Chapter 4. Chapter 5 the 2 basic boundary value problems, \S39, 40, 42, 45. All of Chapter 7: Chapter 8: \S67-73.

\begin{example}
	[Done in HW] $(x X'(x))' + \frac{1}{x} \lambda X(x) = 0$ with $X(1) = 0$ and $X(b) = 0$. In HW you show: $\lambda_n = \alpha_n^2$, $\alpha_n = \frac{n\pi}{\ln{b}}$, $n=1,2,\dots$ and $\phi_n(x) = \sqrt{\frac{2}{\ln{b}}}\sin{(\alpha_n \ln{x})}$. $\{\phi_n\}_{n=1}^\infty$ is orthonormal with respect to weight function $p(x) = \frac{1}{x}$. Let us represent $f(x) = 1$ with these eigenfunctions $1 = \sum_{n=1}^\infty c_n \phi_n(x)$. If this is possible, and we assume it is, we know the Fourier coefficients: \begin{align*} c_n = (f(x),\phi_n(x)) &= \int_1^b \frac{1}{x}\cdot(1) \phi_n(x) \, dx = \sqrt{\frac{2}{\ln{b}}} \int_1^b \frac{1}{x} \sin{(\alpha_n \ln{x})} \, dx = \sqrt{\frac{2}{\ln{b}}} \left( -\frac{1}{\alpha_n} \right) \cos{(\alpha_n \ln{x} )} \bigg\rvert_1^b \\ &= \sqrt{ \frac{2}{\ln{b}}} \left(-\frac{1}{\alpha_n} \right) [\cos{(n\pi)}-1] = \sqrt{ \frac{2}{\ln{b}}} \left( \frac{1}{\alpha_n} \right) (1-(-1)^n) \end{align*}
	So $ \displaystyle 1 = \sum_{n=1}^\infty \sqrt{ \frac{2}{\ln{b}}} \cdot \frac{1-(-1)^n}{\alpha_n} \sqrt{ \frac{2}{\ln{b}}} \sin{( \alpha_n \ln{b})} = \frac{4}{\ln{b}} \sum_{n=1}^\infty \frac{1}{\alpha_{2n-1}} \sin{(\alpha_{2n-1} \ln{x})}$ on $1<x<b$.
	If we make the substitution $s = \frac{\pi}{\ln{b}}\ln{x}$, we translate from $x$ in $[1,b]$ to $s$ in $[0,\pi]$, and $(2n-1)s = \alpha_{2n-1} \ln{x}$, so we get: $$ 1 = \frac{4}{\ln{b}} \sum_{n=1}^\infty \frac{1}{(2n-1)\pi/\ln{b}} \sin{(2n-1)s} = \frac{4}{\pi} \sum_{n=1} \frac{1}{2n-1} \sin{[(2n-1)s]} $$ on $0 < s < \pi$, which we \underline{proven} to be valid on $0<s<\pi$.
\end{example}
\begin{example}
	Consider temperature in cylinder on $0<x<1$ with perfect insulation at $x = 0$ and at $x=1$, surface heat transfer into a medium with temperature 0. Initial temperature distribution $f(x)$. The model: $u_t(x,t) = ku_{xx}(x,t)$, $u_x(0,t) = 0$, $u_x(1,t) = -hu(1,t)$, $u(x,0) = f(x)$. Newton's law of cooling $h[T-u(x,t)]$, $h>0$. Do separation of variables: $u(x,t) = X(x) T(t)$. Get: $X''(x) + \lambda X(x) = 0$, $X'(0) = 0$, $hX(1) + X'(1) = 0$. We solved this last time: ($c = 1$) $X_n(x) = \cos{\alpha_n x}$, $n=1,2,\dots$, $\lambda_n = \alpha_n^2$, $\alpha_n$'s are roots of $\tan{\alpha_n} = \frac{h}{\alpha_n}$. Normalized eigenfunctions $\phi_n(x) = \sqrt{ \frac{2h}{h + \sin^2{\alpha_n}}} \cos{\alpha_n x}$. We also get $T_n(t) = e^{-\lambda_n kt} = e^{-\alpha_n^2 kt}$. So solution is $$ u(x,t) = \sum_{n=1}^\infty c_n e^{-\alpha_n^2 kt} \sqrt{ \frac{2h}{h + \sin^2{\alpha_n}}} \cos{\alpha_n x}.$$ Using IC: $f(x) = \sum_{n=1}^\infty c_n \phi_n(x)$, so $c_n = (f(x),\phi_n(x)) = \int_0^1 f(x) \phi_n(x) \, dx$.
\end{example}
HW 73: 1,2,4.
Next: (not in text) Vibrations of solid elastic beam.

\newpage

Transverse vibrations of solid elastic beam.
Consider elastic beam of length $l$ (much larger than cross sectional are). Let $w(x,t) = $ transverse displacement at time $t$ and position $x$. Under reasonable assumptions, can derive the Euler-Bernoulli beam equation: $$ m(x) w_{tt}(x,t) + \frac{\partial^2}{\partial x^2} [EI(x)w_{xx}(x,t)] = 0. $$
Assume all parameters are constant, we get $ w_{tt}(x,t) + \beta w_{xxxx} (x,t) = 0$, $\beta = \frac{EI}{m} > 0$.
\underline{Boundary Conditions}:
\begin{enumerate}
	\item[]\underline{Clamped}: $w(\bar{x},t) = 0$, $w_x(\bar{x},t) = 0$ for $\bar{x} = 0$ or $l$.
	\item[]\underline{Hinged}: $w(\bar{x}) = 0$, $w_{xx}(\bar{x},t) = 0$ for $\bar{x} = 0$ or $l$.
	\item[]\underline{Free}: $w_{xx}(\bar{x},t) = 0$, $w_{xxx}(\bar{x},t) = 0$ for $\bar{x} = 0$ or $l$.
\end{enumerate}
\begin{example}
	Consider Euler-Bernoulli beam hinge at both ends. $w_{tt}(x,t) + \beta w_{xxxx} (x,t) = 0$. BC $w(0,t) = 0 = w_x(0,t)$, $w(l,t) = 0 = w_{xx}(l,t)$. IC $w(x,0) = f(x)$.
	Apply Fourier method: $w(x,t) = X(x) T(t)$, so $T''(t) + \lambda T(t) = 0$ and $X'''' - \frac{\lambda}{\beta} X = 0$ with $X(0) = 0 = X''(0)$ and $X(l) = 0 = X''(l)$. Get $\lambda>0$, assume $\frac{\lambda}{\beta} = \mu^4$ so that $X'''' - \mu^4 X = 0$. Characteristic euqation: $r^4 - \mu^4 = 0 = (r^2 - \mu^2)(r^2+\mu^2) = (r-\mu)(r+\mu)(r^2+\mu^2)$, with roots $r=\mu,-\mu,i\mu,-i\mu$.
	General solution: $X(x,t) = c_1 \sin{\mu x} + c_2\cos{\mu x} + c_3 \sinh{\mu x} + c_4 \cosh{\mu x}$. BC: $X(0) = 0$: $c_2 + c_4 = 0$. $X''(0) = 0$: $-c_2+c_4 = 0$. $\implies c_2 = 0 = c_4$. $X(l) = 0$: $c_1\sin{\mu l} + c_2 \cos{\mu l} + c_3 \sinh{\mu l} + c_4 \cosh{\mu l} = 0$. $X''(l) = 0$: $-c_1\sin{\mu l} - c_2 \cos{\mu l} + c_3 \sinh{\mu l} + c_4 \cosh{\mu l} = 0$.
	$$\mat{ 0 & 1 & 0 & 1 \\ 0 & -1 & 0 & 1 \\ \sin{\mu l} & \cos{\mu l} & \sinh{\mu l} & \cosh{\mu l} \\ -sin{\mu l} & -\cos{\mu l} & -\sinh{\mu l} & -\cosh{\mu l}} \mat{ c_1 \\ c_2 \\ c_3 \\ c_4} = \mat{0\\0\\0\\0}. $$
	$c_2 = 0 = c_4$, so $c_1 \sin{\mu l} + c_3 \sinh{\mu l} = 0$ and $-c_1 \sin{\mu l} + c_3 \sinh{\mu l} = 0$. Then $2c_3 \sinh{\mu l} = 0 \implies c_3 = 0$. Thus $c_1\sin{\mu l} = 0$, $c_1 \neq 0$, so $\sin{\mu l} = 0$. So $\mu l = n\pi$, $n = 1,2,\dots$, or $\mu_n = \frac{n\pi}{l}$ and $\lambda_n = \beta \left(\frac{n\pi}{l}\right)^4$. Therefore $X_n(x) = \sin{\frac{n\pi}{l}x}$.
\end{example}
HW: Find eigenvalues + eigenfunctions for cantilever beam (clamped at $x=0$ and free at $x=l$).

\begin{recall}
	Beam example $w_{tt}(x,t) + \beta w_{xxxx}(x,t) = 0$. Separate variables $x''''(x) + \frac{\lambda}{\beta} x(x) = 0$, where $\frac{\lambda}{\beta} = \mu^4$ with $X(0) = 0 = X'(0)$ and $X''(l) = 0 = X'''(l)$. Then $X'''' + \mu^4 X = 0$.
	$X(x)  = c_1\sin{\mu x} + c_2 \cos{\mu x} + c_3 \sinh{\mu x} + c_4 \cosh{\mu x}$.
\end{recall}

Modifications for certain non-homogeneous problems (section 77, similar to section 39)
\begin{example}
	$u_t(x,t) = ku_{xx}(x,t)$ with $u(0,t) = 0$ and $Ku_x(1,t) = A$, $A>0$; $u(x,0) = 0$. Non homogeneous BC. Similar to idea in section 39, suppose $u(x,t) = U(x,t)+ \Phi(x)$. Try to select $\Phi(x)$ so that $U(x,t)$ is a solution to homogeneous PDE with homogeneous BC. If possible, then can apply Fourier Method to determine $U(x,t)$, and recover $u(x,t)$.
	Then $U(x,t) = u(x,t) - \Phi(x)$. So $U_t(x,t) = u_t(x,t) = ku_{xx}(x,t)$ and $U_t(x,t) = kU_{xx}(x,t) + k\Phi''(x)$. Then $U(0,t) = u(0,t) - \Phi(0) = -\Phi(0)$ and $U_x(1,t) = u_x(1,t) - \Phi'(1) = \frac{A}{K} - \Phi'(1)$. To make PDE and BC for $U(x,t)$ homogeneous, we want $\Phi(x)$ to satisfy:
	\begin{enumerate}
		\item[i)] $k\Phi''(x) = 0$
		\item[ii)] $\Phi(0) = 0$
		\item[iii)] $\frac{A}{K} - \Phi'(1) = 0$
	\end{enumerate}
	So i) implies $\Phi(x) = Bx+C$. ii) implies $0 = B(0) + C$, so $C = 0$ so $\Phi(x) = Bx$. Now iii) implies $\Phi'(1) = \frac{A}{K}$ so $B = \frac{A}{K}$. So $\Phi(x) = \frac{A}{K}x$.
	Then $U(x,t)$ satisfies: $U_t(x,t) = kU_{xx}(x,t)$, $U(0,t) = 0$, $U_x(1,t) = 0$, and $U(x,0) = u(x,0) - \Phi(x) = -\frac{A}{K}x$. Next apply Fourier method to determine $U(x,t)$. $U(x,t) = X(x) T(t)$. $X''(x) + \lambda X(x) = 0$, $X(0) = 0$, and $X'(1) = 0$. By problem 72.1, $\lambda_n = \alpha_n^2$; $\alpha_n = \frac{(2n-1)\pi}{2}$ for $n=1,2,\dots$; $X_n(x) = \phi_n(x) = \sqrt{2} \sin{(\alpha_n x)}$. Then $T_n(t) = e^{-\alpha_n^2 kt}$. So $U(x,t) = \sum_{n=1}^\infty c_n e^{-\alpha_n^2 kt} \phi_n(x)$.  Then determine $c_n$ so that $-\frac{A}{K}x = \sum_{n=1}^\infty c_n \phi_n(x)$, $c_n = \sqrt{2} \frac{A}{K} \frac{(-1)^n}{\alpha_n^2}$. Thus $u(x,t) = \frac{A}{K}x + \frac{2A}{K} \sum_{n=1}^\infty e^{-\alpha_n^2 kt} \frac{(-1)^n}{\alpha_n^2} \sin{(\alpha_n x)}$.
\end{example}
HW: \S77: 2,3. Not due.
\newpage
\begin{example}
	[Test \#4] $u_t(x,t) = u_{xx}(x,t)$, $u_x(0,t) = 0$, $u(1,t) = 4$, $u(x,0) = 0$. $u(x,t) = U(x,t) + \Phi(x)$. $U(x,t) = u(x,t) - \Phi(x)$. $U_t(x,t) = u_t(x,t) = u_{xx}(x,t) = U_{xx}(x,t) + \Phi''(x)$. $U_x(0,t) = u_x(0,t) - \Phi'(0) = -\Phi'(0)$. $U(1,t) = u(1,t) - \Phi(1) = 4-\Phi(1)$. Select $\Phi(x)$ so that i) $\Phi''(x) = 0 \implies \Phi(x) = Ax+B$; ii) $\Phi'(0) = 0 \implies A = 0, \Phi(x) = B$; iii) $\Phi(1) = 4 \implies B = 4$, so $\Phi(x) = 4$.
	So $U(x,t)$ solves: $U_t(x,t) = U_{xx}(x,t)$, $U_x(0,t) = 0$, $U(1,t) = 0$, $U(x,0) = -4$.
\end{example}
\begin{example}
	[Test \#5] $X''(x) +\lambda X(x) = 0$, $X(0) = 0$, $X'(1) + 2X(1) = 0$. Know $\lambda \geq 0$. Case $\lambda = 0$: $\ra$ only trivial solution, so not an eigenvalue. Case $\lambda>0$: Assume $\lambda = \alpha^2$, $\alpha>0$. $X(x) = c_1 \sin{\alpha x} + c_2\cos{\alpha x}$. $X(0) = 0$ implies $0 = c_2$, so $X(x) = c_1 \sin{\alpha x}$, $X'(x) = c_1\alpha\cos{\alpha x}$. $X'(1) + 2X(1) = 0$ implies $c_1 \alpha \cos{\alpha} + 2c_1 \sin{\alpha} = 0$. Want $c_1 \neq 0$, $\alpha\cos{\alpha} + 2\sin{\alpha} = 0$ means $\tan{\alpha} = -\frac{\alpha}{2}$. By considering graphs of $y = \tan{x}$ and $y = -\frac{x}{2}$, we see there are countable infinite number of solutions $\alpha_n$, $n = 1,2\dots$. Then $\lambda_n = \alpha_n^2$, $X_n(x) = \sin{(\alpha_n x)}$. To get normalized eigenfunction $\phi_n(x) = \frac{1}{||X_n(x)||} X_n(x)$. $||X_n(x)||^2 = \int_0^1 \sin^2{(\alpha_n x)} \, dx = \int_0^1 \frac{1}{2} [1-\cos{2\alpha_n x}] \, dx = \frac{1}{2}x + \frac{1}{4\alpha_n} \sin{2\alpha_n x} \bigg\rvert_0^1 = \frac{1}{2} - \frac{1}{4\alpha_n} \sin{2\alpha_n} = \frac{1}{2} - \frac{1}{2\alpha_n} \sin{\alpha_n}\cos{\alpha_n} = \frac{1}{2} - \frac{1}{2} \left( -\frac{1}{2} \cos{\alpha_n} \right) \cos{\alpha_n} = \frac{1}{2} + \frac{1}{4}\cos^2{\alpha_n} = \frac{2 + \cos^2{\alpha_n}}{4}$.
	So $\phi_n(x) = \frac{2}{\sqrt{2+\cos^2{\alpha_n}}} \sin{(\alpha_n x)}$.
\end{example}

\begin{example}
	[Beam Equation] Last time got to $X''''- \frac{\lambda}{\beta} X = 0$, where $\frac{\lambda}{\beta} = \mu^4$. Then $X'''' - \mu^4 X = 0$ with $X(0) = 0 = X'(0)$, $X''(l) = X'''(l) = 0$, and $X(x) = c_1\sin{\mu x} + c_2\cos{\mu x} + c_3\sinh{\mu x} + c_4\cosh{\mu x}$. Then $X'(x) = \mu[c_1\cos{\mu x} - c_2\sin{\mu x} + c_3\cosh{\mu x} + c_4\sinh{\mu x}]$, $X''(x) = \mu^2 [ -c_1 \sin{\mu x} - c_2\cos{\mu x} + c_3 \sinh{\mu x} + c_4\cosh{\mu x}]$, and $X'''(x) = \mu^3 [ -c_1\cos{\mu x} + c_2 \sin{\mu x} + c_3 \cosh{\mu x} + c_4\sinh{\mu x}]$. $X(0) = 0$ implies $c_2 = -c_4$. $X'(0) = 0$ implies $c_1 = -c_3$. So $X''(l) = 0$ implies $c_3[\sin{\mu l} + \sinh{\mu l}] + c_2 [\cos{\mu l} + \cosh{\mu l}] = 0$ and $X'''(l) = 0$ implies $-c_1[\cos{\mu l} + \cosh{\mu l}] + c_2[\sin{\mu l} - \sinh{\mu l}] = 0$.
	$$\mat{\sin{\mu l} + \sinh{\mu l} & \cos{\mu l} + \cosh{\mu l} \\ -\cos{\mu l} - \cosh{\mu l} & \sin{\mu l} - \sinh{\mu l}} \mat{c_1\\c_2} = \mat{0\\0}.$$ This has a nontrivial solution only if determinant of matrix is zero. Then
	\begin{align*}
		(\sin{\mu l} + \sinh{\mu l})(\sin{\mu l}-\sinh{\mu l}) + (\cos{\mu l} + \cosh{\mu l})^2 &= 0 \\ \sin^2{\mu l} - \sinh^2{\mu l} + \cos^2{\mu l} + \cosh^2{\mu l} + 2\cos{\mu l} \cosh{\mu l} &= 0 = 2 + 2\cos{\mu l} \cosh{\mu l} = 0
	\end{align*}
	So $\cos{\mu l}\cosh{\mu l} = -1$.
\end{example}

\end{document}
